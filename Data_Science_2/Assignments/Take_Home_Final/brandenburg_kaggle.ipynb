{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3c920e6-3761-4d94-9558-ae995ffa39ac",
   "metadata": {},
   "source": [
    "# <center> Kaggle Competition Assignment <center> Ian Brandenburg (2304791) <center> [GitHub Repo](https://github.com/Iandrewburg/Data_Science/tree/main/Data_Science_2/Assignments/Take_Home_Final)\n",
    "    \n",
    "    \n",
    "The Kaggle competition has been launched, please register using this [link](https://www.kaggle.com/t/f79b637ede074e70a233661b4614083c).\n",
    "\n",
    "You will find the training and test data in the data section of the competition, along with a description of the features. You will need to build models on the training data and make predictions on the test data and submit your solutions to Kaggle. You will also find a sample solution file in the data section that shows the format you will need to use for your own submissions.\n",
    "\n",
    "The deadline for Kaggle solutions is 8PM on 19 April. You will be graded primarily on the basis of your work and how clearly you explain your methods and results. Those in the top three in the competition will receive some extra points. I expect you to experiment with all the methods we have covered: linear models, random forest, gradient boosting, neural networks + parameter tuning, feature engineering.\n",
    "\n",
    "You will see the public score of your best model on the leaderboard. A private dataset will be used to evaluate the final performance of your model to avoid overfitting based on the leaderboard.\n",
    "\n",
    "You should also submit to Moodle the documentation (ipynb and pdf) of your work, including exploratory data analysis, data cleaning, parameter tuning and evaluation. Aim for concise explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2156211d-6705-4669-9a65-835e9a896f55",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f6fb47-2ef1-43d6-94ec-a6482b8525dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "from itertools import combinations\n",
    "\n",
    "# Sklearn model selection, preprocessing, metrics, and ensemble methods\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Sklearn pipeline utilities\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Cat Boost Classifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Light GBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "# InterpretML for explainable boosting\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "\n",
    "# TensorFlow and Keras for neural networks\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e3e2f2-32fb-405c-909f-ed9b42a5b7fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Wrangling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044cd425-2b1e-4019-91d4-976186fb8854",
   "metadata": {},
   "source": [
    "## Data Import\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a30844dd-201d-416c-80dc-e0040f99a95a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>is_popular</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>594</td>\n",
       "      <td>9</td>\n",
       "      <td>702</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.620438</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.153395</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>346</td>\n",
       "      <td>8</td>\n",
       "      <td>1197</td>\n",
       "      <td>0.470143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666209</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308167</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>484</td>\n",
       "      <td>9</td>\n",
       "      <td>214</td>\n",
       "      <td>0.618090</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.748092</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>-0.141667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>639</td>\n",
       "      <td>8</td>\n",
       "      <td>249</td>\n",
       "      <td>0.621951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.664740</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>177</td>\n",
       "      <td>12</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.397841</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.583578</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.441111</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "0        594               9               702         0.454545   \n",
       "1        346               8              1197         0.470143   \n",
       "2        484               9               214         0.618090   \n",
       "3        639               8               249         0.621951   \n",
       "4        177              12              1219         0.397841   \n",
       "\n",
       "   n_non_stop_words  n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  \\\n",
       "0               1.0                  0.620438         11               2   \n",
       "1               1.0                  0.666209         21               6   \n",
       "2               1.0                  0.748092          5               2   \n",
       "3               1.0                  0.664740         16               5   \n",
       "4               1.0                  0.583578         21               1   \n",
       "\n",
       "   num_imgs  num_videos  ...  max_positive_polarity  avg_negative_polarity  \\\n",
       "0         1           0  ...               1.000000              -0.153395   \n",
       "1         2          13  ...               1.000000              -0.308167   \n",
       "2         1           0  ...               0.433333              -0.141667   \n",
       "3         8           0  ...               0.500000              -0.500000   \n",
       "4         1           2  ...               0.800000              -0.441111   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                   -0.4                  -0.10                 0.0   \n",
       "1                   -1.0                  -0.10                 0.0   \n",
       "2                   -0.2                  -0.05                 0.0   \n",
       "3                   -0.8                  -0.40                 0.0   \n",
       "4                   -1.0                  -0.05                 0.0   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                       0.0                     0.5   \n",
       "1                       0.0                     0.5   \n",
       "2                       0.0                     0.5   \n",
       "3                       0.0                     0.5   \n",
       "4                       0.0                     0.5   \n",
       "\n",
       "   abs_title_sentiment_polarity  is_popular  article_id  \n",
       "0                           0.0           0           1  \n",
       "1                           0.0           0           3  \n",
       "2                           0.0           0           5  \n",
       "3                           0.0           0           6  \n",
       "4                           0.0           0           7  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"https://raw.githubusercontent.com/Iandrewburg/Data_Science/main/Data_Science_2/Assignments/Take_Home_Final/train.csv\")\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20bbc1b2-429b-465f-9e29-d83e646b31cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134</td>\n",
       "      <td>11</td>\n",
       "      <td>217</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.818966</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.170370</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.155556</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>-0.155556</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>415</td>\n",
       "      <td>11</td>\n",
       "      <td>1041</td>\n",
       "      <td>0.489423</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.700321</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.426268</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>625</td>\n",
       "      <td>9</td>\n",
       "      <td>486</td>\n",
       "      <td>0.599585</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.387821</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148</td>\n",
       "      <td>14</td>\n",
       "      <td>505</td>\n",
       "      <td>0.509018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.718861</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.284722</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>294</td>\n",
       "      <td>14</td>\n",
       "      <td>274</td>\n",
       "      <td>0.620301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "0        134              11               217         0.631579   \n",
       "1        415              11              1041         0.489423   \n",
       "2        625               9               486         0.599585   \n",
       "3        148              14               505         0.509018   \n",
       "4        294              14               274         0.620301   \n",
       "\n",
       "   n_non_stop_words  n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  \\\n",
       "0               1.0                  0.818966          4               2   \n",
       "1               1.0                  0.700321         22               3   \n",
       "2               1.0                  0.727273          4               3   \n",
       "3               1.0                  0.718861          8               4   \n",
       "4               1.0                  0.726190          5               1   \n",
       "\n",
       "   num_imgs  num_videos  ...  min_positive_polarity  max_positive_polarity  \\\n",
       "0         2           0  ...               0.136364                    0.5   \n",
       "1         0          14  ...               0.050000                    1.0   \n",
       "2         1           0  ...               0.062500                    0.7   \n",
       "3         1           1  ...               0.100000                    1.0   \n",
       "4         1           0  ...               0.100000                    0.6   \n",
       "\n",
       "   avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "0              -0.170370              -0.200000              -0.155556   \n",
       "1              -0.426268              -1.000000              -0.100000   \n",
       "2              -0.387821              -1.000000              -0.050000   \n",
       "3              -0.284722              -0.400000              -0.050000   \n",
       "4              -0.333333              -0.333333              -0.333333   \n",
       "\n",
       "   title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0            0.288889                 -0.155556                0.211111   \n",
       "1            0.975000                  0.300000                0.475000   \n",
       "2            0.000000                  0.000000                0.500000   \n",
       "3            0.000000                  0.000000                0.500000   \n",
       "4            0.000000                  0.000000                0.500000   \n",
       "\n",
       "   abs_title_sentiment_polarity  article_id  \n",
       "0                      0.155556           2  \n",
       "1                      0.300000           4  \n",
       "2                      0.000000          10  \n",
       "3                      0.000000          13  \n",
       "4                      0.000000          26  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(\"https://raw.githubusercontent.com/Iandrewburg/Data_Science/main/Data_Science_2/Assignments/Take_Home_Final/test.csv\")\n",
    "test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdaeb309-5690-43a6-a411-a7a56c7aa3f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timedelta', 'n_tokens_title', 'n_tokens_content', 'n_unique_tokens',\n",
       "       'n_non_stop_words', 'n_non_stop_unique_tokens', 'num_hrefs',\n",
       "       'num_self_hrefs', 'num_imgs', 'num_videos', 'average_token_length',\n",
       "       'num_keywords', 'data_channel_is_lifestyle',\n",
       "       'data_channel_is_entertainment', 'data_channel_is_bus',\n",
       "       'data_channel_is_socmed', 'data_channel_is_tech',\n",
       "       'data_channel_is_world', 'kw_min_min', 'kw_max_min', 'kw_avg_min',\n",
       "       'kw_min_max', 'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg',\n",
       "       'kw_avg_avg', 'self_reference_min_shares', 'self_reference_max_shares',\n",
       "       'self_reference_avg_sharess', 'weekday_is_monday', 'weekday_is_tuesday',\n",
       "       'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday',\n",
       "       'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend', 'LDA_00',\n",
       "       'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity',\n",
       "       'global_sentiment_polarity', 'global_rate_positive_words',\n",
       "       'global_rate_negative_words', 'rate_positive_words',\n",
       "       'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
       "       'max_positive_polarity', 'avg_negative_polarity',\n",
       "       'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity',\n",
       "       'title_sentiment_polarity', 'abs_title_subjectivity',\n",
       "       'abs_title_sentiment_polarity', 'article_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced915d4-89b8-49e9-a4a2-84e12f0aa288",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exploratory Data Analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c854cf70-2030-4ae0-bc31-b84b3c68f513",
   "metadata": {},
   "source": [
    "### Variable Descriptions\n",
    "---\n",
    "\n",
    "\n",
    "    timedelta: Days between the article publication and the dataset acquisition (non-predictive)\n",
    "    n_tokens_title: Number of words in the title\n",
    "    n_tokens_content: Number of words in the content\n",
    "    n_unique_tokens: Rate of unique words in the content\n",
    "    n_non_stop_words: Rate of non-stop words in the content\n",
    "    n_non_stop_unique_tokens: Rate of unique non-stop words in the content\n",
    "    num_hrefs: Number of links\n",
    "    num_self_hrefs: Number of links to other articles published by Mashable\n",
    "    num_imgs: Number of images\n",
    "    num_videos: Number of videos\n",
    "    average_token_length: Average length of the words in the content\n",
    "    num_keywords: Number of keywords in the metadata\n",
    "    data_channel_is_lifestyle: Is data channel 'Lifestyle'?\n",
    "    data_channel_is_entertainment: Is data channel 'Entertainment'?\n",
    "    data_channel_is_bus: Is data channel 'Business'?\n",
    "    data_channel_is_socmed: Is data channel 'Social Media'?\n",
    "    data_channel_is_tech: Is data channel 'Tech'?\n",
    "    data_channel_is_world: Is data channel 'World'?\n",
    "    kw_min_min: Worst keyword (min. shares)\n",
    "    kw_max_min: Worst keyword (max. shares)\n",
    "    kw_avg_min: Worst keyword (avg. shares)\n",
    "    kw_min_max: Best keyword (min. shares)\n",
    "    kw_max_max: Best keyword (max. shares)\n",
    "    kw_avg_max: Best keyword (avg. shares)\n",
    "    kw_min_avg: Avg. keyword (min. shares)\n",
    "    kw_max_avg: Avg. keyword (max. shares)\n",
    "    kw_avg_avg: Avg. keyword (avg. shares)\n",
    "    self_reference_min_shares: Min. shares of referenced articles in Mashable\n",
    "    self_reference_max_shares: Max. shares of referenced articles in Mashable\n",
    "    self_reference_avg_sharess: Avg. shares of referenced articles in Mashable\n",
    "    weekday_is_monday: Was the article published on a Monday?\n",
    "    weekday_is_tuesday: Was the article published on a Tuesday?\n",
    "    weekday_is_wednesday: Was the article published on a Wednesday?\n",
    "    weekday_is_thursday: Was the article published on a Thursday?\n",
    "    weekday_is_friday: Was the article published on a Friday?\n",
    "    weekday_is_saturday: Was the article published on a Saturday?\n",
    "    weekday_is_sunday: Was the article published on a Sunday?\n",
    "    is_weekend: Was the article published on the weekend?\n",
    "    LDA_00: Closeness to LDA topic 0\n",
    "    LDA_01: Closeness to LDA topic 1\n",
    "    LDA_02: Closeness to LDA topic 2\n",
    "    LDA_03: Closeness to LDA topic 3\n",
    "    LDA_04: Closeness to LDA topic 4\n",
    "    global_subjectivity: Text subjectivity\n",
    "    global_sentiment_polarity: Text sentiment polarity\n",
    "    global_rate_positive_words: Rate of positive words in the content\n",
    "    global_rate_negative_words: Rate of negative words in the content\n",
    "    rate_positive_words: Rate of positive words among non-neutral tokens\n",
    "    rate_negative_words: Rate of negative words among non-neutral tokens\n",
    "    avg_positive_polarity: Avg. polarity of positive words\n",
    "    min_positive_polarity: Min. polarity of positive words\n",
    "    max_positive_polarity: Max. polarity of positive words\n",
    "    avg_negative_polarity: Avg. polarity of negative words\n",
    "    min_negative_polarity: Min. polarity of negative words\n",
    "    max_negative_polarity: Max. polarity of negative words\n",
    "    title_subjectivity: Title subjectivity\n",
    "    title_sentiment_polarity: Title polarity\n",
    "    abs_title_subjectivity: Absolute subjectivity level\n",
    "    abs_title_sentiment_polarity: Absolute polarity level\n",
    "    is_popular: Whether or not the article was among the most popular ones based on shares on social media\n",
    "    article_id: Unique identifier of the article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "942c303a-6a91-42f4-bfa2-4e1508a1a038",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>...</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>is_popular</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29733.000000</td>\n",
       "      <td>29733.000000</td>\n",
       "      <td>29733.000000</td>\n",
       "      <td>29733.000000</td>\n",
       "      <td>29733.000000</td>\n",
       "      <td>29733.000000</td>\n",
       "      <td>29733.000000</td>\n",
       "      <td>29733.000000</td>\n",
       "      <td>29733.000000</td>\n",
       "      <td>29733.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>29733.000000</td>\n",
       "      <td>29733.000000</td>\n",
       "      <td>29733.000000</td>\n",
       "      <td>29733.000000</td>\n",
       "      <td>29733.000000</td>\n",
       "      <td>29733.000000</td>\n",
       "      <td>29733.000000</td>\n",
       "      <td>29733.000000</td>\n",
       "      <td>29733.000000</td>\n",
       "      <td>29733.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>355.645646</td>\n",
       "      <td>10.390812</td>\n",
       "      <td>545.008274</td>\n",
       "      <td>0.555076</td>\n",
       "      <td>1.005852</td>\n",
       "      <td>0.695432</td>\n",
       "      <td>10.912690</td>\n",
       "      <td>3.290788</td>\n",
       "      <td>4.524535</td>\n",
       "      <td>1.263546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757780</td>\n",
       "      <td>-0.259709</td>\n",
       "      <td>-0.520981</td>\n",
       "      <td>-0.107793</td>\n",
       "      <td>0.281878</td>\n",
       "      <td>0.069691</td>\n",
       "      <td>0.341427</td>\n",
       "      <td>0.155234</td>\n",
       "      <td>0.121649</td>\n",
       "      <td>19834.913530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>214.288261</td>\n",
       "      <td>2.110135</td>\n",
       "      <td>469.358037</td>\n",
       "      <td>4.064572</td>\n",
       "      <td>6.039655</td>\n",
       "      <td>3.768796</td>\n",
       "      <td>11.316508</td>\n",
       "      <td>3.840874</td>\n",
       "      <td>8.213823</td>\n",
       "      <td>4.189080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247293</td>\n",
       "      <td>0.128488</td>\n",
       "      <td>0.290454</td>\n",
       "      <td>0.095672</td>\n",
       "      <td>0.323461</td>\n",
       "      <td>0.264379</td>\n",
       "      <td>0.188735</td>\n",
       "      <td>0.225066</td>\n",
       "      <td>0.326886</td>\n",
       "      <td>11432.376037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>164.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>0.471400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.626126</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.328704</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9965.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>342.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>0.539894</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690566</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.252827</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19859.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>545.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>712.000000</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.755208</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.186494</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29742.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>731.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>8474.000000</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>1042.000000</td>\n",
       "      <td>650.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39643.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
       "count  29733.000000    29733.000000      29733.000000     29733.000000   \n",
       "mean     355.645646       10.390812        545.008274         0.555076   \n",
       "std      214.288261        2.110135        469.358037         4.064572   \n",
       "min        8.000000        2.000000          0.000000         0.000000   \n",
       "25%      164.000000        9.000000        246.000000         0.471400   \n",
       "50%      342.000000       10.000000        409.000000         0.539894   \n",
       "75%      545.000000       12.000000        712.000000         0.609375   \n",
       "max      731.000000       23.000000       8474.000000       701.000000   \n",
       "\n",
       "       n_non_stop_words  n_non_stop_unique_tokens     num_hrefs  \\\n",
       "count      29733.000000              29733.000000  29733.000000   \n",
       "mean           1.005852                  0.695432     10.912690   \n",
       "std            6.039655                  3.768796     11.316508   \n",
       "min            0.000000                  0.000000      0.000000   \n",
       "25%            1.000000                  0.626126      4.000000   \n",
       "50%            1.000000                  0.690566      8.000000   \n",
       "75%            1.000000                  0.755208     14.000000   \n",
       "max         1042.000000                650.000000    304.000000   \n",
       "\n",
       "       num_self_hrefs      num_imgs    num_videos  ...  max_positive_polarity  \\\n",
       "count    29733.000000  29733.000000  29733.000000  ...           29733.000000   \n",
       "mean         3.290788      4.524535      1.263546  ...               0.757780   \n",
       "std          3.840874      8.213823      4.189080  ...               0.247293   \n",
       "min          0.000000      0.000000      0.000000  ...               0.000000   \n",
       "25%          1.000000      1.000000      0.000000  ...               0.600000   \n",
       "50%          2.000000      1.000000      0.000000  ...               0.800000   \n",
       "75%          4.000000      4.000000      1.000000  ...               1.000000   \n",
       "max         74.000000    111.000000     91.000000  ...               1.000000   \n",
       "\n",
       "       avg_negative_polarity  min_negative_polarity  max_negative_polarity  \\\n",
       "count           29733.000000           29733.000000           29733.000000   \n",
       "mean               -0.259709              -0.520981              -0.107793   \n",
       "std                 0.128488               0.290454               0.095672   \n",
       "min                -1.000000              -1.000000              -1.000000   \n",
       "25%                -0.328704              -0.700000              -0.125000   \n",
       "50%                -0.252827              -0.500000              -0.100000   \n",
       "75%                -0.186494              -0.300000              -0.050000   \n",
       "max                 0.000000               0.000000               0.000000   \n",
       "\n",
       "       title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "count        29733.000000              29733.000000            29733.000000   \n",
       "mean             0.281878                  0.069691                0.341427   \n",
       "std              0.323461                  0.264379                0.188735   \n",
       "min              0.000000                 -1.000000                0.000000   \n",
       "25%              0.000000                  0.000000                0.166667   \n",
       "50%              0.144444                  0.000000                0.500000   \n",
       "75%              0.500000                  0.136364                0.500000   \n",
       "max              1.000000                  1.000000                0.500000   \n",
       "\n",
       "       abs_title_sentiment_polarity    is_popular    article_id  \n",
       "count                  29733.000000  29733.000000  29733.000000  \n",
       "mean                       0.155234      0.121649  19834.913530  \n",
       "std                        0.225066      0.326886  11432.376037  \n",
       "min                        0.000000      0.000000      1.000000  \n",
       "25%                        0.000000      0.000000   9965.000000  \n",
       "50%                        0.000000      0.000000  19859.000000  \n",
       "75%                        0.250000      0.000000  29742.000000  \n",
       "max                        1.000000      1.000000  39643.000000  \n",
       "\n",
       "[8 rows x 61 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b07d4d81-512a-4e49-9274-457839f87f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training set is 29733 rows, and 61 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The shape of the training set is {train_data.shape[0]} rows, and {train_data.shape[1]} columns.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2e62837-bcf9-4f77-9f5d-cc532454a9dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 0 missing values in the dataset.\n"
     ]
    }
   ],
   "source": [
    "total_missing_values = train_data.isnull().sum()[train_data.isnull().sum() > 0].sum()\n",
    "print(f\"There are a total of {total_missing_values} missing values in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a44f9aa-7c8e-4556-831c-3542bffe08a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timedelta', 'n_tokens_title', 'n_tokens_content', 'n_unique_tokens',\n",
       "       'n_non_stop_words', 'n_non_stop_unique_tokens', 'num_hrefs',\n",
       "       'num_self_hrefs', 'num_imgs', 'num_videos', 'average_token_length',\n",
       "       'num_keywords', 'data_channel_is_lifestyle',\n",
       "       'data_channel_is_entertainment', 'data_channel_is_bus',\n",
       "       'data_channel_is_socmed', 'data_channel_is_tech',\n",
       "       'data_channel_is_world', 'kw_min_min', 'kw_max_min', 'kw_avg_min',\n",
       "       'kw_min_max', 'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg',\n",
       "       'kw_avg_avg', 'self_reference_min_shares', 'self_reference_max_shares',\n",
       "       'self_reference_avg_sharess', 'weekday_is_monday', 'weekday_is_tuesday',\n",
       "       'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday',\n",
       "       'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend', 'LDA_00',\n",
       "       'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity',\n",
       "       'global_sentiment_polarity', 'global_rate_positive_words',\n",
       "       'global_rate_negative_words', 'rate_positive_words',\n",
       "       'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
       "       'max_positive_polarity', 'avg_negative_polarity',\n",
       "       'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity',\n",
       "       'title_sentiment_polarity', 'abs_title_subjectivity',\n",
       "       'abs_title_sentiment_polarity', 'is_popular', 'article_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fade411-c1c4-4598-8e61-0c8d2ea9a087",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54056a3b-786d-45e9-bbc5-df243acf9c73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining variable groups\n",
    "basic_text_features = ['n_tokens_title',\n",
    "                       'n_tokens_content',\n",
    "                       'n_unique_tokens',\n",
    "                       'n_non_stop_words',\n",
    "                       'n_non_stop_unique_tokens',\n",
    "                       'average_token_length',\n",
    "                       'num_keywords']\n",
    "content_properties = ['num_hrefs',\n",
    "                      'num_self_hrefs',\n",
    "                      'num_imgs',\n",
    "                      'num_videos',\n",
    "                      'global_subjectivity',\n",
    "                      'global_sentiment_polarity',\n",
    "                      'global_rate_positive_words',\n",
    "                      'global_rate_negative_words']\n",
    "keyword_performance = ['kw_min_min',\n",
    "                       'kw_max_min',\n",
    "                       'kw_avg_min',\n",
    "                       'kw_min_max',\n",
    "                       'kw_max_max',\n",
    "                       'kw_avg_max',\n",
    "                       'kw_min_avg',\n",
    "                       'kw_max_avg',\n",
    "                       'kw_avg_avg']\n",
    "self_reference_metrics = ['self_reference_min_shares',\n",
    "                          'self_reference_max_shares',\n",
    "                          'self_reference_avg_sharess']\n",
    "\n",
    "# dropped 'weekday_is_monday' and 'is_weekend'\n",
    "publication_timing = ['weekday_is_tuesday',\n",
    "                      'weekday_is_wednesday',\n",
    "                      'weekday_is_thursday',\n",
    "                      'weekday_is_friday',\n",
    "                      'weekday_is_saturday',\n",
    "                      'weekday_is_sunday']\n",
    "\n",
    "# dropped 'data_channel_is_lifestyle'\n",
    "content_topic_and_sentiment = ['data_channel_is_entertainment',\n",
    "                               'data_channel_is_bus',\n",
    "                               'data_channel_is_socmed',\n",
    "                               'data_channel_is_tech',\n",
    "                               'data_channel_is_world',\n",
    "                               'LDA_00',\n",
    "                               'LDA_01',\n",
    "                               'LDA_02',\n",
    "                               'LDA_03',\n",
    "                               'LDA_04',\n",
    "                               'rate_positive_words',\n",
    "                               'rate_negative_words',\n",
    "                               'avg_positive_polarity',\n",
    "                               'min_positive_polarity', \n",
    "                               'max_positive_polarity',\n",
    "                               'avg_negative_polarity',\n",
    "                               'min_negative_polarity',\n",
    "                               'max_negative_polarity']\n",
    "title_sentiment = ['title_subjectivity',\n",
    "                   'title_sentiment_polarity',\n",
    "                   'abs_title_subjectivity',\n",
    "                   'abs_title_sentiment_polarity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b9de3fc-5a7d-4191-824d-820b00ad7120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def square_features(variables, df): \n",
    "    sqaured_features = []\n",
    "    for var in variables:\n",
    "        feature_name = f'{var}_squared'\n",
    "        df[feature_name] = df[var] ** 2\n",
    "        sqaured_features.append(feature_name)\n",
    "    return sqaured_features\n",
    "\n",
    "def cube_features(variables, df): \n",
    "    cubed_features = []\n",
    "    for var in variables:\n",
    "        feature_name = f'{var}_cubed'\n",
    "        df[feature_name] = df[var] ** 3\n",
    "        cubed_features.append(feature_name)\n",
    "    return cubed_features\n",
    "        \n",
    "def interact_features(variables, df):\n",
    "    interacted_features = []\n",
    "    for (var1, var2) in combinations(variables, 2):\n",
    "        feature_name = f'{var1}_{var2}_interaction'\n",
    "        df[feature_name] = df[var1] * df[var2]\n",
    "        interacted_features.append(feature_name)\n",
    "    return interacted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbf2eb71-32a4-4a62-8c66-9331de8e3cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['self_reference_min_shares_self_reference_max_shares_interaction',\n",
       " 'self_reference_min_shares_self_reference_avg_sharess_interaction',\n",
       " 'self_reference_max_shares_self_reference_avg_sharess_interaction']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################SQUARED TERMS###################\n",
    "# square basic features\n",
    "sqrd_basic_text_features = square_features(basic_text_features, train_data)\n",
    "square_features(basic_text_features, test_data)\n",
    "    \n",
    "# square title sentiment features\n",
    "sqrd_title_sentiment = square_features(title_sentiment, train_data)\n",
    "square_features(title_sentiment, test_data)\n",
    "\n",
    "# square content properties\n",
    "sqrd_content_properties = square_features(content_properties, train_data)\n",
    "square_features(content_properties, test_data)\n",
    "\n",
    "# square keyword performance\n",
    "sqrd_keyword_performance = square_features(keyword_performance, train_data)\n",
    "square_features(keyword_performance, test_data)\n",
    "\n",
    "# square self reference metrics\n",
    "sqrd_self_reference_metrics = square_features(self_reference_metrics, train_data)\n",
    "square_features(self_reference_metrics, test_data)\n",
    "\n",
    "##################CUBED TERMS###################\n",
    "# CUBED basic features\n",
    "cube_basic_text_features = cube_features(basic_text_features, train_data)\n",
    "cube_features(basic_text_features, test_data)\n",
    "    \n",
    "# CUBED title sentiment features\n",
    "cube_title_sentiment = cube_features(title_sentiment, train_data)\n",
    "cube_features(title_sentiment, test_data)\n",
    "\n",
    "# CUBED content properties\n",
    "cube_content_properties = cube_features(content_properties, train_data)\n",
    "cube_features(content_properties, test_data)\n",
    "\n",
    "# CUBED keyword performance\n",
    "cube_keyword_performance = cube_features(keyword_performance, train_data)\n",
    "cube_features(keyword_performance, test_data)\n",
    "\n",
    "# CUBED self reference metrics\n",
    "cube_self_reference_metrics = cube_features(self_reference_metrics, train_data)\n",
    "cube_features(self_reference_metrics, test_data)\n",
    "  \n",
    "################INTERACTION TERMS##################\n",
    "# Interacting the basic features\n",
    "interaction_basic_text_features = interact_features(basic_text_features, train_data)\n",
    "interact_features(basic_text_features, test_data)\n",
    "\n",
    "# Interacting the title sentiment features\n",
    "interaction_title_sentiment = interact_features(title_sentiment, train_data)\n",
    "interact_features(title_sentiment, test_data)\n",
    "\n",
    "# Interacting content properties\n",
    "interaction_content_properties = interact_features(content_properties, train_data)\n",
    "interact_features(content_properties, test_data)\n",
    "\n",
    "# Interacting keyword performance\n",
    "interaction_keyword_performance = interact_features(keyword_performance, train_data)\n",
    "interact_features(keyword_performance, test_data)\n",
    "\n",
    "# Interacting self reference metrics\n",
    "interaction_self_reference_metrics = interact_features(self_reference_metrics, train_data)\n",
    "interact_features(self_reference_metrics, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e44e2b7-5e58-49df-91b8-a3d33b6601bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "perm_importance_variables = ['n_tokens_title',\n",
    "                             'n_tokens_content',\n",
    "                             'n_unique_tokens',\n",
    "                             'n_non_stop_words',\n",
    "                             'n_non_stop_unique_tokens',\n",
    "                             'average_token_length',\n",
    "                             'num_keywords',\n",
    "                             'num_hrefs', \n",
    "                             'num_self_hrefs', \n",
    "                             'num_imgs', \n",
    "                             'num_videos', \n",
    "                             'global_subjectivity', \n",
    "                             'global_sentiment_polarity', \n",
    "                             'kw_min_min', \n",
    "                             'kw_max_min', \n",
    "                             'kw_avg_min', \n",
    "                             'kw_min_max', \n",
    "                             'kw_max_max',\n",
    "                             'kw_avg_max', \n",
    "                             'kw_min_avg', \n",
    "                             'kw_max_avg', \n",
    "                             'kw_avg_avg', \n",
    "                             'self_reference_min_shares', \n",
    "                             'self_reference_max_shares', \n",
    "                             'self_reference_avg_sharess',\n",
    "                             'weekday_is_thursday', \n",
    "                             'weekday_is_friday',\n",
    "                             'weekday_is_sunday', \n",
    "                             'data_channel_is_entertainment',\n",
    "                             'data_channel_is_bus', \n",
    "                             'data_channel_is_socmed', \n",
    "                             'data_channel_is_tech', \n",
    "                             'data_channel_is_world', \n",
    "                             'LDA_00', \n",
    "                             'LDA_01',\n",
    "                             'LDA_02', \n",
    "                             'LDA_03', \n",
    "                             'LDA_04', \n",
    "                             'rate_positive_words', \n",
    "                             'avg_positive_polarity',\n",
    "                             'min_positive_polarity', \n",
    "                             'avg_negative_polarity', \n",
    "                             'min_negative_polarity', \n",
    "                             'max_negative_polarity', \n",
    "                             'title_subjectivity',\n",
    "                             'abs_title_subjectivity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be410bba-7dd2-4be0-934a-2af6b6526caf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timedelta', 'n_tokens_title', 'n_tokens_content', 'n_unique_tokens',\n",
       "       'n_non_stop_words', 'n_non_stop_unique_tokens', 'num_hrefs',\n",
       "       'num_self_hrefs', 'num_imgs', 'num_videos',\n",
       "       ...\n",
       "       'kw_max_max_kw_avg_avg_interaction',\n",
       "       'kw_avg_max_kw_min_avg_interaction',\n",
       "       'kw_avg_max_kw_max_avg_interaction',\n",
       "       'kw_avg_max_kw_avg_avg_interaction',\n",
       "       'kw_min_avg_kw_max_avg_interaction',\n",
       "       'kw_min_avg_kw_avg_avg_interaction',\n",
       "       'kw_max_avg_kw_avg_avg_interaction',\n",
       "       'self_reference_min_shares_self_reference_max_shares_interaction',\n",
       "       'self_reference_min_shares_self_reference_avg_sharess_interaction',\n",
       "       'self_reference_max_shares_self_reference_avg_sharess_interaction'],\n",
       "      dtype='object', length=216)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2737b7bf-22eb-464c-9ddc-92f110091051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'M1': basic_text_features,\n",
    "    'M2': basic_text_features + content_properties,\n",
    "    'M3': basic_text_features + content_properties + keyword_performance,\n",
    "    'M4': basic_text_features + content_properties + keyword_performance + self_reference_metrics,\n",
    "    'M5': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing,\n",
    "    'M6': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment,\n",
    "    'M7': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment, \n",
    "    'M8': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + sqrd_title_sentiment,\n",
    "    'M9': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + sqrd_title_sentiment + sqrd_basic_text_features,\n",
    "    'M10': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + sqrd_title_sentiment + sqrd_basic_text_features + interaction_basic_text_features,\n",
    "    'M11': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + sqrd_title_sentiment + sqrd_basic_text_features + interaction_basic_text_features + interaction_title_sentiment,\n",
    "    'M12': perm_importance_variables,\n",
    "    'M13': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + sqrd_content_properties + sqrd_keyword_performance,\n",
    "    'M14': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + sqrd_title_sentiment + sqrd_basic_text_features + sqrd_content_properties,\n",
    "    'M15': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + sqrd_title_sentiment + sqrd_basic_text_features + sqrd_content_properties + sqrd_keyword_performance,\n",
    "    'M16': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + sqrd_title_sentiment + sqrd_basic_text_features + sqrd_content_properties + sqrd_keyword_performance + sqrd_self_reference_metrics,\n",
    "    'M17': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + interaction_content_properties,\n",
    "    'M18': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + interaction_content_properties + interaction_keyword_performance,\n",
    "    'M19': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + interaction_content_properties + interaction_keyword_performance + interaction_self_reference_metrics,\n",
    "    'M20': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + interaction_content_properties + interaction_keyword_performance + interaction_self_reference_metrics + sqrd_title_sentiment + sqrd_basic_text_features + sqrd_content_properties + sqrd_keyword_performance + sqrd_self_reference_metrics,\n",
    "    'M21': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + interaction_content_properties + interaction_basic_text_features + interaction_title_sentiment + interaction_keyword_performance + interaction_self_reference_metrics + sqrd_title_sentiment + sqrd_basic_text_features + sqrd_content_properties + sqrd_keyword_performance + sqrd_self_reference_metrics,\n",
    "    'M22': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + sqrd_title_sentiment + cube_title_sentiment, \n",
    "    'M23': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + sqrd_title_sentiment + cube_title_sentiment + sqrd_basic_text_features + cube_basic_text_features, \n",
    "    'M24': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + sqrd_title_sentiment + cube_title_sentiment + sqrd_basic_text_features + cube_basic_text_features + sqrd_content_properties + cube_content_properties, \n",
    "    'M25': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + sqrd_title_sentiment + cube_title_sentiment + sqrd_basic_text_features + cube_basic_text_features + sqrd_content_properties + cube_content_properties + sqrd_keyword_performance + cube_keyword_performance, \n",
    "    'M26': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + sqrd_title_sentiment + cube_title_sentiment + sqrd_basic_text_features + cube_basic_text_features + sqrd_content_properties + cube_content_properties + sqrd_keyword_performance + cube_keyword_performance + sqrd_self_reference_metrics + cube_self_reference_metrics, \n",
    "    'M27': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + sqrd_title_sentiment + cube_title_sentiment + sqrd_basic_text_features + cube_basic_text_features + sqrd_content_properties + cube_content_properties + sqrd_keyword_performance + cube_keyword_performance + sqrd_self_reference_metrics + cube_self_reference_metrics + interaction_content_properties, \n",
    "    'M28': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + sqrd_title_sentiment + cube_title_sentiment + sqrd_basic_text_features + cube_basic_text_features + sqrd_content_properties + cube_content_properties + sqrd_keyword_performance + cube_keyword_performance + sqrd_self_reference_metrics + cube_self_reference_metrics + interaction_content_properties + interaction_basic_text_features, \n",
    "    'M29': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + sqrd_title_sentiment + cube_title_sentiment + sqrd_basic_text_features + cube_basic_text_features + sqrd_content_properties + cube_content_properties + sqrd_keyword_performance + cube_keyword_performance + sqrd_self_reference_metrics + cube_self_reference_metrics + interaction_content_properties + interaction_basic_text_features + interaction_title_sentiment, \n",
    "    'M30': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + sqrd_title_sentiment + cube_title_sentiment + sqrd_basic_text_features + cube_basic_text_features + sqrd_content_properties + cube_content_properties + sqrd_keyword_performance + cube_keyword_performance + sqrd_self_reference_metrics + cube_self_reference_metrics + interaction_content_properties + interaction_basic_text_features + interaction_title_sentiment + interaction_keyword_performance, \n",
    "    'M31': basic_text_features + content_properties + keyword_performance + self_reference_metrics + publication_timing + content_topic_and_sentiment + title_sentiment + sqrd_title_sentiment + cube_title_sentiment + sqrd_basic_text_features + cube_basic_text_features + sqrd_content_properties + cube_content_properties + sqrd_keyword_performance + cube_keyword_performance + sqrd_self_reference_metrics + cube_self_reference_metrics + interaction_content_properties + interaction_basic_text_features + interaction_title_sentiment + interaction_keyword_performance + interaction_self_reference_metrics \n",
    "\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8862b8ee-e9e5-4001-933b-7c5ebf93dc91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split 'train_data' into training and validation sets\n",
    "X = train_data.drop(['is_popular', 'timedelta', 'article_id'], axis=1)\n",
    "y = train_data['is_popular']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=20240407)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5e9d75-7692-49aa-94ad-ee2f2509baef",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Models\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f67c4ba-37f8-4050-9d98-2e5b1340589d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculateRMSLE(prediction, y_obs):\n",
    "    return round(np.sqrt(\n",
    "        np.mean(\n",
    "            (\n",
    "                np.log(np.where(prediction < 0, 0, prediction) + 1) - \n",
    "                np.log(y_obs + 1)\n",
    "            )**2\n",
    "        )\n",
    "    ), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c5dfe9e-3f83-446c-bc61-0b76563f6bd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initilialize results list\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10d2a2c-a674-41e6-bd84-e8e078e6320d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Logistic Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc2103b-4079-4f67-86b3-3d4f82da990d",
   "metadata": {},
   "source": [
    "### Simple Logistic Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b30b2eb4-a0bc-48e0-b09d-15b9f31a4c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M1 Logistic Regression</td>\n",
       "      <td>0.548108</td>\n",
       "      <td>0.555135</td>\n",
       "      <td>0.2271</td>\n",
       "      <td>0.2314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M2 Logistic Regression</td>\n",
       "      <td>0.624687</td>\n",
       "      <td>0.627810</td>\n",
       "      <td>0.2253</td>\n",
       "      <td>0.2291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M3 Logistic Regression</td>\n",
       "      <td>0.682657</td>\n",
       "      <td>0.686424</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>0.2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M4 Logistic Regression</td>\n",
       "      <td>0.686342</td>\n",
       "      <td>0.688129</td>\n",
       "      <td>0.2224</td>\n",
       "      <td>0.2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M5 Logistic Regression</td>\n",
       "      <td>0.687915</td>\n",
       "      <td>0.684988</td>\n",
       "      <td>0.2223</td>\n",
       "      <td>0.2260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M6 Logistic Regression</td>\n",
       "      <td>0.693311</td>\n",
       "      <td>0.694309</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M7 Logistic Regression</td>\n",
       "      <td>0.694318</td>\n",
       "      <td>0.695099</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.2253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M8 Logistic Regression</td>\n",
       "      <td>0.695176</td>\n",
       "      <td>0.696331</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M9 Logistic Regression</td>\n",
       "      <td>0.695775</td>\n",
       "      <td>0.694353</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M10 Logistic Regression</td>\n",
       "      <td>0.699305</td>\n",
       "      <td>0.693886</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M11 Logistic Regression</td>\n",
       "      <td>0.699465</td>\n",
       "      <td>0.694220</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M12 Logistic Regression</td>\n",
       "      <td>0.692398</td>\n",
       "      <td>0.697022</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>M13 Logistic Regression</td>\n",
       "      <td>0.701580</td>\n",
       "      <td>0.700482</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M14 Logistic Regression</td>\n",
       "      <td>0.695972</td>\n",
       "      <td>0.694173</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>M15 Logistic Regression</td>\n",
       "      <td>0.702613</td>\n",
       "      <td>0.699578</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.2244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>M16 Logistic Regression</td>\n",
       "      <td>0.709128</td>\n",
       "      <td>0.701346</td>\n",
       "      <td>0.2206</td>\n",
       "      <td>0.2247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>M17 Logistic Regression</td>\n",
       "      <td>0.697060</td>\n",
       "      <td>0.688289</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>M18 Logistic Regression</td>\n",
       "      <td>0.703661</td>\n",
       "      <td>0.687535</td>\n",
       "      <td>0.2211</td>\n",
       "      <td>0.2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>M19 Logistic Regression</td>\n",
       "      <td>0.710787</td>\n",
       "      <td>0.688838</td>\n",
       "      <td>0.2205</td>\n",
       "      <td>0.2262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>M20 Logistic Regression</td>\n",
       "      <td>0.716079</td>\n",
       "      <td>0.695409</td>\n",
       "      <td>0.2199</td>\n",
       "      <td>0.2258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>M21 Logistic Regression</td>\n",
       "      <td>0.718754</td>\n",
       "      <td>0.696427</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>M22 Logistic Regression</td>\n",
       "      <td>0.695714</td>\n",
       "      <td>0.696995</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>M23 Logistic Regression</td>\n",
       "      <td>0.697076</td>\n",
       "      <td>0.695949</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>M24 Logistic Regression</td>\n",
       "      <td>0.698787</td>\n",
       "      <td>0.695604</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>M25 Logistic Regression</td>\n",
       "      <td>0.708691</td>\n",
       "      <td>0.705051</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>M26 Logistic Regression</td>\n",
       "      <td>0.715142</td>\n",
       "      <td>0.706303</td>\n",
       "      <td>0.2201</td>\n",
       "      <td>0.2244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>M27 Logistic Regression</td>\n",
       "      <td>0.716938</td>\n",
       "      <td>0.698923</td>\n",
       "      <td>0.2199</td>\n",
       "      <td>0.2253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>M28 Logistic Regression</td>\n",
       "      <td>0.719412</td>\n",
       "      <td>0.698379</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>M29 Logistic Regression</td>\n",
       "      <td>0.719210</td>\n",
       "      <td>0.698091</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>M30 Logistic Regression</td>\n",
       "      <td>0.721592</td>\n",
       "      <td>0.697905</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>M31 Logistic Regression</td>\n",
       "      <td>0.722127</td>\n",
       "      <td>0.697809</td>\n",
       "      <td>0.2194</td>\n",
       "      <td>0.2254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "0    M1 Logistic Regression      0.548108        0.555135          0.2271   \n",
       "1    M2 Logistic Regression      0.624687        0.627810          0.2253   \n",
       "2    M3 Logistic Regression      0.682657        0.686424          0.2225   \n",
       "3    M4 Logistic Regression      0.686342        0.688129          0.2224   \n",
       "4    M5 Logistic Regression      0.687915        0.684988          0.2223   \n",
       "5    M6 Logistic Regression      0.693311        0.694309          0.2220   \n",
       "6    M7 Logistic Regression      0.694318        0.695099          0.2219   \n",
       "7    M8 Logistic Regression      0.695176        0.696331          0.2219   \n",
       "8    M9 Logistic Regression      0.695775        0.694353          0.2218   \n",
       "9   M10 Logistic Regression      0.699305        0.693886          0.2216   \n",
       "10  M11 Logistic Regression      0.699465        0.694220          0.2216   \n",
       "11  M12 Logistic Regression      0.692398        0.697022          0.2220   \n",
       "12  M13 Logistic Regression      0.701580        0.700482          0.2213   \n",
       "13  M14 Logistic Regression      0.695972        0.694173          0.2218   \n",
       "14  M15 Logistic Regression      0.702613        0.699578          0.2212   \n",
       "15  M16 Logistic Regression      0.709128        0.701346          0.2206   \n",
       "16  M17 Logistic Regression      0.697060        0.688289          0.2216   \n",
       "17  M18 Logistic Regression      0.703661        0.687535          0.2211   \n",
       "18  M19 Logistic Regression      0.710787        0.688838          0.2205   \n",
       "19  M20 Logistic Regression      0.716079        0.695409          0.2199   \n",
       "20  M21 Logistic Regression      0.718754        0.696427          0.2197   \n",
       "21  M22 Logistic Regression      0.695714        0.696995          0.2219   \n",
       "22  M23 Logistic Regression      0.697076        0.695949          0.2218   \n",
       "23  M24 Logistic Regression      0.698787        0.695604          0.2216   \n",
       "24  M25 Logistic Regression      0.708691        0.705051          0.2208   \n",
       "25  M26 Logistic Regression      0.715142        0.706303          0.2201   \n",
       "26  M27 Logistic Regression      0.716938        0.698923          0.2199   \n",
       "27  M28 Logistic Regression      0.719412        0.698379          0.2197   \n",
       "28  M29 Logistic Regression      0.719210        0.698091          0.2197   \n",
       "29  M30 Logistic Regression      0.721592        0.697905          0.2195   \n",
       "30  M31 Logistic Regression      0.722127        0.697809          0.2194   \n",
       "\n",
       "    Validation RMSLE  \n",
       "0             0.2314  \n",
       "1             0.2291  \n",
       "2             0.2259  \n",
       "3             0.2259  \n",
       "4             0.2260  \n",
       "5             0.2255  \n",
       "6             0.2253  \n",
       "7             0.2251  \n",
       "8             0.2252  \n",
       "9             0.2251  \n",
       "10            0.2251  \n",
       "11            0.2251  \n",
       "12            0.2245  \n",
       "13            0.2252  \n",
       "14            0.2244  \n",
       "15            0.2247  \n",
       "16            0.2261  \n",
       "17            0.2259  \n",
       "18            0.2262  \n",
       "19            0.2258  \n",
       "20            0.2255  \n",
       "21            0.2251  \n",
       "22            0.2251  \n",
       "23            0.2252  \n",
       "24            0.2240  \n",
       "25            0.2244  \n",
       "26            0.2253  \n",
       "27            0.2252  \n",
       "28            0.2253  \n",
       "29            0.2255  \n",
       "30            0.2254  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model_name, features in models.items():\n",
    "    # Append \"Logistic Regression\" to the model name for clarity\n",
    "    full_model_name = f\"{model_name} Logistic Regression\"\n",
    "\n",
    "    # Define steps for pipeline: feature scaling and logistic regression\n",
    "    steps = [\n",
    "        (\"scale_features\", ColumnTransformer([(\"scale\", StandardScaler(), features)], remainder='drop')),\n",
    "        (\"log_reg\", LogisticRegression())\n",
    "    ]\n",
    "\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # Fit the model on training data\n",
    "    pipeline.fit(X_train[features], y_train)\n",
    "\n",
    "    # Predict probabilities on the training and validation data\n",
    "    # Note: We use predict_proba to get probabilities, and we're interested in the probabilities of the positive class (usually at index 1)\n",
    "    train_prob = pipeline.predict_proba(X_train[features])[:, 1]\n",
    "    val_prob = pipeline.predict_proba(X_val[features])[:, 1]\n",
    "\n",
    "    # Calculate AUC\n",
    "    train_auc = roc_auc_score(y_train, train_prob)\n",
    "    val_auc = roc_auc_score(y_val, val_prob)\n",
    "    \n",
    "    # Calculate RMSLE\n",
    "    train_rmsle = calculateRMSLE(train_prob, y_train)\n",
    "    val_rmsle = calculateRMSLE(val_prob, y_val)\n",
    "\n",
    "    # Append results\n",
    "    results.append([full_model_name, train_auc, val_auc, train_rmsle, val_rmsle])\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "\n",
    "results_df.tail(31)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dcb08f-8c74-4005-896d-cc95dc41a487",
   "metadata": {},
   "source": [
    "### Tuned Logistic Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22c183b2-d23b-4198-a4a3-4b3b9ab16f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed M1 in 0.98 seconds\n",
      "Completed M2 in 1.91 seconds\n",
      "Completed M3 in 4.39 seconds\n",
      "Completed M4 in 4.96 seconds\n",
      "Completed M5 in 6.05 seconds\n",
      "Completed M6 in 10.84 seconds\n",
      "Completed M7 in 12.25 seconds\n",
      "Completed M8 in 17.74 seconds\n",
      "Completed M9 in 25.21 seconds\n",
      "Completed M10 in 111.26 seconds\n",
      "Completed M11 in 91.14 seconds\n",
      "Completed M12 in 8.28 seconds\n",
      "Completed M13 in 31.09 seconds\n",
      "Completed M14 in 29.58 seconds\n",
      "Completed M15 in 45.38 seconds\n",
      "Completed M16 in 44.61 seconds\n",
      "Completed M17 in 28.90 seconds\n",
      "Completed M18 in 73.55 seconds\n",
      "Completed M19 in 80.24 seconds\n",
      "Completed M20 in 187.04 seconds\n",
      "Completed M21 in 341.66 seconds\n",
      "Completed M22 in 22.43 seconds\n",
      "Completed M23 in 37.47 seconds\n",
      "Completed M24 in 60.85 seconds\n",
      "Completed M25 in 88.07 seconds\n",
      "Completed M26 in 106.10 seconds\n",
      "Completed M27 in 141.23 seconds\n",
      "Completed M28 in 263.02 seconds\n",
      "Completed M29 in 358.95 seconds\n",
      "Completed M30 in 408.96 seconds\n",
      "Completed M31 in 436.17 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>M1 Logistic Regression Tuned</td>\n",
       "      <td>0.578511</td>\n",
       "      <td>0.597577</td>\n",
       "      <td>0.2267</td>\n",
       "      <td>0.2305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>M2 Logistic Regression Tuned</td>\n",
       "      <td>0.625409</td>\n",
       "      <td>0.628886</td>\n",
       "      <td>0.2388</td>\n",
       "      <td>0.2415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>M3 Logistic Regression Tuned</td>\n",
       "      <td>0.683566</td>\n",
       "      <td>0.687520</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>0.2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>M4 Logistic Regression Tuned</td>\n",
       "      <td>0.686853</td>\n",
       "      <td>0.688830</td>\n",
       "      <td>0.2224</td>\n",
       "      <td>0.2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>M5 Logistic Regression Tuned</td>\n",
       "      <td>0.688710</td>\n",
       "      <td>0.686084</td>\n",
       "      <td>0.2223</td>\n",
       "      <td>0.2260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>M6 Logistic Regression Tuned</td>\n",
       "      <td>0.693308</td>\n",
       "      <td>0.694601</td>\n",
       "      <td>0.2221</td>\n",
       "      <td>0.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>M7 Logistic Regression Tuned</td>\n",
       "      <td>0.694352</td>\n",
       "      <td>0.695420</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.2253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>M8 Logistic Regression Tuned</td>\n",
       "      <td>0.695495</td>\n",
       "      <td>0.696638</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>M9 Logistic Regression Tuned</td>\n",
       "      <td>0.695925</td>\n",
       "      <td>0.695024</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.2253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>M10 Logistic Regression Tuned</td>\n",
       "      <td>0.699440</td>\n",
       "      <td>0.694135</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>M11 Logistic Regression Tuned</td>\n",
       "      <td>0.698920</td>\n",
       "      <td>0.696317</td>\n",
       "      <td>0.2217</td>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>M12 Logistic Regression Tuned</td>\n",
       "      <td>0.693144</td>\n",
       "      <td>0.698134</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>M13 Logistic Regression Tuned</td>\n",
       "      <td>0.701555</td>\n",
       "      <td>0.701145</td>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.2246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>M14 Logistic Regression Tuned</td>\n",
       "      <td>0.696147</td>\n",
       "      <td>0.694908</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>M15 Logistic Regression Tuned</td>\n",
       "      <td>0.702992</td>\n",
       "      <td>0.700911</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>M16 Logistic Regression Tuned</td>\n",
       "      <td>0.709479</td>\n",
       "      <td>0.702848</td>\n",
       "      <td>0.2207</td>\n",
       "      <td>0.2247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>M17 Logistic Regression Tuned</td>\n",
       "      <td>0.695592</td>\n",
       "      <td>0.691340</td>\n",
       "      <td>0.2227</td>\n",
       "      <td>0.2266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>M18 Logistic Regression Tuned</td>\n",
       "      <td>0.700774</td>\n",
       "      <td>0.694948</td>\n",
       "      <td>0.2223</td>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>M19 Logistic Regression Tuned</td>\n",
       "      <td>0.707631</td>\n",
       "      <td>0.697339</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>M20 Logistic Regression Tuned</td>\n",
       "      <td>0.712031</td>\n",
       "      <td>0.700753</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>M21 Logistic Regression Tuned</td>\n",
       "      <td>0.713567</td>\n",
       "      <td>0.701898</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.2257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>M22 Logistic Regression Tuned</td>\n",
       "      <td>0.695370</td>\n",
       "      <td>0.696867</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>M23 Logistic Regression Tuned</td>\n",
       "      <td>0.696719</td>\n",
       "      <td>0.695677</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>M24 Logistic Regression Tuned</td>\n",
       "      <td>0.698321</td>\n",
       "      <td>0.695671</td>\n",
       "      <td>0.2217</td>\n",
       "      <td>0.2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>M25 Logistic Regression Tuned</td>\n",
       "      <td>0.709057</td>\n",
       "      <td>0.705078</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>M26 Logistic Regression Tuned</td>\n",
       "      <td>0.715581</td>\n",
       "      <td>0.706397</td>\n",
       "      <td>0.2201</td>\n",
       "      <td>0.2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>M27 Logistic Regression Tuned</td>\n",
       "      <td>0.717523</td>\n",
       "      <td>0.699163</td>\n",
       "      <td>0.2198</td>\n",
       "      <td>0.2253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>M28 Logistic Regression Tuned</td>\n",
       "      <td>0.719902</td>\n",
       "      <td>0.699376</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>M29 Logistic Regression Tuned</td>\n",
       "      <td>0.719965</td>\n",
       "      <td>0.699616</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>M30 Logistic Regression Tuned</td>\n",
       "      <td>0.723291</td>\n",
       "      <td>0.699522</td>\n",
       "      <td>0.2192</td>\n",
       "      <td>0.2253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>M31 Logistic Regression Tuned</td>\n",
       "      <td>0.723497</td>\n",
       "      <td>0.699059</td>\n",
       "      <td>0.2192</td>\n",
       "      <td>0.2254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Training AUC  Validation AUC  \\\n",
       "31   M1 Logistic Regression Tuned      0.578511        0.597577   \n",
       "32   M2 Logistic Regression Tuned      0.625409        0.628886   \n",
       "33   M3 Logistic Regression Tuned      0.683566        0.687520   \n",
       "34   M4 Logistic Regression Tuned      0.686853        0.688830   \n",
       "35   M5 Logistic Regression Tuned      0.688710        0.686084   \n",
       "36   M6 Logistic Regression Tuned      0.693308        0.694601   \n",
       "37   M7 Logistic Regression Tuned      0.694352        0.695420   \n",
       "38   M8 Logistic Regression Tuned      0.695495        0.696638   \n",
       "39   M9 Logistic Regression Tuned      0.695925        0.695024   \n",
       "40  M10 Logistic Regression Tuned      0.699440        0.694135   \n",
       "41  M11 Logistic Regression Tuned      0.698920        0.696317   \n",
       "42  M12 Logistic Regression Tuned      0.693144        0.698134   \n",
       "43  M13 Logistic Regression Tuned      0.701555        0.701145   \n",
       "44  M14 Logistic Regression Tuned      0.696147        0.694908   \n",
       "45  M15 Logistic Regression Tuned      0.702992        0.700911   \n",
       "46  M16 Logistic Regression Tuned      0.709479        0.702848   \n",
       "47  M17 Logistic Regression Tuned      0.695592        0.691340   \n",
       "48  M18 Logistic Regression Tuned      0.700774        0.694948   \n",
       "49  M19 Logistic Regression Tuned      0.707631        0.697339   \n",
       "50  M20 Logistic Regression Tuned      0.712031        0.700753   \n",
       "51  M21 Logistic Regression Tuned      0.713567        0.701898   \n",
       "52  M22 Logistic Regression Tuned      0.695370        0.696867   \n",
       "53  M23 Logistic Regression Tuned      0.696719        0.695677   \n",
       "54  M24 Logistic Regression Tuned      0.698321        0.695671   \n",
       "55  M25 Logistic Regression Tuned      0.709057        0.705078   \n",
       "56  M26 Logistic Regression Tuned      0.715581        0.706397   \n",
       "57  M27 Logistic Regression Tuned      0.717523        0.699163   \n",
       "58  M28 Logistic Regression Tuned      0.719902        0.699376   \n",
       "59  M29 Logistic Regression Tuned      0.719965        0.699616   \n",
       "60  M30 Logistic Regression Tuned      0.723291        0.699522   \n",
       "61  M31 Logistic Regression Tuned      0.723497        0.699059   \n",
       "\n",
       "    Training RMSLE  Validation RMSLE  \n",
       "31          0.2267            0.2305  \n",
       "32          0.2388            0.2415  \n",
       "33          0.2225            0.2259  \n",
       "34          0.2224            0.2259  \n",
       "35          0.2223            0.2260  \n",
       "36          0.2221            0.2255  \n",
       "37          0.2220            0.2253  \n",
       "38          0.2219            0.2251  \n",
       "39          0.2219            0.2253  \n",
       "40          0.2216            0.2251  \n",
       "41          0.2217            0.2250  \n",
       "42          0.2220            0.2251  \n",
       "43          0.2214            0.2246  \n",
       "44          0.2218            0.2252  \n",
       "45          0.2213            0.2245  \n",
       "46          0.2207            0.2247  \n",
       "47          0.2227            0.2266  \n",
       "48          0.2223            0.2263  \n",
       "49          0.2216            0.2264  \n",
       "50          0.2213            0.2260  \n",
       "51          0.2212            0.2257  \n",
       "52          0.2220            0.2251  \n",
       "53          0.2219            0.2252  \n",
       "54          0.2217            0.2252  \n",
       "55          0.2208            0.2240  \n",
       "56          0.2201            0.2243  \n",
       "57          0.2198            0.2253  \n",
       "58          0.2196            0.2251  \n",
       "59          0.2196            0.2251  \n",
       "60          0.2192            0.2253  \n",
       "61          0.2192            0.2254  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model_name, features in models.items():\n",
    "\n",
    "    start_time = time.time()\n",
    "    # Define steps for pipeline: feature scaling and logistic regression\n",
    "    steps = [\n",
    "        (\"scale_features\", ColumnTransformer([(\"scale\", StandardScaler(), features)], remainder='drop')),\n",
    "        (\"log_reg\", LogisticRegression(solver='liblinear'))\n",
    "    ]\n",
    "\n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline(steps)\n",
    "\n",
    "    # Define a range of inverse regularization strength `C`\n",
    "    param_grid = {\n",
    "        'log_reg__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'log_reg__penalty': ['l2']  # L2 regularization\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc')\n",
    "    grid_search.fit(X_train[features], y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    train_prob = best_model.predict_proba(X_train[features])[:, 1]\n",
    "    val_prob = best_model.predict_proba(X_val[features])[:, 1]\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, train_prob)\n",
    "    val_auc = roc_auc_score(y_val, val_prob)\n",
    "    \n",
    "    # Calculate RMSLE\n",
    "    train_rmsle = calculateRMSLE(train_prob, y_train)\n",
    "    val_rmsle = calculateRMSLE(val_prob, y_val)\n",
    "\n",
    "    # Append results\n",
    "    results.append([f\"{model_name} Logistic Regression Tuned\", train_auc, val_auc, train_rmsle, val_rmsle])\n",
    "    \n",
    "    end_time = time.time()  # End timer\n",
    "    print(f\"Completed {model_name} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "\n",
    "results_df.tail(31)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d4cc9c-847e-4cf5-9489-42a1a836189a",
   "metadata": {},
   "source": [
    "## Lasso Model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d8aff7a-c8f9-410f-9b69-231748b00629",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed M1 in 0.29 seconds\n",
      "Completed M2 in 0.29 seconds\n",
      "Completed M3 in 0.35 seconds\n",
      "Completed M4 in 0.40 seconds\n",
      "Completed M5 in 0.41 seconds\n",
      "Completed M6 in 1.13 seconds\n",
      "Completed M7 in 1.11 seconds\n",
      "Completed M8 in 1.14 seconds\n",
      "Completed M9 in 1.28 seconds\n",
      "Completed M10 in 1.97 seconds\n",
      "Completed M11 in 2.08 seconds\n",
      "Completed M12 in 0.87 seconds\n",
      "Completed M13 in 1.56 seconds\n",
      "Completed M14 in 1.33 seconds\n",
      "Completed M15 in 1.60 seconds\n",
      "Completed M16 in 1.27 seconds\n",
      "Completed M17 in 1.46 seconds\n",
      "Completed M18 in 2.36 seconds\n",
      "Completed M19 in 2.14 seconds\n",
      "Completed M20 in 3.06 seconds\n",
      "Completed M21 in 3.99 seconds\n",
      "Completed M22 in 1.40 seconds\n",
      "Completed M23 in 1.46 seconds\n",
      "Completed M24 in 1.82 seconds\n",
      "Completed M25 in 2.70 seconds\n",
      "Completed M26 in 2.95 seconds\n",
      "Completed M27 in 3.77 seconds\n",
      "Completed M28 in 4.38 seconds\n",
      "Completed M29 in 4.61 seconds\n",
      "Completed M30 in 5.34 seconds\n",
      "Completed M31 in 5.89 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>M1 Lasso</td>\n",
       "      <td>0.523024</td>\n",
       "      <td>0.531205</td>\n",
       "      <td>0.4853</td>\n",
       "      <td>0.4840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>M2 Lasso</td>\n",
       "      <td>0.589911</td>\n",
       "      <td>0.592422</td>\n",
       "      <td>0.4711</td>\n",
       "      <td>0.4696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>M3 Lasso</td>\n",
       "      <td>0.629210</td>\n",
       "      <td>0.625074</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>0.4643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>M4 Lasso</td>\n",
       "      <td>0.631790</td>\n",
       "      <td>0.629762</td>\n",
       "      <td>0.4620</td>\n",
       "      <td>0.4616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>M5 Lasso</td>\n",
       "      <td>0.635561</td>\n",
       "      <td>0.631840</td>\n",
       "      <td>0.4611</td>\n",
       "      <td>0.4617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>M6 Lasso</td>\n",
       "      <td>0.642905</td>\n",
       "      <td>0.646199</td>\n",
       "      <td>0.4595</td>\n",
       "      <td>0.4580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>M7 Lasso</td>\n",
       "      <td>0.641516</td>\n",
       "      <td>0.654014</td>\n",
       "      <td>0.4598</td>\n",
       "      <td>0.4550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>M8 Lasso</td>\n",
       "      <td>0.642905</td>\n",
       "      <td>0.649153</td>\n",
       "      <td>0.4595</td>\n",
       "      <td>0.4568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>M9 Lasso</td>\n",
       "      <td>0.642508</td>\n",
       "      <td>0.644775</td>\n",
       "      <td>0.4596</td>\n",
       "      <td>0.4582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>M10 Lasso</td>\n",
       "      <td>0.644294</td>\n",
       "      <td>0.643148</td>\n",
       "      <td>0.4592</td>\n",
       "      <td>0.4592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>M11 Lasso</td>\n",
       "      <td>0.645088</td>\n",
       "      <td>0.645429</td>\n",
       "      <td>0.4590</td>\n",
       "      <td>0.4587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>M12 Lasso</td>\n",
       "      <td>0.642707</td>\n",
       "      <td>0.652782</td>\n",
       "      <td>0.4595</td>\n",
       "      <td>0.4550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>M13 Lasso</td>\n",
       "      <td>0.648661</td>\n",
       "      <td>0.646767</td>\n",
       "      <td>0.4582</td>\n",
       "      <td>0.4580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>M14 Lasso</td>\n",
       "      <td>0.643699</td>\n",
       "      <td>0.647354</td>\n",
       "      <td>0.4593</td>\n",
       "      <td>0.4569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>M15 Lasso</td>\n",
       "      <td>0.647669</td>\n",
       "      <td>0.642484</td>\n",
       "      <td>0.4584</td>\n",
       "      <td>0.4593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>M16 Lasso</td>\n",
       "      <td>0.651241</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.4576</td>\n",
       "      <td>0.4571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>M17 Lasso</td>\n",
       "      <td>0.643302</td>\n",
       "      <td>0.649442</td>\n",
       "      <td>0.4594</td>\n",
       "      <td>0.4565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>M18 Lasso</td>\n",
       "      <td>0.643501</td>\n",
       "      <td>0.651839</td>\n",
       "      <td>0.4594</td>\n",
       "      <td>0.4549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>M19 Lasso</td>\n",
       "      <td>0.648264</td>\n",
       "      <td>0.653100</td>\n",
       "      <td>0.4583</td>\n",
       "      <td>0.4532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>M20 Lasso</td>\n",
       "      <td>0.652035</td>\n",
       "      <td>0.644014</td>\n",
       "      <td>0.4575</td>\n",
       "      <td>0.4584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>M21 Lasso</td>\n",
       "      <td>0.653424</td>\n",
       "      <td>0.646786</td>\n",
       "      <td>0.4572</td>\n",
       "      <td>0.4569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>M22 Lasso</td>\n",
       "      <td>0.643302</td>\n",
       "      <td>0.647258</td>\n",
       "      <td>0.4594</td>\n",
       "      <td>0.4570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>M23 Lasso</td>\n",
       "      <td>0.641913</td>\n",
       "      <td>0.645256</td>\n",
       "      <td>0.4597</td>\n",
       "      <td>0.4578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>M24 Lasso</td>\n",
       "      <td>0.642508</td>\n",
       "      <td>0.647450</td>\n",
       "      <td>0.4596</td>\n",
       "      <td>0.4568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>M25 Lasso</td>\n",
       "      <td>0.648463</td>\n",
       "      <td>0.645429</td>\n",
       "      <td>0.4583</td>\n",
       "      <td>0.4587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>M26 Lasso</td>\n",
       "      <td>0.653821</td>\n",
       "      <td>0.648778</td>\n",
       "      <td>0.4571</td>\n",
       "      <td>0.4566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>M27 Lasso</td>\n",
       "      <td>0.652234</td>\n",
       "      <td>0.645342</td>\n",
       "      <td>0.4574</td>\n",
       "      <td>0.4582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>M28 Lasso</td>\n",
       "      <td>0.652829</td>\n",
       "      <td>0.641936</td>\n",
       "      <td>0.4573</td>\n",
       "      <td>0.4582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>M29 Lasso</td>\n",
       "      <td>0.652432</td>\n",
       "      <td>0.642504</td>\n",
       "      <td>0.4574</td>\n",
       "      <td>0.4582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>M30 Lasso</td>\n",
       "      <td>0.653028</td>\n",
       "      <td>0.646401</td>\n",
       "      <td>0.4573</td>\n",
       "      <td>0.4573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>M31 Lasso</td>\n",
       "      <td>0.653226</td>\n",
       "      <td>0.646680</td>\n",
       "      <td>0.4572</td>\n",
       "      <td>0.4575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model  Training AUC  Validation AUC  Training RMSLE  Validation RMSLE\n",
       "62   M1 Lasso      0.523024        0.531205          0.4853            0.4840\n",
       "63   M2 Lasso      0.589911        0.592422          0.4711            0.4696\n",
       "64   M3 Lasso      0.629210        0.625074          0.4625            0.4643\n",
       "65   M4 Lasso      0.631790        0.629762          0.4620            0.4616\n",
       "66   M5 Lasso      0.635561        0.631840          0.4611            0.4617\n",
       "67   M6 Lasso      0.642905        0.646199          0.4595            0.4580\n",
       "68   M7 Lasso      0.641516        0.654014          0.4598            0.4550\n",
       "69   M8 Lasso      0.642905        0.649153          0.4595            0.4568\n",
       "70   M9 Lasso      0.642508        0.644775          0.4596            0.4582\n",
       "71  M10 Lasso      0.644294        0.643148          0.4592            0.4592\n",
       "72  M11 Lasso      0.645088        0.645429          0.4590            0.4587\n",
       "73  M12 Lasso      0.642707        0.652782          0.4595            0.4550\n",
       "74  M13 Lasso      0.648661        0.646767          0.4582            0.4580\n",
       "75  M14 Lasso      0.643699        0.647354          0.4593            0.4569\n",
       "76  M15 Lasso      0.647669        0.642484          0.4584            0.4593\n",
       "77  M16 Lasso      0.651241        0.650000          0.4576            0.4571\n",
       "78  M17 Lasso      0.643302        0.649442          0.4594            0.4565\n",
       "79  M18 Lasso      0.643501        0.651839          0.4594            0.4549\n",
       "80  M19 Lasso      0.648264        0.653100          0.4583            0.4532\n",
       "81  M20 Lasso      0.652035        0.644014          0.4575            0.4584\n",
       "82  M21 Lasso      0.653424        0.646786          0.4572            0.4569\n",
       "83  M22 Lasso      0.643302        0.647258          0.4594            0.4570\n",
       "84  M23 Lasso      0.641913        0.645256          0.4597            0.4578\n",
       "85  M24 Lasso      0.642508        0.647450          0.4596            0.4568\n",
       "86  M25 Lasso      0.648463        0.645429          0.4583            0.4587\n",
       "87  M26 Lasso      0.653821        0.648778          0.4571            0.4566\n",
       "88  M27 Lasso      0.652234        0.645342          0.4574            0.4582\n",
       "89  M28 Lasso      0.652829        0.641936          0.4573            0.4582\n",
       "90  M29 Lasso      0.652432        0.642504          0.4574            0.4582\n",
       "91  M30 Lasso      0.653028        0.646401          0.4573            0.4573\n",
       "92  M31 Lasso      0.653226        0.646680          0.4572            0.4575"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for group_name, features in models.items():\n",
    "    start_time = time.time()  # Start timer\n",
    "\n",
    "    steps = [\n",
    "        (\"scale_features\", ColumnTransformer([(\"scale_numeric_features\", MinMaxScaler(), features)], remainder='drop')),\n",
    "        (\"lasso\", LassoCV())\n",
    "    ]\n",
    "    pipe_lasso = Pipeline(steps)\n",
    "    pipe_lasso.fit(X_train[features], y_train)\n",
    "\n",
    "    train_scores = pipe_lasso.predict(X_train[features])\n",
    "    val_scores = pipe_lasso.predict(X_val[features])\n",
    "\n",
    "    # Convert scores to binary predictions based on the median threshold\n",
    "    threshold = np.median(train_scores)\n",
    "    train_pred = np.where(train_scores > threshold, 1, 0)\n",
    "    val_pred = np.where(val_scores > threshold, 1, 0)\n",
    "\n",
    "    # Calculate AUC scores\n",
    "    train_auc = roc_auc_score(y_train, train_pred)\n",
    "    val_auc = roc_auc_score(y_val, val_pred)\n",
    "    \n",
    "    train_rmsle = calculateRMSLE(train_pred, y_train) \n",
    "    val_rmsle = calculateRMSLE(val_pred, y_val)\n",
    "\n",
    "    new_row = pd.DataFrame([[f\"{group_name} Lasso\", train_auc, val_auc, train_rmsle, val_rmsle]], \n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    end_time = time.time()  # End timer\n",
    "    print(f\"Completed {group_name} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df.tail(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceeb0c7-2024-4301-87fb-ebfc56927fc8",
   "metadata": {},
   "source": [
    "## Stacking Model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f976a2a0-a0ea-424a-9fcc-d6310ec86a4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed M1 in 27.42 seconds\n",
      "Completed M2 in 37.75 seconds\n",
      "Completed M3 in 47.45 seconds\n",
      "Completed M4 in 56.97 seconds\n",
      "Completed M5 in 49.07 seconds\n",
      "Completed M6 in 68.92 seconds\n",
      "Completed M7 in 67.88 seconds\n",
      "Completed M8 in 66.06 seconds\n",
      "Completed M9 in 76.81 seconds\n",
      "Completed M10 in 104.90 seconds\n",
      "Completed M11 in 104.74 seconds\n",
      "Completed M12 in 59.84 seconds\n",
      "Completed M13 in 82.94 seconds\n",
      "Completed M14 in 80.55 seconds\n",
      "Completed M15 in 92.28 seconds\n",
      "Completed M16 in 92.47 seconds\n",
      "Completed M17 in 103.85 seconds\n",
      "Completed M18 in 149.08 seconds\n",
      "Completed M19 in 158.47 seconds\n",
      "Completed M20 in 174.34 seconds\n",
      "Completed M21 in 197.28 seconds\n",
      "Completed M22 in 65.26 seconds\n",
      "Completed M23 in 76.45 seconds\n",
      "Completed M24 in 91.53 seconds\n",
      "Completed M25 in 106.27 seconds\n",
      "Completed M26 in 108.24 seconds\n",
      "Completed M27 in 143.81 seconds\n",
      "Completed M28 in 438.40 seconds\n",
      "Completed M29 in 171.27 seconds\n",
      "Completed M30 in 205.02 seconds\n",
      "Completed M31 in 206.20 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>M1 STACKED</td>\n",
       "      <td>0.999279</td>\n",
       "      <td>0.582803</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>0.2308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>M2 STACKED</td>\n",
       "      <td>0.999535</td>\n",
       "      <td>0.647539</td>\n",
       "      <td>0.1329</td>\n",
       "      <td>0.2291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>M3 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.694660</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>0.2254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>M4 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.701611</td>\n",
       "      <td>0.0851</td>\n",
       "      <td>0.2257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>M5 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704613</td>\n",
       "      <td>0.0814</td>\n",
       "      <td>0.2256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>M6 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714806</td>\n",
       "      <td>0.0774</td>\n",
       "      <td>0.2253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>M7 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.715391</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.2244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>M8 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.716757</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.2244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>M9 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.712760</td>\n",
       "      <td>0.0766</td>\n",
       "      <td>0.2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>M10 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.710793</td>\n",
       "      <td>0.0816</td>\n",
       "      <td>0.2249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>M11 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708077</td>\n",
       "      <td>0.0782</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>M12 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714303</td>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.2244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>M13 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.712307</td>\n",
       "      <td>0.0804</td>\n",
       "      <td>0.2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>M14 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708617</td>\n",
       "      <td>0.0783</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>M15 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.715043</td>\n",
       "      <td>0.0780</td>\n",
       "      <td>0.2245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>M16 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714724</td>\n",
       "      <td>0.0809</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>M17 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707926</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.2258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>M18 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.709377</td>\n",
       "      <td>0.0832</td>\n",
       "      <td>0.2256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>M19 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708620</td>\n",
       "      <td>0.0855</td>\n",
       "      <td>0.2257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>M20 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.717524</td>\n",
       "      <td>0.0840</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>M21 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714015</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>0.2248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>M22 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704769</td>\n",
       "      <td>0.0785</td>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>M23 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714010</td>\n",
       "      <td>0.0798</td>\n",
       "      <td>0.2247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>M24 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.710349</td>\n",
       "      <td>0.0793</td>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>M25 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.718301</td>\n",
       "      <td>0.0807</td>\n",
       "      <td>0.2242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>M26 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.704987</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.2254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>M27 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.708281</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>0.2254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>M28 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.711128</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>0.2245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>M29 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.711505</td>\n",
       "      <td>0.0822</td>\n",
       "      <td>0.2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>M30 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.711104</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.2248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>M31 STACKED</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.713077</td>\n",
       "      <td>0.0811</td>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "93    M1 STACKED      0.999279        0.582803          0.1769   \n",
       "94    M2 STACKED      0.999535        0.647539          0.1329   \n",
       "95    M3 STACKED      1.000000        0.694660          0.0860   \n",
       "96    M4 STACKED      1.000000        0.701611          0.0851   \n",
       "97    M5 STACKED      1.000000        0.704613          0.0814   \n",
       "98    M6 STACKED      1.000000        0.714806          0.0774   \n",
       "99    M7 STACKED      1.000000        0.715391          0.0787   \n",
       "100   M8 STACKED      1.000000        0.716757          0.0797   \n",
       "101   M9 STACKED      1.000000        0.712760          0.0766   \n",
       "102  M10 STACKED      1.000000        0.710793          0.0816   \n",
       "103  M11 STACKED      1.000000        0.708077          0.0782   \n",
       "104  M12 STACKED      1.000000        0.714303          0.0787   \n",
       "105  M13 STACKED      1.000000        0.712307          0.0804   \n",
       "106  M14 STACKED      1.000000        0.708617          0.0783   \n",
       "107  M15 STACKED      1.000000        0.715043          0.0780   \n",
       "108  M16 STACKED      1.000000        0.714724          0.0809   \n",
       "109  M17 STACKED      1.000000        0.707926          0.0800   \n",
       "110  M18 STACKED      1.000000        0.709377          0.0832   \n",
       "111  M19 STACKED      1.000000        0.708620          0.0855   \n",
       "112  M20 STACKED      1.000000        0.717524          0.0840   \n",
       "113  M21 STACKED      1.000000        0.714015          0.0824   \n",
       "114  M22 STACKED      1.000000        0.704769          0.0785   \n",
       "115  M23 STACKED      1.000000        0.714010          0.0798   \n",
       "116  M24 STACKED      1.000000        0.710349          0.0793   \n",
       "117  M25 STACKED      1.000000        0.718301          0.0807   \n",
       "118  M26 STACKED      1.000000        0.704987          0.0812   \n",
       "119  M27 STACKED      1.000000        0.708281          0.0844   \n",
       "120  M28 STACKED      1.000000        0.711128          0.0818   \n",
       "121  M29 STACKED      1.000000        0.711505          0.0822   \n",
       "122  M30 STACKED      1.000000        0.711104          0.0806   \n",
       "123  M31 STACKED      1.000000        0.713077          0.0811   \n",
       "\n",
       "     Validation RMSLE  \n",
       "93             0.2308  \n",
       "94             0.2291  \n",
       "95             0.2254  \n",
       "96             0.2257  \n",
       "97             0.2256  \n",
       "98             0.2253  \n",
       "99             0.2244  \n",
       "100            0.2244  \n",
       "101            0.2252  \n",
       "102            0.2249  \n",
       "103            0.2251  \n",
       "104            0.2244  \n",
       "105            0.2252  \n",
       "106            0.2251  \n",
       "107            0.2245  \n",
       "108            0.2251  \n",
       "109            0.2258  \n",
       "110            0.2256  \n",
       "111            0.2257  \n",
       "112            0.2251  \n",
       "113            0.2248  \n",
       "114            0.2250  \n",
       "115            0.2247  \n",
       "116            0.2250  \n",
       "117            0.2242  \n",
       "118            0.2254  \n",
       "119            0.2254  \n",
       "120            0.2245  \n",
       "121            0.2252  \n",
       "122            0.2248  \n",
       "123            0.2250  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define your base models\n",
    "base_models = [\n",
    "    ('dt', DecisionTreeClassifier(random_state=20240407)),\n",
    "    ('rf', RandomForestClassifier(random_state=20240407)),\n",
    "    ('xgb', xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=20240407))\n",
    "]\n",
    "\n",
    "# Meta-model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Stacking classifier\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "for model_name, features in models.items():\n",
    "    start_time = time.time()  # Start timer\n",
    "    \n",
    "    # Create a pipeline with scaling and stacking model\n",
    "    pipeline = Pipeline([\n",
    "        (\"scale_features\", ColumnTransformer([(\"scale\", StandardScaler(), features)], remainder='drop')),\n",
    "        (\"stacking\", stacking_model)\n",
    "    ])\n",
    "    \n",
    "    # Fit the pipeline\n",
    "    pipeline.fit(X_train[features], y_train)\n",
    "    \n",
    "    # Predict probabilities on the training and validation data\n",
    "    train_prob = pipeline.predict_proba(X_train[features])[:, 1]\n",
    "    val_prob = pipeline.predict_proba(X_val[features])[:, 1]\n",
    "    \n",
    "    # Calculate AUC\n",
    "    train_auc = roc_auc_score(y_train, train_prob)\n",
    "    val_auc = roc_auc_score(y_val, val_prob)\n",
    "    \n",
    "    # Calculate RMSLE\n",
    "    train_rmsle = calculateRMSLE(train_prob, y_train)\n",
    "    val_rmsle = calculateRMSLE(val_prob, y_val)\n",
    "    \n",
    "    # Append results\n",
    "    new_row = pd.DataFrame([[f\"{model_name} STACKED\", train_auc, val_auc, train_rmsle, val_rmsle]], \n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "    \n",
    "    end_time = time.time()  # End timer\n",
    "    print(f\"Completed {model_name} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "results_df.tail(31)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a3f4f8-56ac-483b-8dbf-0bb64ae96f02",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a17cf-b4fa-4096-82dc-bb0a5919ec2d",
   "metadata": {},
   "source": [
    "### Decision Tree Classifer Max Depth 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49202df9-45fb-4893-b0ea-a50cd4f27365",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed M1 in 0.10 seconds\n",
      "Completed M2 in 0.18 seconds\n",
      "Completed M3 in 0.27 seconds\n",
      "Completed M4 in 0.27 seconds\n",
      "Completed M5 in 0.29 seconds\n",
      "Completed M6 in 0.42 seconds\n",
      "Completed M7 in 0.45 seconds\n",
      "Completed M8 in 0.46 seconds\n",
      "Completed M9 in 0.53 seconds\n",
      "Completed M10 in 0.78 seconds\n",
      "Completed M11 in 0.81 seconds\n",
      "Completed M12 in 0.40 seconds\n",
      "Completed M13 in 0.63 seconds\n",
      "Completed M14 in 0.61 seconds\n",
      "Completed M15 in 0.70 seconds\n",
      "Completed M16 in 0.73 seconds\n",
      "Completed M17 in 0.79 seconds\n",
      "Completed M18 in 1.35 seconds\n",
      "Completed M19 in 1.36 seconds\n",
      "Completed M20 in 1.65 seconds\n",
      "Completed M21 in 1.86 seconds\n",
      "Completed M22 in 0.49 seconds\n",
      "Completed M23 in 0.60 seconds\n",
      "Completed M24 in 0.75 seconds\n",
      "Completed M25 in 0.94 seconds\n",
      "Completed M26 in 0.97 seconds\n",
      "Completed M27 in 1.32 seconds\n",
      "Completed M28 in 1.58 seconds\n",
      "Completed M29 in 1.61 seconds\n",
      "Completed M30 in 2.09 seconds\n",
      "Completed M31 in 2.20 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>M1 Decision Tree MD5</td>\n",
       "      <td>0.593985</td>\n",
       "      <td>0.579518</td>\n",
       "      <td>0.2254</td>\n",
       "      <td>0.2309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>M2 Decision Tree MD5</td>\n",
       "      <td>0.645188</td>\n",
       "      <td>0.613544</td>\n",
       "      <td>0.2229</td>\n",
       "      <td>0.2310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>M3 Decision Tree MD5</td>\n",
       "      <td>0.689169</td>\n",
       "      <td>0.681748</td>\n",
       "      <td>0.2207</td>\n",
       "      <td>0.2274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>M4 Decision Tree MD5</td>\n",
       "      <td>0.702222</td>\n",
       "      <td>0.677891</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>M5 Decision Tree MD5</td>\n",
       "      <td>0.702322</td>\n",
       "      <td>0.675899</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>M6 Decision Tree MD5</td>\n",
       "      <td>0.701975</td>\n",
       "      <td>0.673412</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>M7 Decision Tree MD5</td>\n",
       "      <td>0.702134</td>\n",
       "      <td>0.669154</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>M8 Decision Tree MD5</td>\n",
       "      <td>0.702134</td>\n",
       "      <td>0.668961</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>M9 Decision Tree MD5</td>\n",
       "      <td>0.702134</td>\n",
       "      <td>0.669002</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>M10 Decision Tree MD5</td>\n",
       "      <td>0.699318</td>\n",
       "      <td>0.672435</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.2274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>M11 Decision Tree MD5</td>\n",
       "      <td>0.699161</td>\n",
       "      <td>0.671234</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.2279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>M12 Decision Tree MD5</td>\n",
       "      <td>0.701146</td>\n",
       "      <td>0.674605</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>M13 Decision Tree MD5</td>\n",
       "      <td>0.702134</td>\n",
       "      <td>0.669234</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>M14 Decision Tree MD5</td>\n",
       "      <td>0.702134</td>\n",
       "      <td>0.669234</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>M15 Decision Tree MD5</td>\n",
       "      <td>0.702134</td>\n",
       "      <td>0.668961</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>M16 Decision Tree MD5</td>\n",
       "      <td>0.702134</td>\n",
       "      <td>0.668961</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>M17 Decision Tree MD5</td>\n",
       "      <td>0.700275</td>\n",
       "      <td>0.674260</td>\n",
       "      <td>0.2193</td>\n",
       "      <td>0.2286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>M18 Decision Tree MD5</td>\n",
       "      <td>0.700671</td>\n",
       "      <td>0.679698</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.2281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>M19 Decision Tree MD5</td>\n",
       "      <td>0.700671</td>\n",
       "      <td>0.679698</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.2281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>M20 Decision Tree MD5</td>\n",
       "      <td>0.700671</td>\n",
       "      <td>0.679698</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.2281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>M21 Decision Tree MD5</td>\n",
       "      <td>0.700574</td>\n",
       "      <td>0.680021</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.2283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>M22 Decision Tree MD5</td>\n",
       "      <td>0.702134</td>\n",
       "      <td>0.669002</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>M23 Decision Tree MD5</td>\n",
       "      <td>0.702134</td>\n",
       "      <td>0.669002</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>M24 Decision Tree MD5</td>\n",
       "      <td>0.702134</td>\n",
       "      <td>0.669002</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>M25 Decision Tree MD5</td>\n",
       "      <td>0.702134</td>\n",
       "      <td>0.669042</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>M26 Decision Tree MD5</td>\n",
       "      <td>0.702134</td>\n",
       "      <td>0.668961</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>M27 Decision Tree MD5</td>\n",
       "      <td>0.700275</td>\n",
       "      <td>0.674260</td>\n",
       "      <td>0.2193</td>\n",
       "      <td>0.2286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>M28 Decision Tree MD5</td>\n",
       "      <td>0.699245</td>\n",
       "      <td>0.676840</td>\n",
       "      <td>0.2193</td>\n",
       "      <td>0.2283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>M29 Decision Tree MD5</td>\n",
       "      <td>0.698546</td>\n",
       "      <td>0.681102</td>\n",
       "      <td>0.2193</td>\n",
       "      <td>0.2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>M30 Decision Tree MD5</td>\n",
       "      <td>0.700574</td>\n",
       "      <td>0.680021</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.2283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>M31 Decision Tree MD5</td>\n",
       "      <td>0.700574</td>\n",
       "      <td>0.680021</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.2283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "124   M1 Decision Tree MD5      0.593985        0.579518          0.2254   \n",
       "125   M2 Decision Tree MD5      0.645188        0.613544          0.2229   \n",
       "126   M3 Decision Tree MD5      0.689169        0.681748          0.2207   \n",
       "127   M4 Decision Tree MD5      0.702222        0.677891          0.2197   \n",
       "128   M5 Decision Tree MD5      0.702322        0.675899          0.2197   \n",
       "129   M6 Decision Tree MD5      0.701975        0.673412          0.2197   \n",
       "130   M7 Decision Tree MD5      0.702134        0.669154          0.2197   \n",
       "131   M8 Decision Tree MD5      0.702134        0.668961          0.2197   \n",
       "132   M9 Decision Tree MD5      0.702134        0.669002          0.2197   \n",
       "133  M10 Decision Tree MD5      0.699318        0.672435          0.2196   \n",
       "134  M11 Decision Tree MD5      0.699161        0.671234          0.2196   \n",
       "135  M12 Decision Tree MD5      0.701146        0.674605          0.2197   \n",
       "136  M13 Decision Tree MD5      0.702134        0.669234          0.2197   \n",
       "137  M14 Decision Tree MD5      0.702134        0.669234          0.2197   \n",
       "138  M15 Decision Tree MD5      0.702134        0.668961          0.2197   \n",
       "139  M16 Decision Tree MD5      0.702134        0.668961          0.2197   \n",
       "140  M17 Decision Tree MD5      0.700275        0.674260          0.2193   \n",
       "141  M18 Decision Tree MD5      0.700671        0.679698          0.2191   \n",
       "142  M19 Decision Tree MD5      0.700671        0.679698          0.2191   \n",
       "143  M20 Decision Tree MD5      0.700671        0.679698          0.2191   \n",
       "144  M21 Decision Tree MD5      0.700574        0.680021          0.2191   \n",
       "145  M22 Decision Tree MD5      0.702134        0.669002          0.2197   \n",
       "146  M23 Decision Tree MD5      0.702134        0.669002          0.2197   \n",
       "147  M24 Decision Tree MD5      0.702134        0.669002          0.2197   \n",
       "148  M25 Decision Tree MD5      0.702134        0.669042          0.2197   \n",
       "149  M26 Decision Tree MD5      0.702134        0.668961          0.2197   \n",
       "150  M27 Decision Tree MD5      0.700275        0.674260          0.2193   \n",
       "151  M28 Decision Tree MD5      0.699245        0.676840          0.2193   \n",
       "152  M29 Decision Tree MD5      0.698546        0.681102          0.2193   \n",
       "153  M30 Decision Tree MD5      0.700574        0.680021          0.2191   \n",
       "154  M31 Decision Tree MD5      0.700574        0.680021          0.2191   \n",
       "\n",
       "     Validation RMSLE  \n",
       "124            0.2309  \n",
       "125            0.2310  \n",
       "126            0.2274  \n",
       "127            0.2263  \n",
       "128            0.2265  \n",
       "129            0.2268  \n",
       "130            0.2275  \n",
       "131            0.2277  \n",
       "132            0.2275  \n",
       "133            0.2274  \n",
       "134            0.2279  \n",
       "135            0.2270  \n",
       "136            0.2272  \n",
       "137            0.2272  \n",
       "138            0.2277  \n",
       "139            0.2277  \n",
       "140            0.2286  \n",
       "141            0.2281  \n",
       "142            0.2281  \n",
       "143            0.2281  \n",
       "144            0.2283  \n",
       "145            0.2275  \n",
       "146            0.2275  \n",
       "147            0.2275  \n",
       "148            0.2274  \n",
       "149            0.2277  \n",
       "150            0.2286  \n",
       "151            0.2283  \n",
       "152            0.2280  \n",
       "153            0.2283  \n",
       "154            0.2283  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for group_name, features in models.items():\n",
    "    start_time = time.time()  # Start timer\n",
    "    \n",
    "    steps = [\n",
    "        (\"scale_features\", ColumnTransformer([(\"scale_numeric_features\", MinMaxScaler(), features)], remainder='drop')),\n",
    "        (\"tree\", DecisionTreeClassifier(max_depth=5, random_state=20240407))\n",
    "    ]\n",
    "    pipe_tree = Pipeline(steps)\n",
    "\n",
    "    # Fit the model on training data\n",
    "    pipe_tree.fit(X_train[features], y_train)\n",
    "\n",
    "    # Predict probabilities for the positive class\n",
    "    train_prob = pipe_tree.predict_proba(X_train[features])[:, 1]\n",
    "    val_prob = pipe_tree.predict_proba(X_val[features])[:, 1]\n",
    "\n",
    "    # Calculate AUC scores\n",
    "    train_auc = roc_auc_score(y_train, train_prob)\n",
    "    val_auc = roc_auc_score(y_val, val_prob)\n",
    "    \n",
    "    # Calculate RMSLE\n",
    "    train_rmsle = calculateRMSLE(train_prob, y_train)\n",
    "    val_rmsle = calculateRMSLE(val_prob, y_val)\n",
    "\n",
    "    # Append results\n",
    "    new_row = pd.DataFrame([[f\"{group_name} Decision Tree MD5\", train_auc, val_auc, train_rmsle, val_rmsle]], \n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "    \n",
    "    end_time = time.time()  # End timer\n",
    "    print(f\"Completed {group_name} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df.tail(31)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba979487-f9cc-4aae-ad61-e68d1dc0e9d2",
   "metadata": {},
   "source": [
    "### Decision Tree Classifer Max Depth 6\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd7fe38d-609f-4d7b-8f50-50eaaf5c9b26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed M1 in 0.10 seconds\n",
      "Completed M2 in 0.20 seconds\n",
      "Completed M3 in 0.32 seconds\n",
      "Completed M4 in 0.34 seconds\n",
      "Completed M5 in 0.34 seconds\n",
      "Completed M6 in 0.52 seconds\n",
      "Completed M7 in 0.53 seconds\n",
      "Completed M8 in 0.55 seconds\n",
      "Completed M9 in 0.61 seconds\n",
      "Completed M10 in 0.92 seconds\n",
      "Completed M11 in 0.97 seconds\n",
      "Completed M12 in 0.46 seconds\n",
      "Completed M13 in 0.72 seconds\n",
      "Completed M14 in 0.70 seconds\n",
      "Completed M15 in 0.82 seconds\n",
      "Completed M16 in 0.85 seconds\n",
      "Completed M17 in 0.92 seconds\n",
      "Completed M18 in 1.51 seconds\n",
      "Completed M19 in 1.50 seconds\n",
      "Completed M20 in 1.92 seconds\n",
      "Completed M21 in 2.26 seconds\n",
      "Completed M22 in 0.62 seconds\n",
      "Completed M23 in 0.70 seconds\n",
      "Completed M24 in 0.88 seconds\n",
      "Completed M25 in 1.09 seconds\n",
      "Completed M26 in 1.15 seconds\n",
      "Completed M27 in 1.54 seconds\n",
      "Completed M28 in 1.85 seconds\n",
      "Completed M29 in 1.88 seconds\n",
      "Completed M30 in 2.42 seconds\n",
      "Completed M31 in 2.58 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>M1 Decision Tree MD6</td>\n",
       "      <td>0.606142</td>\n",
       "      <td>0.563066</td>\n",
       "      <td>0.2242</td>\n",
       "      <td>0.2322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>M2 Decision Tree MD6</td>\n",
       "      <td>0.659318</td>\n",
       "      <td>0.615339</td>\n",
       "      <td>0.2211</td>\n",
       "      <td>0.2326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>M3 Decision Tree MD6</td>\n",
       "      <td>0.702358</td>\n",
       "      <td>0.683364</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.2288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>M4 Decision Tree MD6</td>\n",
       "      <td>0.715865</td>\n",
       "      <td>0.669937</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.2285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>M5 Decision Tree MD6</td>\n",
       "      <td>0.716589</td>\n",
       "      <td>0.672902</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.2283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>M6 Decision Tree MD6</td>\n",
       "      <td>0.717090</td>\n",
       "      <td>0.670325</td>\n",
       "      <td>0.2172</td>\n",
       "      <td>0.2282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>M7 Decision Tree MD6</td>\n",
       "      <td>0.717947</td>\n",
       "      <td>0.666980</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.2286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>M8 Decision Tree MD6</td>\n",
       "      <td>0.717947</td>\n",
       "      <td>0.666980</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.2286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>M9 Decision Tree MD6</td>\n",
       "      <td>0.717947</td>\n",
       "      <td>0.666983</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.2286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>M10 Decision Tree MD6</td>\n",
       "      <td>0.711630</td>\n",
       "      <td>0.673889</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.2285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>M11 Decision Tree MD6</td>\n",
       "      <td>0.711634</td>\n",
       "      <td>0.675729</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.2285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>M12 Decision Tree MD6</td>\n",
       "      <td>0.715329</td>\n",
       "      <td>0.672186</td>\n",
       "      <td>0.2172</td>\n",
       "      <td>0.2281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>M13 Decision Tree MD6</td>\n",
       "      <td>0.718217</td>\n",
       "      <td>0.665591</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.2287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>M14 Decision Tree MD6</td>\n",
       "      <td>0.718217</td>\n",
       "      <td>0.666726</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.2287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>M15 Decision Tree MD6</td>\n",
       "      <td>0.718217</td>\n",
       "      <td>0.666726</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.2287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>M16 Decision Tree MD6</td>\n",
       "      <td>0.718217</td>\n",
       "      <td>0.667106</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.2283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>M17 Decision Tree MD6</td>\n",
       "      <td>0.714122</td>\n",
       "      <td>0.668302</td>\n",
       "      <td>0.2168</td>\n",
       "      <td>0.2299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>M18 Decision Tree MD6</td>\n",
       "      <td>0.716974</td>\n",
       "      <td>0.673574</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>M19 Decision Tree MD6</td>\n",
       "      <td>0.716974</td>\n",
       "      <td>0.672723</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>M20 Decision Tree MD6</td>\n",
       "      <td>0.716974</td>\n",
       "      <td>0.673623</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>M21 Decision Tree MD6</td>\n",
       "      <td>0.716640</td>\n",
       "      <td>0.672329</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>M22 Decision Tree MD6</td>\n",
       "      <td>0.717947</td>\n",
       "      <td>0.667172</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.2284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>M23 Decision Tree MD6</td>\n",
       "      <td>0.717947</td>\n",
       "      <td>0.666791</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.2287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>M24 Decision Tree MD6</td>\n",
       "      <td>0.718217</td>\n",
       "      <td>0.665591</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.2287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>M25 Decision Tree MD6</td>\n",
       "      <td>0.718217</td>\n",
       "      <td>0.665399</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.2288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>M26 Decision Tree MD6</td>\n",
       "      <td>0.718217</td>\n",
       "      <td>0.665591</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.2287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>M27 Decision Tree MD6</td>\n",
       "      <td>0.714122</td>\n",
       "      <td>0.666611</td>\n",
       "      <td>0.2168</td>\n",
       "      <td>0.2303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>M28 Decision Tree MD6</td>\n",
       "      <td>0.713867</td>\n",
       "      <td>0.668258</td>\n",
       "      <td>0.2168</td>\n",
       "      <td>0.2299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>M29 Decision Tree MD6</td>\n",
       "      <td>0.712036</td>\n",
       "      <td>0.679049</td>\n",
       "      <td>0.2168</td>\n",
       "      <td>0.2289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>M30 Decision Tree MD6</td>\n",
       "      <td>0.716640</td>\n",
       "      <td>0.672216</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>M31 Decision Tree MD6</td>\n",
       "      <td>0.716640</td>\n",
       "      <td>0.672379</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "155   M1 Decision Tree MD6      0.606142        0.563066          0.2242   \n",
       "156   M2 Decision Tree MD6      0.659318        0.615339          0.2211   \n",
       "157   M3 Decision Tree MD6      0.702358        0.683364          0.2188   \n",
       "158   M4 Decision Tree MD6      0.715865        0.669937          0.2173   \n",
       "159   M5 Decision Tree MD6      0.716589        0.672902          0.2173   \n",
       "160   M6 Decision Tree MD6      0.717090        0.670325          0.2172   \n",
       "161   M7 Decision Tree MD6      0.717947        0.666980          0.2174   \n",
       "162   M8 Decision Tree MD6      0.717947        0.666980          0.2174   \n",
       "163   M9 Decision Tree MD6      0.717947        0.666983          0.2174   \n",
       "164  M10 Decision Tree MD6      0.711630        0.673889          0.2175   \n",
       "165  M11 Decision Tree MD6      0.711634        0.675729          0.2174   \n",
       "166  M12 Decision Tree MD6      0.715329        0.672186          0.2172   \n",
       "167  M13 Decision Tree MD6      0.718217        0.665591          0.2173   \n",
       "168  M14 Decision Tree MD6      0.718217        0.666726          0.2173   \n",
       "169  M15 Decision Tree MD6      0.718217        0.666726          0.2173   \n",
       "170  M16 Decision Tree MD6      0.718217        0.667106          0.2173   \n",
       "171  M17 Decision Tree MD6      0.714122        0.668302          0.2168   \n",
       "172  M18 Decision Tree MD6      0.716974        0.673574          0.2164   \n",
       "173  M19 Decision Tree MD6      0.716974        0.672723          0.2164   \n",
       "174  M20 Decision Tree MD6      0.716974        0.673623          0.2164   \n",
       "175  M21 Decision Tree MD6      0.716640        0.672329          0.2164   \n",
       "176  M22 Decision Tree MD6      0.717947        0.667172          0.2174   \n",
       "177  M23 Decision Tree MD6      0.717947        0.666791          0.2174   \n",
       "178  M24 Decision Tree MD6      0.718217        0.665591          0.2173   \n",
       "179  M25 Decision Tree MD6      0.718217        0.665399          0.2173   \n",
       "180  M26 Decision Tree MD6      0.718217        0.665591          0.2173   \n",
       "181  M27 Decision Tree MD6      0.714122        0.666611          0.2168   \n",
       "182  M28 Decision Tree MD6      0.713867        0.668258          0.2168   \n",
       "183  M29 Decision Tree MD6      0.712036        0.679049          0.2168   \n",
       "184  M30 Decision Tree MD6      0.716640        0.672216          0.2164   \n",
       "185  M31 Decision Tree MD6      0.716640        0.672379          0.2164   \n",
       "\n",
       "     Validation RMSLE  \n",
       "155            0.2322  \n",
       "156            0.2326  \n",
       "157            0.2288  \n",
       "158            0.2285  \n",
       "159            0.2283  \n",
       "160            0.2282  \n",
       "161            0.2286  \n",
       "162            0.2286  \n",
       "163            0.2286  \n",
       "164            0.2285  \n",
       "165            0.2285  \n",
       "166            0.2281  \n",
       "167            0.2287  \n",
       "168            0.2287  \n",
       "169            0.2287  \n",
       "170            0.2283  \n",
       "171            0.2299  \n",
       "172            0.2297  \n",
       "173            0.2298  \n",
       "174            0.2296  \n",
       "175            0.2302  \n",
       "176            0.2284  \n",
       "177            0.2287  \n",
       "178            0.2287  \n",
       "179            0.2288  \n",
       "180            0.2287  \n",
       "181            0.2303  \n",
       "182            0.2299  \n",
       "183            0.2289  \n",
       "184            0.2303  \n",
       "185            0.2301  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for group_name, features in models.items():\n",
    "    start_time = time.time()  # Start timer\n",
    "    \n",
    "    steps = [\n",
    "        (\"scale_features\", ColumnTransformer([(\"scale_numeric_features\", MinMaxScaler(), features)], remainder='drop')),\n",
    "        (\"tree\", DecisionTreeClassifier(max_depth=6, random_state=20240407))\n",
    "    ]\n",
    "    pipe_tree = Pipeline(steps)\n",
    "\n",
    "    # Fit the model on training data\n",
    "    pipe_tree.fit(X_train[features], y_train)\n",
    "\n",
    "    # Predict probabilities for the positive class\n",
    "    train_prob = pipe_tree.predict_proba(X_train[features])[:, 1]\n",
    "    val_prob = pipe_tree.predict_proba(X_val[features])[:, 1]\n",
    "\n",
    "    # Calculate AUC scores using the probabilities\n",
    "    train_auc = roc_auc_score(y_train, train_prob)\n",
    "    val_auc = roc_auc_score(y_val, val_prob)\n",
    "\n",
    "    # Calculate RMSLE\n",
    "    train_rmsle = calculateRMSLE(train_prob, y_train)\n",
    "    val_rmsle = calculateRMSLE(val_prob, y_val)\n",
    "\n",
    "    # Append results\n",
    "    new_row = pd.DataFrame([[f\"{group_name} Decision Tree MD6\", train_auc, val_auc, train_rmsle, val_rmsle]], \n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "    \n",
    "    end_time = time.time()  # End timer\n",
    "    print(f\"Completed {group_name} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df.tail(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306d27e3-0612-48ff-8a2a-ef4b0e80736f",
   "metadata": {},
   "source": [
    "### Decision Tree Classifer Max Depth 7\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba6618b7-563a-4edb-95c4-6485c147e40d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed M1 in 0.12 seconds\n",
      "Completed M2 in 0.21 seconds\n",
      "Completed M3 in 0.36 seconds\n",
      "Completed M4 in 0.39 seconds\n",
      "Completed M5 in 0.39 seconds\n",
      "Completed M6 in 0.59 seconds\n",
      "Completed M7 in 0.59 seconds\n",
      "Completed M8 in 0.64 seconds\n",
      "Completed M9 in 0.70 seconds\n",
      "Completed M10 in 1.05 seconds\n",
      "Completed M11 in 1.10 seconds\n",
      "Completed M12 in 0.53 seconds\n",
      "Completed M13 in 0.83 seconds\n",
      "Completed M14 in 0.81 seconds\n",
      "Completed M15 in 0.93 seconds\n",
      "Completed M16 in 0.97 seconds\n",
      "Completed M17 in 1.05 seconds\n",
      "Completed M18 in 1.67 seconds\n",
      "Completed M19 in 1.76 seconds\n",
      "Completed M20 in 2.17 seconds\n",
      "Completed M21 in 2.49 seconds\n",
      "Completed M22 in 0.65 seconds\n",
      "Completed M23 in 0.79 seconds\n",
      "Completed M24 in 1.01 seconds\n",
      "Completed M25 in 1.26 seconds\n",
      "Completed M26 in 1.33 seconds\n",
      "Completed M27 in 1.76 seconds\n",
      "Completed M28 in 2.10 seconds\n",
      "Completed M29 in 2.25 seconds\n",
      "Completed M30 in 2.96 seconds\n",
      "Completed M31 in 2.91 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>M1 Decision Tree MD7</td>\n",
       "      <td>0.618633</td>\n",
       "      <td>0.574762</td>\n",
       "      <td>0.2229</td>\n",
       "      <td>0.2334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>M2 Decision Tree MD7</td>\n",
       "      <td>0.676916</td>\n",
       "      <td>0.621189</td>\n",
       "      <td>0.2183</td>\n",
       "      <td>0.2361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>M3 Decision Tree MD7</td>\n",
       "      <td>0.716705</td>\n",
       "      <td>0.679916</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>0.2296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>M4 Decision Tree MD7</td>\n",
       "      <td>0.731960</td>\n",
       "      <td>0.658502</td>\n",
       "      <td>0.2138</td>\n",
       "      <td>0.2317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>M5 Decision Tree MD7</td>\n",
       "      <td>0.732297</td>\n",
       "      <td>0.660033</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>0.2325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>M6 Decision Tree MD7</td>\n",
       "      <td>0.732842</td>\n",
       "      <td>0.668368</td>\n",
       "      <td>0.2138</td>\n",
       "      <td>0.2314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>M7 Decision Tree MD7</td>\n",
       "      <td>0.734117</td>\n",
       "      <td>0.666903</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>M8 Decision Tree MD7</td>\n",
       "      <td>0.734678</td>\n",
       "      <td>0.667129</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.2310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>M9 Decision Tree MD7</td>\n",
       "      <td>0.734117</td>\n",
       "      <td>0.665766</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.2312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>M10 Decision Tree MD7</td>\n",
       "      <td>0.726670</td>\n",
       "      <td>0.676924</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.2302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>M11 Decision Tree MD7</td>\n",
       "      <td>0.725687</td>\n",
       "      <td>0.675754</td>\n",
       "      <td>0.2141</td>\n",
       "      <td>0.2302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>M12 Decision Tree MD7</td>\n",
       "      <td>0.730659</td>\n",
       "      <td>0.673338</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.2309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>M13 Decision Tree MD7</td>\n",
       "      <td>0.735542</td>\n",
       "      <td>0.660959</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.2317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>M14 Decision Tree MD7</td>\n",
       "      <td>0.734974</td>\n",
       "      <td>0.660638</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.2320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>M15 Decision Tree MD7</td>\n",
       "      <td>0.734974</td>\n",
       "      <td>0.662002</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.2317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>M16 Decision Tree MD7</td>\n",
       "      <td>0.734974</td>\n",
       "      <td>0.662615</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.2310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>M17 Decision Tree MD7</td>\n",
       "      <td>0.728223</td>\n",
       "      <td>0.665090</td>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.2326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>M18 Decision Tree MD7</td>\n",
       "      <td>0.731147</td>\n",
       "      <td>0.669459</td>\n",
       "      <td>0.2124</td>\n",
       "      <td>0.2320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>M19 Decision Tree MD7</td>\n",
       "      <td>0.729218</td>\n",
       "      <td>0.671922</td>\n",
       "      <td>0.2124</td>\n",
       "      <td>0.2319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>M20 Decision Tree MD7</td>\n",
       "      <td>0.729301</td>\n",
       "      <td>0.670441</td>\n",
       "      <td>0.2124</td>\n",
       "      <td>0.2319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>M21 Decision Tree MD7</td>\n",
       "      <td>0.729804</td>\n",
       "      <td>0.666320</td>\n",
       "      <td>0.2122</td>\n",
       "      <td>0.2334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>M22 Decision Tree MD7</td>\n",
       "      <td>0.734117</td>\n",
       "      <td>0.667091</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.2310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>M23 Decision Tree MD7</td>\n",
       "      <td>0.734117</td>\n",
       "      <td>0.666697</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.2314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>M24 Decision Tree MD7</td>\n",
       "      <td>0.734974</td>\n",
       "      <td>0.660912</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.2316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>M25 Decision Tree MD7</td>\n",
       "      <td>0.735542</td>\n",
       "      <td>0.660876</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.2319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>M26 Decision Tree MD7</td>\n",
       "      <td>0.735542</td>\n",
       "      <td>0.660919</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.2317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>M27 Decision Tree MD7</td>\n",
       "      <td>0.728339</td>\n",
       "      <td>0.667062</td>\n",
       "      <td>0.2133</td>\n",
       "      <td>0.2319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>M28 Decision Tree MD7</td>\n",
       "      <td>0.726385</td>\n",
       "      <td>0.669269</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.2332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>M29 Decision Tree MD7</td>\n",
       "      <td>0.725104</td>\n",
       "      <td>0.680026</td>\n",
       "      <td>0.2127</td>\n",
       "      <td>0.2315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>M30 Decision Tree MD7</td>\n",
       "      <td>0.730528</td>\n",
       "      <td>0.667052</td>\n",
       "      <td>0.2123</td>\n",
       "      <td>0.2333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>M31 Decision Tree MD7</td>\n",
       "      <td>0.729804</td>\n",
       "      <td>0.664633</td>\n",
       "      <td>0.2122</td>\n",
       "      <td>0.2340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "186   M1 Decision Tree MD7      0.618633        0.574762          0.2229   \n",
       "187   M2 Decision Tree MD7      0.676916        0.621189          0.2183   \n",
       "188   M3 Decision Tree MD7      0.716705        0.679916          0.2162   \n",
       "189   M4 Decision Tree MD7      0.731960        0.658502          0.2138   \n",
       "190   M5 Decision Tree MD7      0.732297        0.660033          0.2137   \n",
       "191   M6 Decision Tree MD7      0.732842        0.668368          0.2138   \n",
       "192   M7 Decision Tree MD7      0.734117        0.666903          0.2140   \n",
       "193   M8 Decision Tree MD7      0.734678        0.667129          0.2139   \n",
       "194   M9 Decision Tree MD7      0.734117        0.665766          0.2140   \n",
       "195  M10 Decision Tree MD7      0.726670        0.676924          0.2143   \n",
       "196  M11 Decision Tree MD7      0.725687        0.675754          0.2141   \n",
       "197  M12 Decision Tree MD7      0.730659        0.673338          0.2139   \n",
       "198  M13 Decision Tree MD7      0.735542        0.660959          0.2139   \n",
       "199  M14 Decision Tree MD7      0.734974        0.660638          0.2139   \n",
       "200  M15 Decision Tree MD7      0.734974        0.662002          0.2139   \n",
       "201  M16 Decision Tree MD7      0.734974        0.662615          0.2139   \n",
       "202  M17 Decision Tree MD7      0.728223        0.665090          0.2133   \n",
       "203  M18 Decision Tree MD7      0.731147        0.669459          0.2124   \n",
       "204  M19 Decision Tree MD7      0.729218        0.671922          0.2124   \n",
       "205  M20 Decision Tree MD7      0.729301        0.670441          0.2124   \n",
       "206  M21 Decision Tree MD7      0.729804        0.666320          0.2122   \n",
       "207  M22 Decision Tree MD7      0.734117        0.667091          0.2140   \n",
       "208  M23 Decision Tree MD7      0.734117        0.666697          0.2140   \n",
       "209  M24 Decision Tree MD7      0.734974        0.660912          0.2139   \n",
       "210  M25 Decision Tree MD7      0.735542        0.660876          0.2139   \n",
       "211  M26 Decision Tree MD7      0.735542        0.660919          0.2139   \n",
       "212  M27 Decision Tree MD7      0.728339        0.667062          0.2133   \n",
       "213  M28 Decision Tree MD7      0.726385        0.669269          0.2128   \n",
       "214  M29 Decision Tree MD7      0.725104        0.680026          0.2127   \n",
       "215  M30 Decision Tree MD7      0.730528        0.667052          0.2123   \n",
       "216  M31 Decision Tree MD7      0.729804        0.664633          0.2122   \n",
       "\n",
       "     Validation RMSLE  \n",
       "186            0.2334  \n",
       "187            0.2361  \n",
       "188            0.2296  \n",
       "189            0.2317  \n",
       "190            0.2325  \n",
       "191            0.2314  \n",
       "192            0.2311  \n",
       "193            0.2310  \n",
       "194            0.2312  \n",
       "195            0.2302  \n",
       "196            0.2302  \n",
       "197            0.2309  \n",
       "198            0.2317  \n",
       "199            0.2320  \n",
       "200            0.2317  \n",
       "201            0.2310  \n",
       "202            0.2326  \n",
       "203            0.2320  \n",
       "204            0.2319  \n",
       "205            0.2319  \n",
       "206            0.2334  \n",
       "207            0.2310  \n",
       "208            0.2314  \n",
       "209            0.2316  \n",
       "210            0.2319  \n",
       "211            0.2317  \n",
       "212            0.2319  \n",
       "213            0.2332  \n",
       "214            0.2315  \n",
       "215            0.2333  \n",
       "216            0.2340  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for group_name, features in models.items():\n",
    "    start_time = time.time()  # Start timer\n",
    "    \n",
    "    steps = [\n",
    "        (\"scale_features\", ColumnTransformer([(\"scale_numeric_features\", MinMaxScaler(), features)], remainder='drop')),\n",
    "        (\"tree\", DecisionTreeClassifier(max_depth=7, random_state=20240407))\n",
    "    ]\n",
    "    pipe_tree = Pipeline(steps)\n",
    "\n",
    "    # Fit the model on training data\n",
    "    pipe_tree.fit(X_train[features], y_train)\n",
    "\n",
    "    # Predict probabilities for the positive class\n",
    "    train_prob = pipe_tree.predict_proba(X_train[features])[:, 1]\n",
    "    val_prob = pipe_tree.predict_proba(X_val[features])[:, 1]\n",
    "\n",
    "    # Calculate AUC scores using the probabilities\n",
    "    train_auc = roc_auc_score(y_train, train_prob)\n",
    "    val_auc = roc_auc_score(y_val, val_prob)\n",
    "\n",
    "    # Calculate RMSLE\n",
    "    train_rmsle = calculateRMSLE(train_prob, y_train)\n",
    "    val_rmsle = calculateRMSLE(val_prob, y_val)\n",
    "\n",
    "    # Append results\n",
    "    new_row = pd.DataFrame([[f\"{group_name} Decision Tree MD7\", train_auc, val_auc, train_rmsle, val_rmsle]], \n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "    \n",
    "    end_time = time.time()  # End timer\n",
    "    print(f\"Completed {group_name} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df.tail(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9715ab5-3daa-46cc-9432-fcec6edd2462",
   "metadata": {},
   "source": [
    "### Decision Tree Classifer Grid Search\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c2e04bf-e77b-4458-aa04-3b3c24cadba2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed M1 with best max_depth=7 in 5.48 seconds\n",
      "Completed M2 with best max_depth=5 in 1.02 seconds\n",
      "Completed M3 with best max_depth=4 in 1.30 seconds\n",
      "Completed M4 with best max_depth=5 in 1.51 seconds\n",
      "Completed M5 with best max_depth=5 in 1.57 seconds\n",
      "Completed M6 with best max_depth=4 in 2.19 seconds\n",
      "Completed M7 with best max_depth=4 in 2.31 seconds\n",
      "Completed M8 with best max_depth=4 in 2.44 seconds\n",
      "Completed M9 with best max_depth=4 in 2.69 seconds\n",
      "Completed M10 with best max_depth=5 in 4.27 seconds\n",
      "Completed M11 with best max_depth=5 in 4.52 seconds\n",
      "Completed M12 with best max_depth=4 in 2.01 seconds\n",
      "Completed M13 with best max_depth=4 in 3.25 seconds\n",
      "Completed M14 with best max_depth=4 in 3.17 seconds\n",
      "Completed M15 with best max_depth=4 in 3.55 seconds\n",
      "Completed M16 with best max_depth=4 in 3.77 seconds\n",
      "Completed M17 with best max_depth=3 in 3.89 seconds\n",
      "Completed M18 with best max_depth=5 in 6.64 seconds\n",
      "Completed M19 with best max_depth=3 in 6.39 seconds\n",
      "Completed M20 with best max_depth=4 in 8.51 seconds\n",
      "Completed M21 with best max_depth=3 in 9.25 seconds\n",
      "Completed M22 with best max_depth=4 in 2.67 seconds\n",
      "Completed M23 with best max_depth=4 in 3.21 seconds\n",
      "Completed M24 with best max_depth=4 in 4.23 seconds\n",
      "Completed M25 with best max_depth=4 in 4.97 seconds\n",
      "Completed M26 with best max_depth=4 in 5.58 seconds\n",
      "Completed M27 with best max_depth=3 in 6.80 seconds\n",
      "Completed M28 with best max_depth=5 in 8.84 seconds\n",
      "Completed M29 with best max_depth=5 in 8.87 seconds\n",
      "Completed M30 with best max_depth=3 in 10.53 seconds\n",
      "Completed M31 with best max_depth=3 in 10.65 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>M1 Decision Tree Grid Search</td>\n",
       "      <td>0.618633</td>\n",
       "      <td>0.574762</td>\n",
       "      <td>0.2229</td>\n",
       "      <td>0.2334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>M2 Decision Tree Grid Search</td>\n",
       "      <td>0.645188</td>\n",
       "      <td>0.613544</td>\n",
       "      <td>0.2229</td>\n",
       "      <td>0.2310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>M3 Decision Tree Grid Search</td>\n",
       "      <td>0.677494</td>\n",
       "      <td>0.677595</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.2268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>M4 Decision Tree Grid Search</td>\n",
       "      <td>0.702222</td>\n",
       "      <td>0.677891</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>M5 Decision Tree Grid Search</td>\n",
       "      <td>0.702322</td>\n",
       "      <td>0.675899</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>M6 Decision Tree Grid Search</td>\n",
       "      <td>0.688481</td>\n",
       "      <td>0.671874</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.2271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>M7 Decision Tree Grid Search</td>\n",
       "      <td>0.688161</td>\n",
       "      <td>0.671863</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.2272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>M8 Decision Tree Grid Search</td>\n",
       "      <td>0.688161</td>\n",
       "      <td>0.671863</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.2272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>M9 Decision Tree Grid Search</td>\n",
       "      <td>0.688161</td>\n",
       "      <td>0.671863</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.2272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>M10 Decision Tree Grid Search</td>\n",
       "      <td>0.699318</td>\n",
       "      <td>0.672435</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.2274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>M11 Decision Tree Grid Search</td>\n",
       "      <td>0.699161</td>\n",
       "      <td>0.671234</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.2279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>M12 Decision Tree Grid Search</td>\n",
       "      <td>0.688481</td>\n",
       "      <td>0.671874</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.2271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>M13 Decision Tree Grid Search</td>\n",
       "      <td>0.688161</td>\n",
       "      <td>0.671863</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.2272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>M14 Decision Tree Grid Search</td>\n",
       "      <td>0.688161</td>\n",
       "      <td>0.671863</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.2272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>M15 Decision Tree Grid Search</td>\n",
       "      <td>0.688161</td>\n",
       "      <td>0.671863</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.2272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>M16 Decision Tree Grid Search</td>\n",
       "      <td>0.688161</td>\n",
       "      <td>0.671863</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.2272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>M17 Decision Tree Grid Search</td>\n",
       "      <td>0.678634</td>\n",
       "      <td>0.673502</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.2271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>M18 Decision Tree Grid Search</td>\n",
       "      <td>0.700671</td>\n",
       "      <td>0.679698</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.2281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>M19 Decision Tree Grid Search</td>\n",
       "      <td>0.678560</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.2270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>M20 Decision Tree Grid Search</td>\n",
       "      <td>0.690074</td>\n",
       "      <td>0.683425</td>\n",
       "      <td>0.2209</td>\n",
       "      <td>0.2271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>M21 Decision Tree Grid Search</td>\n",
       "      <td>0.678560</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.2270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>M22 Decision Tree Grid Search</td>\n",
       "      <td>0.688161</td>\n",
       "      <td>0.671863</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.2272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>M23 Decision Tree Grid Search</td>\n",
       "      <td>0.688161</td>\n",
       "      <td>0.671863</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.2272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>M24 Decision Tree Grid Search</td>\n",
       "      <td>0.688161</td>\n",
       "      <td>0.671863</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.2272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>M25 Decision Tree Grid Search</td>\n",
       "      <td>0.688161</td>\n",
       "      <td>0.671863</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.2272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>M26 Decision Tree Grid Search</td>\n",
       "      <td>0.688161</td>\n",
       "      <td>0.671863</td>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.2272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>M27 Decision Tree Grid Search</td>\n",
       "      <td>0.678634</td>\n",
       "      <td>0.673502</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.2271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>M28 Decision Tree Grid Search</td>\n",
       "      <td>0.699245</td>\n",
       "      <td>0.676840</td>\n",
       "      <td>0.2193</td>\n",
       "      <td>0.2283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>M29 Decision Tree Grid Search</td>\n",
       "      <td>0.698546</td>\n",
       "      <td>0.681102</td>\n",
       "      <td>0.2193</td>\n",
       "      <td>0.2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>M30 Decision Tree Grid Search</td>\n",
       "      <td>0.678560</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.2270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>M31 Decision Tree Grid Search</td>\n",
       "      <td>0.678560</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.2270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  Training AUC  Validation AUC  \\\n",
       "217   M1 Decision Tree Grid Search      0.618633        0.574762   \n",
       "218   M2 Decision Tree Grid Search      0.645188        0.613544   \n",
       "219   M3 Decision Tree Grid Search      0.677494        0.677595   \n",
       "220   M4 Decision Tree Grid Search      0.702222        0.677891   \n",
       "221   M5 Decision Tree Grid Search      0.702322        0.675899   \n",
       "222   M6 Decision Tree Grid Search      0.688481        0.671874   \n",
       "223   M7 Decision Tree Grid Search      0.688161        0.671863   \n",
       "224   M8 Decision Tree Grid Search      0.688161        0.671863   \n",
       "225   M9 Decision Tree Grid Search      0.688161        0.671863   \n",
       "226  M10 Decision Tree Grid Search      0.699318        0.672435   \n",
       "227  M11 Decision Tree Grid Search      0.699161        0.671234   \n",
       "228  M12 Decision Tree Grid Search      0.688481        0.671874   \n",
       "229  M13 Decision Tree Grid Search      0.688161        0.671863   \n",
       "230  M14 Decision Tree Grid Search      0.688161        0.671863   \n",
       "231  M15 Decision Tree Grid Search      0.688161        0.671863   \n",
       "232  M16 Decision Tree Grid Search      0.688161        0.671863   \n",
       "233  M17 Decision Tree Grid Search      0.678634        0.673502   \n",
       "234  M18 Decision Tree Grid Search      0.700671        0.679698   \n",
       "235  M19 Decision Tree Grid Search      0.678560        0.673000   \n",
       "236  M20 Decision Tree Grid Search      0.690074        0.683425   \n",
       "237  M21 Decision Tree Grid Search      0.678560        0.673000   \n",
       "238  M22 Decision Tree Grid Search      0.688161        0.671863   \n",
       "239  M23 Decision Tree Grid Search      0.688161        0.671863   \n",
       "240  M24 Decision Tree Grid Search      0.688161        0.671863   \n",
       "241  M25 Decision Tree Grid Search      0.688161        0.671863   \n",
       "242  M26 Decision Tree Grid Search      0.688161        0.671863   \n",
       "243  M27 Decision Tree Grid Search      0.678634        0.673502   \n",
       "244  M28 Decision Tree Grid Search      0.699245        0.676840   \n",
       "245  M29 Decision Tree Grid Search      0.698546        0.681102   \n",
       "246  M30 Decision Tree Grid Search      0.678560        0.673000   \n",
       "247  M31 Decision Tree Grid Search      0.678560        0.673000   \n",
       "\n",
       "     Training RMSLE  Validation RMSLE  \n",
       "217          0.2229            0.2334  \n",
       "218          0.2229            0.2310  \n",
       "219          0.2219            0.2268  \n",
       "220          0.2197            0.2263  \n",
       "221          0.2197            0.2265  \n",
       "222          0.2212            0.2271  \n",
       "223          0.2212            0.2272  \n",
       "224          0.2212            0.2272  \n",
       "225          0.2212            0.2272  \n",
       "226          0.2196            0.2274  \n",
       "227          0.2196            0.2279  \n",
       "228          0.2212            0.2271  \n",
       "229          0.2212            0.2272  \n",
       "230          0.2212            0.2272  \n",
       "231          0.2212            0.2272  \n",
       "232          0.2212            0.2272  \n",
       "233          0.2219            0.2271  \n",
       "234          0.2191            0.2281  \n",
       "235          0.2219            0.2270  \n",
       "236          0.2209            0.2271  \n",
       "237          0.2219            0.2270  \n",
       "238          0.2212            0.2272  \n",
       "239          0.2212            0.2272  \n",
       "240          0.2212            0.2272  \n",
       "241          0.2212            0.2272  \n",
       "242          0.2212            0.2272  \n",
       "243          0.2219            0.2271  \n",
       "244          0.2193            0.2283  \n",
       "245          0.2193            0.2280  \n",
       "246          0.2219            0.2270  \n",
       "247          0.2219            0.2270  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for group_name, features in models.items():\n",
    "    start_time = time.time()  # Start timer\n",
    "    \n",
    "    # Define the steps of the pipeline\n",
    "    steps = [\n",
    "        (\"scale_features\", ColumnTransformer([(\"scale_numeric_features\", MinMaxScaler(), features)], remainder='drop')),\n",
    "        (\"tree\", DecisionTreeClassifier(random_state=20240407))\n",
    "    ]\n",
    "    pipe_tree = Pipeline(steps)\n",
    "    \n",
    "    # Define the parameter grid to search over\n",
    "    param_grid = {\n",
    "        \"tree__max_depth\": range(3, 9) \n",
    "    }\n",
    "    \n",
    "    # Initialize GridSearchCV\n",
    "    grid_search = GridSearchCV(pipe_tree, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    # Fit the model on training data\n",
    "    grid_search.fit(X_train[features], y_train)\n",
    "    \n",
    "    # Best model after grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Predict probabilities for the positive class with the best model\n",
    "    train_prob = best_model.predict_proba(X_train[features])[:, 1]\n",
    "    val_prob = best_model.predict_proba(X_val[features])[:, 1]\n",
    "\n",
    "    # Calculate AUC scores using the probabilities\n",
    "    train_auc = roc_auc_score(y_train, train_prob)\n",
    "    val_auc = roc_auc_score(y_val, val_prob)\n",
    "\n",
    "    # Calculate RMSLE\n",
    "    train_rmsle = calculateRMSLE(train_prob, y_train)\n",
    "    val_rmsle = calculateRMSLE(val_prob, y_val)\n",
    "\n",
    "    # Append results\n",
    "    best_depth = best_model.named_steps['tree'].max_depth\n",
    "    new_row = pd.DataFrame([[f\"{group_name} Decision Tree Grid Search\", train_auc, val_auc, train_rmsle, val_rmsle]], \n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "    \n",
    "    end_time = time.time()  # End timer\n",
    "    print(f\"Completed {group_name} with best max_depth={best_depth} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df.tail(31)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9357f0-e591-4fd6-884d-9158a6ab6321",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bdd91c4-1da4-4267-92a4-aad41ccf1ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed M1 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 100} in 17.49 seconds\n",
      "Completed M2 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 4, 'random_forest__n_estimators': 100} in 23.53 seconds\n",
      "Completed M3 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 100} in 31.09 seconds\n",
      "Completed M4 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 100} in 36.96 seconds\n",
      "Completed M5 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 100} in 32.57 seconds\n",
      "Completed M6 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 100} in 43.04 seconds\n",
      "Completed M7 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 100} in 42.59 seconds\n",
      "Completed M8 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 4, 'random_forest__n_estimators': 100} in 41.54 seconds\n",
      "Completed M9 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 100} in 47.13 seconds\n",
      "Completed M10 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 100} in 60.64 seconds\n",
      "Completed M11 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 100} in 61.48 seconds\n",
      "Completed M12 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 100} in 40.40 seconds\n",
      "Completed M13 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 4, 'random_forest__n_estimators': 100} in 50.61 seconds\n",
      "Completed M14 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 4, 'random_forest__n_estimators': 100} in 49.37 seconds\n",
      "Completed M15 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 4, 'random_forest__n_estimators': 100} in 56.47 seconds\n",
      "Completed M16 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 4, 'random_forest__n_estimators': 100} in 55.60 seconds\n",
      "Completed M17 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 100} in 63.90 seconds\n",
      "Completed M18 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 100} in 79.08 seconds\n",
      "Completed M19 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 100} in 85.83 seconds\n",
      "Completed M20 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 4, 'random_forest__n_estimators': 100} in 92.56 seconds\n",
      "Completed M21 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 100} in 103.58 seconds\n",
      "Completed M22 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 100} in 40.73 seconds\n",
      "Completed M23 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 4, 'random_forest__n_estimators': 100} in 47.14 seconds\n",
      "Completed M24 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 4, 'random_forest__n_estimators': 100} in 56.03 seconds\n",
      "Completed M25 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 4, 'random_forest__n_estimators': 100} in 63.60 seconds\n",
      "Completed M26 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 4, 'random_forest__n_estimators': 100} in 63.69 seconds\n",
      "Completed M27 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 4, 'random_forest__n_estimators': 100} in 82.93 seconds\n",
      "Completed M28 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 4, 'random_forest__n_estimators': 100} in 88.33 seconds\n",
      "Completed M29 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 4, 'random_forest__n_estimators': 100} in 94.43 seconds\n",
      "Completed M30 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 100} in 109.03 seconds\n",
      "Completed M31 with best parameters {'random_forest__max_depth': 7, 'random_forest__min_samples_split': 2, 'random_forest__n_estimators': 100} in 109.70 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>M1 Random Forest</td>\n",
       "      <td>0.692130</td>\n",
       "      <td>0.603921</td>\n",
       "      <td>0.2215</td>\n",
       "      <td>0.2301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>M2 Random Forest</td>\n",
       "      <td>0.733817</td>\n",
       "      <td>0.656886</td>\n",
       "      <td>0.2172</td>\n",
       "      <td>0.2279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>M3 Random Forest</td>\n",
       "      <td>0.774158</td>\n",
       "      <td>0.708519</td>\n",
       "      <td>0.2132</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>M4 Random Forest</td>\n",
       "      <td>0.782287</td>\n",
       "      <td>0.711795</td>\n",
       "      <td>0.2109</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>M5 Random Forest</td>\n",
       "      <td>0.781630</td>\n",
       "      <td>0.712681</td>\n",
       "      <td>0.2114</td>\n",
       "      <td>0.2242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>M6 Random Forest</td>\n",
       "      <td>0.792354</td>\n",
       "      <td>0.714636</td>\n",
       "      <td>0.2109</td>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>M7 Random Forest</td>\n",
       "      <td>0.792197</td>\n",
       "      <td>0.715297</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>M8 Random Forest</td>\n",
       "      <td>0.791399</td>\n",
       "      <td>0.713278</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>M9 Random Forest</td>\n",
       "      <td>0.795269</td>\n",
       "      <td>0.714616</td>\n",
       "      <td>0.2106</td>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>M10 Random Forest</td>\n",
       "      <td>0.795790</td>\n",
       "      <td>0.715590</td>\n",
       "      <td>0.2104</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>M11 Random Forest</td>\n",
       "      <td>0.793728</td>\n",
       "      <td>0.717255</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>M12 Random Forest</td>\n",
       "      <td>0.794477</td>\n",
       "      <td>0.714816</td>\n",
       "      <td>0.2108</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>M13 Random Forest</td>\n",
       "      <td>0.792061</td>\n",
       "      <td>0.713364</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>M14 Random Forest</td>\n",
       "      <td>0.794005</td>\n",
       "      <td>0.715745</td>\n",
       "      <td>0.2107</td>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>M15 Random Forest</td>\n",
       "      <td>0.792506</td>\n",
       "      <td>0.716487</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>M16 Random Forest</td>\n",
       "      <td>0.792441</td>\n",
       "      <td>0.713936</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>M17 Random Forest</td>\n",
       "      <td>0.793682</td>\n",
       "      <td>0.713212</td>\n",
       "      <td>0.2101</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>M18 Random Forest</td>\n",
       "      <td>0.793187</td>\n",
       "      <td>0.714930</td>\n",
       "      <td>0.2094</td>\n",
       "      <td>0.2237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>M19 Random Forest</td>\n",
       "      <td>0.792326</td>\n",
       "      <td>0.715411</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>M20 Random Forest</td>\n",
       "      <td>0.791841</td>\n",
       "      <td>0.714108</td>\n",
       "      <td>0.2089</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>M21 Random Forest</td>\n",
       "      <td>0.793415</td>\n",
       "      <td>0.717114</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.2236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>M22 Random Forest</td>\n",
       "      <td>0.794812</td>\n",
       "      <td>0.714967</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>M23 Random Forest</td>\n",
       "      <td>0.795248</td>\n",
       "      <td>0.712613</td>\n",
       "      <td>0.2112</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>M24 Random Forest</td>\n",
       "      <td>0.796912</td>\n",
       "      <td>0.710943</td>\n",
       "      <td>0.2103</td>\n",
       "      <td>0.2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>M25 Random Forest</td>\n",
       "      <td>0.796458</td>\n",
       "      <td>0.715752</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>M26 Random Forest</td>\n",
       "      <td>0.788110</td>\n",
       "      <td>0.713519</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>M27 Random Forest</td>\n",
       "      <td>0.790270</td>\n",
       "      <td>0.714281</td>\n",
       "      <td>0.2095</td>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>M28 Random Forest</td>\n",
       "      <td>0.791918</td>\n",
       "      <td>0.711802</td>\n",
       "      <td>0.2093</td>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>M29 Random Forest</td>\n",
       "      <td>0.793466</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.2093</td>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>M30 Random Forest</td>\n",
       "      <td>0.794712</td>\n",
       "      <td>0.713761</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>M31 Random Forest</td>\n",
       "      <td>0.793070</td>\n",
       "      <td>0.713840</td>\n",
       "      <td>0.2086</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "248   M1 Random Forest      0.692130        0.603921          0.2215   \n",
       "249   M2 Random Forest      0.733817        0.656886          0.2172   \n",
       "250   M3 Random Forest      0.774158        0.708519          0.2132   \n",
       "251   M4 Random Forest      0.782287        0.711795          0.2109   \n",
       "252   M5 Random Forest      0.781630        0.712681          0.2114   \n",
       "253   M6 Random Forest      0.792354        0.714636          0.2109   \n",
       "254   M7 Random Forest      0.792197        0.715297          0.2110   \n",
       "255   M8 Random Forest      0.791399        0.713278          0.2111   \n",
       "256   M9 Random Forest      0.795269        0.714616          0.2106   \n",
       "257  M10 Random Forest      0.795790        0.715590          0.2104   \n",
       "258  M11 Random Forest      0.793728        0.717255          0.2105   \n",
       "259  M12 Random Forest      0.794477        0.714816          0.2108   \n",
       "260  M13 Random Forest      0.792061        0.713364          0.2105   \n",
       "261  M14 Random Forest      0.794005        0.715745          0.2107   \n",
       "262  M15 Random Forest      0.792506        0.716487          0.2105   \n",
       "263  M16 Random Forest      0.792441        0.713936          0.2100   \n",
       "264  M17 Random Forest      0.793682        0.713212          0.2101   \n",
       "265  M18 Random Forest      0.793187        0.714930          0.2094   \n",
       "266  M19 Random Forest      0.792326        0.715411          0.2090   \n",
       "267  M20 Random Forest      0.791841        0.714108          0.2089   \n",
       "268  M21 Random Forest      0.793415        0.717114          0.2087   \n",
       "269  M22 Random Forest      0.794812        0.714967          0.2110   \n",
       "270  M23 Random Forest      0.795248        0.712613          0.2112   \n",
       "271  M24 Random Forest      0.796912        0.710943          0.2103   \n",
       "272  M25 Random Forest      0.796458        0.715752          0.2102   \n",
       "273  M26 Random Forest      0.788110        0.713519          0.2102   \n",
       "274  M27 Random Forest      0.790270        0.714281          0.2095   \n",
       "275  M28 Random Forest      0.791918        0.711802          0.2093   \n",
       "276  M29 Random Forest      0.793466        0.713869          0.2093   \n",
       "277  M30 Random Forest      0.794712        0.713761          0.2087   \n",
       "278  M31 Random Forest      0.793070        0.713840          0.2086   \n",
       "\n",
       "     Validation RMSLE  \n",
       "248            0.2301  \n",
       "249            0.2279  \n",
       "250            0.2241  \n",
       "251            0.2241  \n",
       "252            0.2242  \n",
       "253            0.2240  \n",
       "254            0.2240  \n",
       "255            0.2241  \n",
       "256            0.2240  \n",
       "257            0.2239  \n",
       "258            0.2239  \n",
       "259            0.2239  \n",
       "260            0.2240  \n",
       "261            0.2240  \n",
       "262            0.2236  \n",
       "263            0.2239  \n",
       "264            0.2241  \n",
       "265            0.2237  \n",
       "266            0.2238  \n",
       "267            0.2241  \n",
       "268            0.2236  \n",
       "269            0.2239  \n",
       "270            0.2241  \n",
       "271            0.2243  \n",
       "272            0.2238  \n",
       "273            0.2240  \n",
       "274            0.2240  \n",
       "275            0.2240  \n",
       "276            0.2240  \n",
       "277            0.2239  \n",
       "278            0.2238  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for group_name, features in models.items():\n",
    "    start_time = time.time()  # Start timer\n",
    "    \n",
    "    steps = [\n",
    "        (\"scale_features\", ColumnTransformer([(\"scale_numeric_features\", MinMaxScaler(), features)], remainder='drop')),\n",
    "        (\"random_forest\", RandomForestClassifier(random_state=20240407))\n",
    "    ]\n",
    "    pipe_rf = Pipeline(steps)\n",
    "    \n",
    "    # Define the parameter grid to search over\n",
    "    param_grid = {\n",
    "        \"random_forest__max_depth\": [None, 3, 5, 7],  # None means no limit on the depth\n",
    "        \"random_forest__n_estimators\": [10, 50, 100],  # Number of trees\n",
    "        \"random_forest__min_samples_split\": [2, 4]  # Minimum number of samples required to split an internal node\n",
    "    }\n",
    "    \n",
    "    # Initialize GridSearchCV\n",
    "    grid_search = GridSearchCV(pipe_rf, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    # Fit the model on training data\n",
    "    grid_search.fit(X_train[features], y_train)\n",
    "    \n",
    "    # Best model after grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Predict probabilities for the positive class with the best model\n",
    "    train_prob = best_model.predict_proba(X_train[features])[:, 1]\n",
    "    val_prob = best_model.predict_proba(X_val[features])[:, 1]\n",
    "\n",
    "    # Calculate AUC scores using the probabilities\n",
    "    train_auc = roc_auc_score(y_train, train_prob)\n",
    "    val_auc = roc_auc_score(y_val, val_prob)\n",
    "    \n",
    "    # Calculate RMSLE\n",
    "    train_rmsle = calculateRMSLE(train_prob, y_train)\n",
    "    val_rmsle = calculateRMSLE(val_prob, y_val)\n",
    "\n",
    "    # Append results\n",
    "    best_params = grid_search.best_params_\n",
    "    new_row = pd.DataFrame([[f\"{group_name} Random Forest\", train_auc, val_auc, train_rmsle, val_rmsle]],\n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "    \n",
    "    end_time = time.time()  # End timer\n",
    "    print(f\"Completed {group_name} with best parameters {best_params} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df.tail(31)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b239e1-c123-43da-be03-90ed65695d1c",
   "metadata": {},
   "source": [
    "## Gradient Boosted Random Forest\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e1f3cc0-74f7-437a-8777-d21e91ec2370",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed M1 with best parameters {'xgb__learning_rate': 0.01, 'xgb__max_depth': 5, 'xgb__n_estimators': 200} in 3.63 seconds\n",
      "Completed M2 with best parameters {'xgb__learning_rate': 0.01, 'xgb__max_depth': 5, 'xgb__n_estimators': 200} in 6.17 seconds\n",
      "Completed M3 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 9.08 seconds\n",
      "Completed M4 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 10.31 seconds\n",
      "Completed M5 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 10.84 seconds\n",
      "Completed M6 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 16.22 seconds\n",
      "Completed M7 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 16.97 seconds\n",
      "Completed M8 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 17.61 seconds\n",
      "Completed M9 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 20.20 seconds\n",
      "Completed M10 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 29.73 seconds\n",
      "Completed M11 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 31.75 seconds\n",
      "Completed M12 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 14.56 seconds\n",
      "Completed M13 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 22.79 seconds\n",
      "Completed M14 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 22.73 seconds\n",
      "Completed M15 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 26.80 seconds\n",
      "Completed M16 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 27.66 seconds\n",
      "Completed M17 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 28.88 seconds\n",
      "Completed M18 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 48.34 seconds\n",
      "Completed M19 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 49.82 seconds\n",
      "Completed M20 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 64.94 seconds\n",
      "Completed M21 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 80.72 seconds\n",
      "Completed M22 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 18.37 seconds\n",
      "Completed M23 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 23.03 seconds\n",
      "Completed M24 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 29.36 seconds\n",
      "Completed M25 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 37.33 seconds\n",
      "Completed M26 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 40.43 seconds\n",
      "Completed M27 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 55.82 seconds\n",
      "Completed M28 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 68.48 seconds\n",
      "Completed M29 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 71.14 seconds\n",
      "Completed M30 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 97.89 seconds\n",
      "Completed M31 with best parameters {'xgb__learning_rate': 0.1, 'xgb__max_depth': 3, 'xgb__n_estimators': 100} in 102.59 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>M1 XGBoost</td>\n",
       "      <td>0.665216</td>\n",
       "      <td>0.596593</td>\n",
       "      <td>0.2241</td>\n",
       "      <td>0.2309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>M2 XGBoost</td>\n",
       "      <td>0.719108</td>\n",
       "      <td>0.659764</td>\n",
       "      <td>0.2198</td>\n",
       "      <td>0.2287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>M3 XGBoost</td>\n",
       "      <td>0.747470</td>\n",
       "      <td>0.712439</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>0.2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>M4 XGBoost</td>\n",
       "      <td>0.759199</td>\n",
       "      <td>0.716104</td>\n",
       "      <td>0.2146</td>\n",
       "      <td>0.2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>M5 XGBoost</td>\n",
       "      <td>0.759368</td>\n",
       "      <td>0.716645</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>M6 XGBoost</td>\n",
       "      <td>0.768038</td>\n",
       "      <td>0.720897</td>\n",
       "      <td>0.2138</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>M7 XGBoost</td>\n",
       "      <td>0.769562</td>\n",
       "      <td>0.719086</td>\n",
       "      <td>0.2135</td>\n",
       "      <td>0.2242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>M8 XGBoost</td>\n",
       "      <td>0.769562</td>\n",
       "      <td>0.719086</td>\n",
       "      <td>0.2135</td>\n",
       "      <td>0.2242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>M9 XGBoost</td>\n",
       "      <td>0.769550</td>\n",
       "      <td>0.719653</td>\n",
       "      <td>0.2135</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>M10 XGBoost</td>\n",
       "      <td>0.771894</td>\n",
       "      <td>0.722050</td>\n",
       "      <td>0.2131</td>\n",
       "      <td>0.2235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>M11 XGBoost</td>\n",
       "      <td>0.774262</td>\n",
       "      <td>0.722890</td>\n",
       "      <td>0.2127</td>\n",
       "      <td>0.2236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>M12 XGBoost</td>\n",
       "      <td>0.767690</td>\n",
       "      <td>0.722454</td>\n",
       "      <td>0.2138</td>\n",
       "      <td>0.2237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>M13 XGBoost</td>\n",
       "      <td>0.770440</td>\n",
       "      <td>0.720937</td>\n",
       "      <td>0.2134</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>M14 XGBoost</td>\n",
       "      <td>0.769978</td>\n",
       "      <td>0.719701</td>\n",
       "      <td>0.2135</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>M15 XGBoost</td>\n",
       "      <td>0.769828</td>\n",
       "      <td>0.719955</td>\n",
       "      <td>0.2135</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>M16 XGBoost</td>\n",
       "      <td>0.769828</td>\n",
       "      <td>0.719955</td>\n",
       "      <td>0.2135</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>M17 XGBoost</td>\n",
       "      <td>0.773609</td>\n",
       "      <td>0.717837</td>\n",
       "      <td>0.2129</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>M18 XGBoost</td>\n",
       "      <td>0.776353</td>\n",
       "      <td>0.720049</td>\n",
       "      <td>0.2124</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>M19 XGBoost</td>\n",
       "      <td>0.778091</td>\n",
       "      <td>0.722872</td>\n",
       "      <td>0.2123</td>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>M20 XGBoost</td>\n",
       "      <td>0.778148</td>\n",
       "      <td>0.722158</td>\n",
       "      <td>0.2122</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>M21 XGBoost</td>\n",
       "      <td>0.780335</td>\n",
       "      <td>0.721468</td>\n",
       "      <td>0.2118</td>\n",
       "      <td>0.2237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>M22 XGBoost</td>\n",
       "      <td>0.769562</td>\n",
       "      <td>0.719086</td>\n",
       "      <td>0.2135</td>\n",
       "      <td>0.2242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>M23 XGBoost</td>\n",
       "      <td>0.769511</td>\n",
       "      <td>0.719509</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>M24 XGBoost</td>\n",
       "      <td>0.769979</td>\n",
       "      <td>0.719701</td>\n",
       "      <td>0.2135</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>M25 XGBoost</td>\n",
       "      <td>0.769828</td>\n",
       "      <td>0.719955</td>\n",
       "      <td>0.2135</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>M26 XGBoost</td>\n",
       "      <td>0.769828</td>\n",
       "      <td>0.719955</td>\n",
       "      <td>0.2135</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>M27 XGBoost</td>\n",
       "      <td>0.773841</td>\n",
       "      <td>0.718111</td>\n",
       "      <td>0.2128</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>M28 XGBoost</td>\n",
       "      <td>0.776852</td>\n",
       "      <td>0.721188</td>\n",
       "      <td>0.2123</td>\n",
       "      <td>0.2237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>M29 XGBoost</td>\n",
       "      <td>0.776864</td>\n",
       "      <td>0.720156</td>\n",
       "      <td>0.2122</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>M30 XGBoost</td>\n",
       "      <td>0.780568</td>\n",
       "      <td>0.721286</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>0.2237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>M31 XGBoost</td>\n",
       "      <td>0.780335</td>\n",
       "      <td>0.721468</td>\n",
       "      <td>0.2118</td>\n",
       "      <td>0.2237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "279   M1 XGBoost      0.665216        0.596593          0.2241   \n",
       "280   M2 XGBoost      0.719108        0.659764          0.2198   \n",
       "281   M3 XGBoost      0.747470        0.712439          0.2162   \n",
       "282   M4 XGBoost      0.759199        0.716104          0.2146   \n",
       "283   M5 XGBoost      0.759368        0.716645          0.2145   \n",
       "284   M6 XGBoost      0.768038        0.720897          0.2138   \n",
       "285   M7 XGBoost      0.769562        0.719086          0.2135   \n",
       "286   M8 XGBoost      0.769562        0.719086          0.2135   \n",
       "287   M9 XGBoost      0.769550        0.719653          0.2135   \n",
       "288  M10 XGBoost      0.771894        0.722050          0.2131   \n",
       "289  M11 XGBoost      0.774262        0.722890          0.2127   \n",
       "290  M12 XGBoost      0.767690        0.722454          0.2138   \n",
       "291  M13 XGBoost      0.770440        0.720937          0.2134   \n",
       "292  M14 XGBoost      0.769978        0.719701          0.2135   \n",
       "293  M15 XGBoost      0.769828        0.719955          0.2135   \n",
       "294  M16 XGBoost      0.769828        0.719955          0.2135   \n",
       "295  M17 XGBoost      0.773609        0.717837          0.2129   \n",
       "296  M18 XGBoost      0.776353        0.720049          0.2124   \n",
       "297  M19 XGBoost      0.778091        0.722872          0.2123   \n",
       "298  M20 XGBoost      0.778148        0.722158          0.2122   \n",
       "299  M21 XGBoost      0.780335        0.721468          0.2118   \n",
       "300  M22 XGBoost      0.769562        0.719086          0.2135   \n",
       "301  M23 XGBoost      0.769511        0.719509          0.2136   \n",
       "302  M24 XGBoost      0.769979        0.719701          0.2135   \n",
       "303  M25 XGBoost      0.769828        0.719955          0.2135   \n",
       "304  M26 XGBoost      0.769828        0.719955          0.2135   \n",
       "305  M27 XGBoost      0.773841        0.718111          0.2128   \n",
       "306  M28 XGBoost      0.776852        0.721188          0.2123   \n",
       "307  M29 XGBoost      0.776864        0.720156          0.2122   \n",
       "308  M30 XGBoost      0.780568        0.721286          0.2117   \n",
       "309  M31 XGBoost      0.780335        0.721468          0.2118   \n",
       "\n",
       "     Validation RMSLE  \n",
       "279            0.2309  \n",
       "280            0.2287  \n",
       "281            0.2243  \n",
       "282            0.2243  \n",
       "283            0.2242  \n",
       "284            0.2241  \n",
       "285            0.2242  \n",
       "286            0.2242  \n",
       "287            0.2241  \n",
       "288            0.2235  \n",
       "289            0.2236  \n",
       "290            0.2237  \n",
       "291            0.2239  \n",
       "292            0.2241  \n",
       "293            0.2241  \n",
       "294            0.2241  \n",
       "295            0.2241  \n",
       "296            0.2241  \n",
       "297            0.2240  \n",
       "298            0.2241  \n",
       "299            0.2237  \n",
       "300            0.2242  \n",
       "301            0.2241  \n",
       "302            0.2241  \n",
       "303            0.2241  \n",
       "304            0.2241  \n",
       "305            0.2241  \n",
       "306            0.2237  \n",
       "307            0.2239  \n",
       "308            0.2237  \n",
       "309            0.2237  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for group_name, features in models.items():\n",
    "    start_time = time.time()  # Timer start\n",
    "    \n",
    "    steps = [\n",
    "        (\"scale_features\", ColumnTransformer([(\"scale_numeric_features\", MinMaxScaler(), features)], remainder='drop')),\n",
    "        (\"xgb\", xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n",
    "    ]\n",
    "    pipe_xgb = Pipeline(steps)\n",
    "    \n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        \"xgb__n_estimators\": [100, 200],  # Number of trees\n",
    "        \"xgb__max_depth\": [3, 5, 7],  # Depth of trees\n",
    "        \"xgb__learning_rate\": [0.01, 0.1]  # Step size shrinkage used in update to prevents overfitting\n",
    "    }\n",
    "    \n",
    "    # Initialize GridSearchCV\n",
    "    grid_search = GridSearchCV(pipe_xgb, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    grid_search.fit(X_train[features], y_train)\n",
    "    \n",
    "    # Best model after grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Predict probabilities for the positive class\n",
    "    train_prob = best_model.predict_proba(X_train[features])[:, 1]\n",
    "    val_prob = best_model.predict_proba(X_val[features])[:, 1]\n",
    "\n",
    "    # Calculate AUC scores using the probabilities\n",
    "    train_auc = roc_auc_score(y_train, train_prob)\n",
    "    val_auc = roc_auc_score(y_val, val_prob)\n",
    "    \n",
    "    # Calculate RMSLE\n",
    "    train_rmsle = calculateRMSLE(train_prob, y_train)\n",
    "    val_rmsle = calculateRMSLE(val_prob, y_val)\n",
    "\n",
    "    # Append results\n",
    "    best_params = grid_search.best_params_\n",
    "    new_row = pd.DataFrame([[f\"{group_name} XGBoost\", train_auc, val_auc, train_rmsle, val_rmsle]],\n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "    \n",
    "    end_time = time.time()  # End timer\n",
    "    print(f\"Completed {group_name} with best parameters {best_params} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df.tail(31)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cc04ef-9082-452d-9f45-307fc6502be1",
   "metadata": {},
   "source": [
    "## Light Gradient Boosting Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fd1648-a056-4bc8-b100-97748763ecb9",
   "metadata": {},
   "source": [
    "### Simple Light Gradient Boosting\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7502d19-7203-434a-8e59-be7e9bdb21f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed M1 in 0.61 seconds\n",
      "Completed M2 in 0.52 seconds\n",
      "Completed M3 in 0.56 seconds\n",
      "Completed M4 in 0.56 seconds\n",
      "Completed M5 in 0.57 seconds\n",
      "Completed M6 in 0.64 seconds\n",
      "Completed M7 in 0.65 seconds\n",
      "Completed M8 in 0.68 seconds\n",
      "Completed M9 in 0.71 seconds\n",
      "Completed M10 in 0.79 seconds\n",
      "Completed M11 in 0.83 seconds\n",
      "Completed M12 in 0.63 seconds\n",
      "Completed M13 in 0.77 seconds\n",
      "Completed M14 in 0.89 seconds\n",
      "Completed M15 in 0.91 seconds\n",
      "Completed M16 in 0.93 seconds\n",
      "Completed M17 in 0.91 seconds\n",
      "Completed M18 in 1.13 seconds\n",
      "Completed M19 in 1.19 seconds\n",
      "Completed M20 in 1.16 seconds\n",
      "Completed M21 in 1.45 seconds\n",
      "Completed M22 in 0.70 seconds\n",
      "Completed M23 in 0.74 seconds\n",
      "Completed M24 in 0.82 seconds\n",
      "Completed M25 in 0.91 seconds\n",
      "Completed M26 in 0.92 seconds\n",
      "Completed M27 in 1.05 seconds\n",
      "Completed M28 in 1.16 seconds\n",
      "Completed M29 in 1.26 seconds\n",
      "Completed M30 in 1.70 seconds\n",
      "Completed M31 in 1.73 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>M1 LightGBM Simple</td>\n",
       "      <td>0.842516</td>\n",
       "      <td>0.591113</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>M2 LightGBM Simple</td>\n",
       "      <td>0.892884</td>\n",
       "      <td>0.641908</td>\n",
       "      <td>0.1952</td>\n",
       "      <td>0.2294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>M3 LightGBM Simple</td>\n",
       "      <td>0.916443</td>\n",
       "      <td>0.703488</td>\n",
       "      <td>0.1869</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>M4 LightGBM Simple</td>\n",
       "      <td>0.919905</td>\n",
       "      <td>0.706887</td>\n",
       "      <td>0.1838</td>\n",
       "      <td>0.2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>M5 LightGBM Simple</td>\n",
       "      <td>0.915052</td>\n",
       "      <td>0.706785</td>\n",
       "      <td>0.1845</td>\n",
       "      <td>0.2261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>M6 LightGBM Simple</td>\n",
       "      <td>0.933078</td>\n",
       "      <td>0.711330</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>M7 LightGBM Simple</td>\n",
       "      <td>0.937193</td>\n",
       "      <td>0.708391</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.2256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>M8 LightGBM Simple</td>\n",
       "      <td>0.937193</td>\n",
       "      <td>0.708391</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.2256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>M9 LightGBM Simple</td>\n",
       "      <td>0.937193</td>\n",
       "      <td>0.708391</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.2256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>M10 LightGBM Simple</td>\n",
       "      <td>0.937184</td>\n",
       "      <td>0.709963</td>\n",
       "      <td>0.1774</td>\n",
       "      <td>0.2247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>M11 LightGBM Simple</td>\n",
       "      <td>0.938791</td>\n",
       "      <td>0.716654</td>\n",
       "      <td>0.1774</td>\n",
       "      <td>0.2245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>M12 LightGBM Simple</td>\n",
       "      <td>0.931819</td>\n",
       "      <td>0.716769</td>\n",
       "      <td>0.1805</td>\n",
       "      <td>0.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>M13 LightGBM Simple</td>\n",
       "      <td>0.939260</td>\n",
       "      <td>0.714709</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>M14 LightGBM Simple</td>\n",
       "      <td>0.937708</td>\n",
       "      <td>0.711139</td>\n",
       "      <td>0.1786</td>\n",
       "      <td>0.2258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>M15 LightGBM Simple</td>\n",
       "      <td>0.939260</td>\n",
       "      <td>0.714709</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>M16 LightGBM Simple</td>\n",
       "      <td>0.939260</td>\n",
       "      <td>0.714709</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>M17 LightGBM Simple</td>\n",
       "      <td>0.939677</td>\n",
       "      <td>0.709743</td>\n",
       "      <td>0.1756</td>\n",
       "      <td>0.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>M18 LightGBM Simple</td>\n",
       "      <td>0.944691</td>\n",
       "      <td>0.714028</td>\n",
       "      <td>0.1732</td>\n",
       "      <td>0.2248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>M19 LightGBM Simple</td>\n",
       "      <td>0.948079</td>\n",
       "      <td>0.711990</td>\n",
       "      <td>0.1730</td>\n",
       "      <td>0.2249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>M20 LightGBM Simple</td>\n",
       "      <td>0.946868</td>\n",
       "      <td>0.713726</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.2254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>M21 LightGBM Simple</td>\n",
       "      <td>0.945169</td>\n",
       "      <td>0.709520</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>M22 LightGBM Simple</td>\n",
       "      <td>0.937193</td>\n",
       "      <td>0.708391</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.2256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>M23 LightGBM Simple</td>\n",
       "      <td>0.937193</td>\n",
       "      <td>0.708391</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.2256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>M24 LightGBM Simple</td>\n",
       "      <td>0.937708</td>\n",
       "      <td>0.711139</td>\n",
       "      <td>0.1786</td>\n",
       "      <td>0.2258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>M25 LightGBM Simple</td>\n",
       "      <td>0.939260</td>\n",
       "      <td>0.714709</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>M26 LightGBM Simple</td>\n",
       "      <td>0.939260</td>\n",
       "      <td>0.714709</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>M27 LightGBM Simple</td>\n",
       "      <td>0.942648</td>\n",
       "      <td>0.714965</td>\n",
       "      <td>0.1763</td>\n",
       "      <td>0.2249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>M28 LightGBM Simple</td>\n",
       "      <td>0.942749</td>\n",
       "      <td>0.711064</td>\n",
       "      <td>0.1740</td>\n",
       "      <td>0.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>M29 LightGBM Simple</td>\n",
       "      <td>0.944236</td>\n",
       "      <td>0.719813</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>0.2246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>M30 LightGBM Simple</td>\n",
       "      <td>0.945702</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.2247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>M31 LightGBM Simple</td>\n",
       "      <td>0.945169</td>\n",
       "      <td>0.709520</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "310   M1 LightGBM Simple      0.842516        0.591113          0.2070   \n",
       "311   M2 LightGBM Simple      0.892884        0.641908          0.1952   \n",
       "312   M3 LightGBM Simple      0.916443        0.703488          0.1869   \n",
       "313   M4 LightGBM Simple      0.919905        0.706887          0.1838   \n",
       "314   M5 LightGBM Simple      0.915052        0.706785          0.1845   \n",
       "315   M6 LightGBM Simple      0.933078        0.711330          0.1802   \n",
       "316   M7 LightGBM Simple      0.937193        0.708391          0.1791   \n",
       "317   M8 LightGBM Simple      0.937193        0.708391          0.1791   \n",
       "318   M9 LightGBM Simple      0.937193        0.708391          0.1791   \n",
       "319  M10 LightGBM Simple      0.937184        0.709963          0.1774   \n",
       "320  M11 LightGBM Simple      0.938791        0.716654          0.1774   \n",
       "321  M12 LightGBM Simple      0.931819        0.716769          0.1805   \n",
       "322  M13 LightGBM Simple      0.939260        0.714709          0.1791   \n",
       "323  M14 LightGBM Simple      0.937708        0.711139          0.1786   \n",
       "324  M15 LightGBM Simple      0.939260        0.714709          0.1791   \n",
       "325  M16 LightGBM Simple      0.939260        0.714709          0.1791   \n",
       "326  M17 LightGBM Simple      0.939677        0.709743          0.1756   \n",
       "327  M18 LightGBM Simple      0.944691        0.714028          0.1732   \n",
       "328  M19 LightGBM Simple      0.948079        0.711990          0.1730   \n",
       "329  M20 LightGBM Simple      0.946868        0.713726          0.1733   \n",
       "330  M21 LightGBM Simple      0.945169        0.709520          0.1724   \n",
       "331  M22 LightGBM Simple      0.937193        0.708391          0.1791   \n",
       "332  M23 LightGBM Simple      0.937193        0.708391          0.1791   \n",
       "333  M24 LightGBM Simple      0.937708        0.711139          0.1786   \n",
       "334  M25 LightGBM Simple      0.939260        0.714709          0.1791   \n",
       "335  M26 LightGBM Simple      0.939260        0.714709          0.1791   \n",
       "336  M27 LightGBM Simple      0.942648        0.714965          0.1763   \n",
       "337  M28 LightGBM Simple      0.942749        0.711064          0.1740   \n",
       "338  M29 LightGBM Simple      0.944236        0.719813          0.1745   \n",
       "339  M30 LightGBM Simple      0.945702        0.716667          0.1726   \n",
       "340  M31 LightGBM Simple      0.945169        0.709520          0.1724   \n",
       "\n",
       "     Validation RMSLE  \n",
       "310            0.2311  \n",
       "311            0.2294  \n",
       "312            0.2251  \n",
       "313            0.2259  \n",
       "314            0.2261  \n",
       "315            0.2251  \n",
       "316            0.2256  \n",
       "317            0.2256  \n",
       "318            0.2256  \n",
       "319            0.2247  \n",
       "320            0.2245  \n",
       "321            0.2255  \n",
       "322            0.2250  \n",
       "323            0.2258  \n",
       "324            0.2250  \n",
       "325            0.2250  \n",
       "326            0.2255  \n",
       "327            0.2248  \n",
       "328            0.2249  \n",
       "329            0.2254  \n",
       "330            0.2251  \n",
       "331            0.2256  \n",
       "332            0.2256  \n",
       "333            0.2258  \n",
       "334            0.2250  \n",
       "335            0.2250  \n",
       "336            0.2249  \n",
       "337            0.2255  \n",
       "338            0.2246  \n",
       "339            0.2247  \n",
       "340            0.2251  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for group_name, features in models.items():\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create datasets for LightGBM\n",
    "    lgb_train = lgb.Dataset(X_train[features], label=y_train)\n",
    "    lgb_val = lgb.Dataset(X_val[features], label=y_val, reference=lgb_train)\n",
    "\n",
    "    # Simplify params by only setting the essentials\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'verbose': -1,\n",
    "        'random_state': 20240325\n",
    "    }\n",
    "\n",
    "    # Train model with a fixed number of boost rounds to simplify\n",
    "    num_boost_round = 100\n",
    "    lgb_model = lgb.train(params,\n",
    "                          lgb_train,\n",
    "                          num_boost_round=num_boost_round,\n",
    "                          valid_sets=[lgb_val])\n",
    "\n",
    "    # Prediction and evaluation\n",
    "    train_prob = lgb_model.predict(X_train[features], num_iteration=lgb_model.best_iteration)\n",
    "    val_prob = lgb_model.predict(X_val[features], num_iteration=lgb_model.best_iteration)\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, train_prob)\n",
    "    val_auc = roc_auc_score(y_val, val_prob)\n",
    "\n",
    "    # Assuming calculateRMSLE is previously defined\n",
    "    train_rmsle = calculateRMSLE(y_train, train_prob)\n",
    "    val_rmsle = calculateRMSLE(y_val, val_prob)\n",
    "\n",
    "    # Append results\n",
    "    new_row = pd.DataFrame([[f\"{group_name} LightGBM Simple\", train_auc, val_auc, train_rmsle, val_rmsle]], \n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Completed {group_name} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df.tail(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df191341-84c1-438a-bf30-29d0efaac611",
   "metadata": {},
   "source": [
    "### Tuned Light Gradient Boosting\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "484226b4-43c1-4245-b4fd-dcf27f3e4e21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed M1 in 4.61 seconds\n",
      "Completed M2 in 4.71 seconds\n",
      "Completed M3 in 5.20 seconds\n",
      "Completed M4 in 5.47 seconds\n",
      "Completed M5 in 5.12 seconds\n",
      "Completed M6 in 5.75 seconds\n",
      "Completed M7 in 5.78 seconds\n",
      "Completed M8 in 5.53 seconds\n",
      "Completed M9 in 6.23 seconds\n",
      "Completed M10 in 6.44 seconds\n",
      "Completed M11 in 6.64 seconds\n",
      "Completed M12 in 5.80 seconds\n",
      "Completed M13 in 5.84 seconds\n",
      "Completed M14 in 6.34 seconds\n",
      "Completed M15 in 6.39 seconds\n",
      "Completed M16 in 6.19 seconds\n",
      "Completed M17 in 6.95 seconds\n",
      "Completed M18 in 7.29 seconds\n",
      "Completed M19 in 8.21 seconds\n",
      "Completed M20 in 8.21 seconds\n",
      "Completed M21 in 9.86 seconds\n",
      "Completed M22 in 5.72 seconds\n",
      "Completed M23 in 6.60 seconds\n",
      "Completed M24 in 6.39 seconds\n",
      "Completed M25 in 7.16 seconds\n",
      "Completed M26 in 7.77 seconds\n",
      "Completed M27 in 8.05 seconds\n",
      "Completed M28 in 8.98 seconds\n",
      "Completed M29 in 9.13 seconds\n",
      "Completed M30 in 9.72 seconds\n",
      "Completed M31 in 10.65 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>M1 LightGBM Tuned</td>\n",
       "      <td>0.939188</td>\n",
       "      <td>0.573151</td>\n",
       "      <td>0.1857</td>\n",
       "      <td>0.2336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>M2 LightGBM Tuned</td>\n",
       "      <td>0.976504</td>\n",
       "      <td>0.618826</td>\n",
       "      <td>0.1605</td>\n",
       "      <td>0.2321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>M3 LightGBM Tuned</td>\n",
       "      <td>0.989452</td>\n",
       "      <td>0.687944</td>\n",
       "      <td>0.1446</td>\n",
       "      <td>0.2273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>M4 LightGBM Tuned</td>\n",
       "      <td>0.989442</td>\n",
       "      <td>0.699864</td>\n",
       "      <td>0.1414</td>\n",
       "      <td>0.2273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>M5 LightGBM Tuned</td>\n",
       "      <td>0.991744</td>\n",
       "      <td>0.698887</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.2274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>M6 LightGBM Tuned</td>\n",
       "      <td>0.995478</td>\n",
       "      <td>0.706937</td>\n",
       "      <td>0.1317</td>\n",
       "      <td>0.2261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>M7 LightGBM Tuned</td>\n",
       "      <td>0.996543</td>\n",
       "      <td>0.703983</td>\n",
       "      <td>0.1292</td>\n",
       "      <td>0.2265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>M8 LightGBM Tuned</td>\n",
       "      <td>0.996543</td>\n",
       "      <td>0.703983</td>\n",
       "      <td>0.1292</td>\n",
       "      <td>0.2265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>M9 LightGBM Tuned</td>\n",
       "      <td>0.996543</td>\n",
       "      <td>0.703983</td>\n",
       "      <td>0.1292</td>\n",
       "      <td>0.2265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>M10 LightGBM Tuned</td>\n",
       "      <td>0.997476</td>\n",
       "      <td>0.704864</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.2257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>M11 LightGBM Tuned</td>\n",
       "      <td>0.997174</td>\n",
       "      <td>0.702369</td>\n",
       "      <td>0.1253</td>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>M12 LightGBM Tuned</td>\n",
       "      <td>0.995949</td>\n",
       "      <td>0.710317</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>M13 LightGBM Tuned</td>\n",
       "      <td>0.996994</td>\n",
       "      <td>0.702532</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>0.2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>M14 LightGBM Tuned</td>\n",
       "      <td>0.996551</td>\n",
       "      <td>0.701504</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.2265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>M15 LightGBM Tuned</td>\n",
       "      <td>0.996994</td>\n",
       "      <td>0.702532</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>0.2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>M16 LightGBM Tuned</td>\n",
       "      <td>0.996994</td>\n",
       "      <td>0.702532</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>0.2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>M17 LightGBM Tuned</td>\n",
       "      <td>0.997594</td>\n",
       "      <td>0.705479</td>\n",
       "      <td>0.1237</td>\n",
       "      <td>0.2262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>M18 LightGBM Tuned</td>\n",
       "      <td>0.998806</td>\n",
       "      <td>0.703776</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>0.2266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>M19 LightGBM Tuned</td>\n",
       "      <td>0.998681</td>\n",
       "      <td>0.702071</td>\n",
       "      <td>0.1167</td>\n",
       "      <td>0.2270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>M20 LightGBM Tuned</td>\n",
       "      <td>0.998657</td>\n",
       "      <td>0.705644</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>0.2267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>M21 LightGBM Tuned</td>\n",
       "      <td>0.998908</td>\n",
       "      <td>0.706279</td>\n",
       "      <td>0.1134</td>\n",
       "      <td>0.2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>M22 LightGBM Tuned</td>\n",
       "      <td>0.996543</td>\n",
       "      <td>0.703983</td>\n",
       "      <td>0.1292</td>\n",
       "      <td>0.2265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>M23 LightGBM Tuned</td>\n",
       "      <td>0.996543</td>\n",
       "      <td>0.703983</td>\n",
       "      <td>0.1292</td>\n",
       "      <td>0.2265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>M24 LightGBM Tuned</td>\n",
       "      <td>0.996482</td>\n",
       "      <td>0.702687</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>0.2265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>M25 LightGBM Tuned</td>\n",
       "      <td>0.996959</td>\n",
       "      <td>0.703153</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>M26 LightGBM Tuned</td>\n",
       "      <td>0.996959</td>\n",
       "      <td>0.703153</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>M27 LightGBM Tuned</td>\n",
       "      <td>0.997354</td>\n",
       "      <td>0.702421</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>0.2272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>M28 LightGBM Tuned</td>\n",
       "      <td>0.998384</td>\n",
       "      <td>0.706762</td>\n",
       "      <td>0.1197</td>\n",
       "      <td>0.2266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>M29 LightGBM Tuned</td>\n",
       "      <td>0.998254</td>\n",
       "      <td>0.703443</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>0.2271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>M30 LightGBM Tuned</td>\n",
       "      <td>0.999104</td>\n",
       "      <td>0.709370</td>\n",
       "      <td>0.1134</td>\n",
       "      <td>0.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>M31 LightGBM Tuned</td>\n",
       "      <td>0.998908</td>\n",
       "      <td>0.706279</td>\n",
       "      <td>0.1134</td>\n",
       "      <td>0.2264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "341   M1 LightGBM Tuned      0.939188        0.573151          0.1857   \n",
       "342   M2 LightGBM Tuned      0.976504        0.618826          0.1605   \n",
       "343   M3 LightGBM Tuned      0.989452        0.687944          0.1446   \n",
       "344   M4 LightGBM Tuned      0.989442        0.699864          0.1414   \n",
       "345   M5 LightGBM Tuned      0.991744        0.698887          0.1390   \n",
       "346   M6 LightGBM Tuned      0.995478        0.706937          0.1317   \n",
       "347   M7 LightGBM Tuned      0.996543        0.703983          0.1292   \n",
       "348   M8 LightGBM Tuned      0.996543        0.703983          0.1292   \n",
       "349   M9 LightGBM Tuned      0.996543        0.703983          0.1292   \n",
       "350  M10 LightGBM Tuned      0.997476        0.704864          0.1250   \n",
       "351  M11 LightGBM Tuned      0.997174        0.702369          0.1253   \n",
       "352  M12 LightGBM Tuned      0.995949        0.710317          0.1312   \n",
       "353  M13 LightGBM Tuned      0.996994        0.702532          0.1283   \n",
       "354  M14 LightGBM Tuned      0.996551        0.701504          0.1296   \n",
       "355  M15 LightGBM Tuned      0.996994        0.702532          0.1283   \n",
       "356  M16 LightGBM Tuned      0.996994        0.702532          0.1283   \n",
       "357  M17 LightGBM Tuned      0.997594        0.705479          0.1237   \n",
       "358  M18 LightGBM Tuned      0.998806        0.703776          0.1166   \n",
       "359  M19 LightGBM Tuned      0.998681        0.702071          0.1167   \n",
       "360  M20 LightGBM Tuned      0.998657        0.705644          0.1158   \n",
       "361  M21 LightGBM Tuned      0.998908        0.706279          0.1134   \n",
       "362  M22 LightGBM Tuned      0.996543        0.703983          0.1292   \n",
       "363  M23 LightGBM Tuned      0.996543        0.703983          0.1292   \n",
       "364  M24 LightGBM Tuned      0.996482        0.702687          0.1296   \n",
       "365  M25 LightGBM Tuned      0.996959        0.703153          0.1283   \n",
       "366  M26 LightGBM Tuned      0.996959        0.703153          0.1283   \n",
       "367  M27 LightGBM Tuned      0.997354        0.702421          0.1230   \n",
       "368  M28 LightGBM Tuned      0.998384        0.706762          0.1197   \n",
       "369  M29 LightGBM Tuned      0.998254        0.703443          0.1189   \n",
       "370  M30 LightGBM Tuned      0.999104        0.709370          0.1134   \n",
       "371  M31 LightGBM Tuned      0.998908        0.706279          0.1134   \n",
       "\n",
       "     Validation RMSLE  \n",
       "341            0.2336  \n",
       "342            0.2321  \n",
       "343            0.2273  \n",
       "344            0.2273  \n",
       "345            0.2274  \n",
       "346            0.2261  \n",
       "347            0.2265  \n",
       "348            0.2265  \n",
       "349            0.2265  \n",
       "350            0.2257  \n",
       "351            0.2263  \n",
       "352            0.2255  \n",
       "353            0.2264  \n",
       "354            0.2265  \n",
       "355            0.2264  \n",
       "356            0.2264  \n",
       "357            0.2262  \n",
       "358            0.2266  \n",
       "359            0.2270  \n",
       "360            0.2267  \n",
       "361            0.2264  \n",
       "362            0.2265  \n",
       "363            0.2265  \n",
       "364            0.2265  \n",
       "365            0.2263  \n",
       "366            0.2263  \n",
       "367            0.2272  \n",
       "368            0.2266  \n",
       "369            0.2271  \n",
       "370            0.2255  \n",
       "371            0.2264  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for group_name, features in models.items():\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create datasets for LightGBM\n",
    "    lgb_train = lgb.Dataset(X_train[features], label=y_train)\n",
    "    lgb_val = lgb.Dataset(X_val[features], label=y_val, reference=lgb_train)\n",
    "\n",
    "    # Adjust parameters to reduce overfitting\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': 0.05,  # Lowered learning rate\n",
    "        'num_leaves': 20,  # Fewer leaves\n",
    "        'lambda_l1': 0.5,  # Added L1 regularization\n",
    "        'lambda_l2': 0.5,  # Added L2 regularization\n",
    "        'verbose': -1,\n",
    "        'random_state': 20240325\n",
    "    }\n",
    "\n",
    "    # Train model with early stopping\n",
    "    lgb_model = lgb.train(params,\n",
    "                          lgb_train,\n",
    "                          valid_sets=[lgb_val],\n",
    "                          num_boost_round=1000)  # Maximum number of boosting rounds\n",
    "\n",
    "    # Prediction and evaluation\n",
    "    train_prob = lgb_model.predict(X_train[features], num_iteration=lgb_model.best_iteration)\n",
    "    val_prob = lgb_model.predict(X_val[features], num_iteration=lgb_model.best_iteration)\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, train_prob)\n",
    "    val_auc = roc_auc_score(y_val, val_prob)\n",
    "\n",
    "    # Assuming calculateRMSLE is previously defined\n",
    "    train_rmsle = calculateRMSLE(y_train, train_prob)\n",
    "    val_rmsle = calculateRMSLE(y_val, val_prob)\n",
    "\n",
    "    # Append results\n",
    "    new_row = pd.DataFrame([[f\"{group_name} LightGBM Tuned\", train_auc, val_auc, train_rmsle, val_rmsle]], \n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Completed {group_name} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "results_df.tail(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e039161-3d58-4514-a721-5e6eeca52055",
   "metadata": {},
   "source": [
    "## Cat Boosting\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4088505-dece-4d4c-94a7-e2656528b98e",
   "metadata": {},
   "source": [
    "### Simple Cat Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60ad65ec-afd0-4b54-850c-ed85f8c233eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed M1 in 3.44 seconds\n",
      "Completed M2 in 3.24 seconds\n",
      "Completed M3 in 3.49 seconds\n",
      "Completed M4 in 3.48 seconds\n",
      "Completed M5 in 3.20 seconds\n",
      "Completed M6 in 3.46 seconds\n",
      "Completed M7 in 3.58 seconds\n",
      "Completed M8 in 3.90 seconds\n",
      "Completed M9 in 3.89 seconds\n",
      "Completed M10 in 4.02 seconds\n",
      "Completed M11 in 4.21 seconds\n",
      "Completed M12 in 3.77 seconds\n",
      "Completed M13 in 3.98 seconds\n",
      "Completed M14 in 3.76 seconds\n",
      "Completed M15 in 4.07 seconds\n",
      "Completed M16 in 4.36 seconds\n",
      "Completed M17 in 4.11 seconds\n",
      "Completed M18 in 4.50 seconds\n",
      "Completed M19 in 4.69 seconds\n",
      "Completed M20 in 5.43 seconds\n",
      "Completed M21 in 5.57 seconds\n",
      "Completed M22 in 3.73 seconds\n",
      "Completed M23 in 4.11 seconds\n",
      "Completed M24 in 4.22 seconds\n",
      "Completed M25 in 4.32 seconds\n",
      "Completed M26 in 4.60 seconds\n",
      "Completed M27 in 5.31 seconds\n",
      "Completed M28 in 5.18 seconds\n",
      "Completed M29 in 5.47 seconds\n",
      "Completed M30 in 6.38 seconds\n",
      "Completed M31 in 5.87 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>M1 CatBoost Simple</td>\n",
       "      <td>0.618453</td>\n",
       "      <td>0.595543</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.2303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>M2 CatBoost Simple</td>\n",
       "      <td>0.669739</td>\n",
       "      <td>0.656781</td>\n",
       "      <td>0.2227</td>\n",
       "      <td>0.2279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>M3 CatBoost Simple</td>\n",
       "      <td>0.707846</td>\n",
       "      <td>0.708040</td>\n",
       "      <td>0.2203</td>\n",
       "      <td>0.2244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>M4 CatBoost Simple</td>\n",
       "      <td>0.720150</td>\n",
       "      <td>0.714292</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>M5 CatBoost Simple</td>\n",
       "      <td>0.720699</td>\n",
       "      <td>0.713801</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>M6 CatBoost Simple</td>\n",
       "      <td>0.723002</td>\n",
       "      <td>0.715514</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>M7 CatBoost Simple</td>\n",
       "      <td>0.723666</td>\n",
       "      <td>0.717000</td>\n",
       "      <td>0.2189</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>M8 CatBoost Simple</td>\n",
       "      <td>0.723455</td>\n",
       "      <td>0.716248</td>\n",
       "      <td>0.2189</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>M9 CatBoost Simple</td>\n",
       "      <td>0.723954</td>\n",
       "      <td>0.717557</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>M10 CatBoost Simple</td>\n",
       "      <td>0.723738</td>\n",
       "      <td>0.715799</td>\n",
       "      <td>0.2189</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>M11 CatBoost Simple</td>\n",
       "      <td>0.724089</td>\n",
       "      <td>0.716550</td>\n",
       "      <td>0.2187</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>M12 CatBoost Simple</td>\n",
       "      <td>0.722991</td>\n",
       "      <td>0.717070</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>M13 CatBoost Simple</td>\n",
       "      <td>0.723679</td>\n",
       "      <td>0.716868</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>M14 CatBoost Simple</td>\n",
       "      <td>0.723793</td>\n",
       "      <td>0.716271</td>\n",
       "      <td>0.2189</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>M15 CatBoost Simple</td>\n",
       "      <td>0.723694</td>\n",
       "      <td>0.716679</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>M16 CatBoost Simple</td>\n",
       "      <td>0.723898</td>\n",
       "      <td>0.716920</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>M17 CatBoost Simple</td>\n",
       "      <td>0.724818</td>\n",
       "      <td>0.717518</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>M18 CatBoost Simple</td>\n",
       "      <td>0.724918</td>\n",
       "      <td>0.717098</td>\n",
       "      <td>0.2187</td>\n",
       "      <td>0.2237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>M19 CatBoost Simple</td>\n",
       "      <td>0.725062</td>\n",
       "      <td>0.717590</td>\n",
       "      <td>0.2186</td>\n",
       "      <td>0.2237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>M20 CatBoost Simple</td>\n",
       "      <td>0.725010</td>\n",
       "      <td>0.717192</td>\n",
       "      <td>0.2186</td>\n",
       "      <td>0.2237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>M21 CatBoost Simple</td>\n",
       "      <td>0.724701</td>\n",
       "      <td>0.717163</td>\n",
       "      <td>0.2186</td>\n",
       "      <td>0.2237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>M22 CatBoost Simple</td>\n",
       "      <td>0.723191</td>\n",
       "      <td>0.716020</td>\n",
       "      <td>0.2189</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>M23 CatBoost Simple</td>\n",
       "      <td>0.723381</td>\n",
       "      <td>0.715913</td>\n",
       "      <td>0.2189</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>M24 CatBoost Simple</td>\n",
       "      <td>0.723900</td>\n",
       "      <td>0.716267</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>M25 CatBoost Simple</td>\n",
       "      <td>0.723863</td>\n",
       "      <td>0.717047</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>M26 CatBoost Simple</td>\n",
       "      <td>0.723881</td>\n",
       "      <td>0.715158</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>M27 CatBoost Simple</td>\n",
       "      <td>0.725017</td>\n",
       "      <td>0.715846</td>\n",
       "      <td>0.2186</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>M28 CatBoost Simple</td>\n",
       "      <td>0.725118</td>\n",
       "      <td>0.716557</td>\n",
       "      <td>0.2186</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>M29 CatBoost Simple</td>\n",
       "      <td>0.724827</td>\n",
       "      <td>0.714946</td>\n",
       "      <td>0.2186</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>M30 CatBoost Simple</td>\n",
       "      <td>0.725759</td>\n",
       "      <td>0.716240</td>\n",
       "      <td>0.2185</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>M31 CatBoost Simple</td>\n",
       "      <td>0.725350</td>\n",
       "      <td>0.716669</td>\n",
       "      <td>0.2185</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "372   M1 CatBoost Simple      0.618453        0.595543          0.2255   \n",
       "373   M2 CatBoost Simple      0.669739        0.656781          0.2227   \n",
       "374   M3 CatBoost Simple      0.707846        0.708040          0.2203   \n",
       "375   M4 CatBoost Simple      0.720150        0.714292          0.2191   \n",
       "376   M5 CatBoost Simple      0.720699        0.713801          0.2191   \n",
       "377   M6 CatBoost Simple      0.723002        0.715514          0.2190   \n",
       "378   M7 CatBoost Simple      0.723666        0.717000          0.2189   \n",
       "379   M8 CatBoost Simple      0.723455        0.716248          0.2189   \n",
       "380   M9 CatBoost Simple      0.723954        0.717557          0.2188   \n",
       "381  M10 CatBoost Simple      0.723738        0.715799          0.2189   \n",
       "382  M11 CatBoost Simple      0.724089        0.716550          0.2187   \n",
       "383  M12 CatBoost Simple      0.722991        0.717070          0.2190   \n",
       "384  M13 CatBoost Simple      0.723679        0.716868          0.2188   \n",
       "385  M14 CatBoost Simple      0.723793        0.716271          0.2189   \n",
       "386  M15 CatBoost Simple      0.723694        0.716679          0.2188   \n",
       "387  M16 CatBoost Simple      0.723898        0.716920          0.2188   \n",
       "388  M17 CatBoost Simple      0.724818        0.717518          0.2188   \n",
       "389  M18 CatBoost Simple      0.724918        0.717098          0.2187   \n",
       "390  M19 CatBoost Simple      0.725062        0.717590          0.2186   \n",
       "391  M20 CatBoost Simple      0.725010        0.717192          0.2186   \n",
       "392  M21 CatBoost Simple      0.724701        0.717163          0.2186   \n",
       "393  M22 CatBoost Simple      0.723191        0.716020          0.2189   \n",
       "394  M23 CatBoost Simple      0.723381        0.715913          0.2189   \n",
       "395  M24 CatBoost Simple      0.723900        0.716267          0.2188   \n",
       "396  M25 CatBoost Simple      0.723863        0.717047          0.2188   \n",
       "397  M26 CatBoost Simple      0.723881        0.715158          0.2188   \n",
       "398  M27 CatBoost Simple      0.725017        0.715846          0.2186   \n",
       "399  M28 CatBoost Simple      0.725118        0.716557          0.2186   \n",
       "400  M29 CatBoost Simple      0.724827        0.714946          0.2186   \n",
       "401  M30 CatBoost Simple      0.725759        0.716240          0.2185   \n",
       "402  M31 CatBoost Simple      0.725350        0.716669          0.2185   \n",
       "\n",
       "     Validation RMSLE  \n",
       "372            0.2303  \n",
       "373            0.2279  \n",
       "374            0.2244  \n",
       "375            0.2240  \n",
       "376            0.2241  \n",
       "377            0.2239  \n",
       "378            0.2238  \n",
       "379            0.2239  \n",
       "380            0.2238  \n",
       "381            0.2239  \n",
       "382            0.2239  \n",
       "383            0.2238  \n",
       "384            0.2238  \n",
       "385            0.2239  \n",
       "386            0.2238  \n",
       "387            0.2238  \n",
       "388            0.2238  \n",
       "389            0.2237  \n",
       "390            0.2237  \n",
       "391            0.2237  \n",
       "392            0.2237  \n",
       "393            0.2239  \n",
       "394            0.2239  \n",
       "395            0.2239  \n",
       "396            0.2238  \n",
       "397            0.2239  \n",
       "398            0.2239  \n",
       "399            0.2238  \n",
       "400            0.2239  \n",
       "401            0.2238  \n",
       "402            0.2238  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for group_name, features in models.items():\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Defining CatBoost model\n",
    "    cb_model = CatBoostClassifier(\n",
    "        iterations=500,  # Fewer iterations for quicker learning\n",
    "        learning_rate=0.01,  # Higher learning rate for faster convergence\n",
    "        depth=4,  # Lower depth to reduce model complexity and overfitting\n",
    "        random_state=20240325,\n",
    "        verbose=False  # Silence the output to avoid flooding the notebook/console\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    cb_model.fit(X_train[features], y_train, eval_set=(X_val[features], y_val), early_stopping_rounds=50, verbose=False)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    train_prob = cb_model.predict_proba(X_train[features])[:, 1]\n",
    "    val_prob = cb_model.predict_proba(X_val[features])[:, 1]\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, train_prob)\n",
    "    val_auc = roc_auc_score(y_val, val_prob)\n",
    "    \n",
    "    # Assuming calculateRMSLE is defined elsewhere\n",
    "    train_rmsle = calculateRMSLE(y_train, train_prob)\n",
    "    val_rmsle = calculateRMSLE(y_val, val_prob)\n",
    "\n",
    "    # Append results\n",
    "    new_row = pd.DataFrame([[f\"{group_name} CatBoost Simple\", train_auc, val_auc, train_rmsle, val_rmsle]], \n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Completed {group_name} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df.tail(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11a4352-4d7d-43ee-bd70-5a142a985424",
   "metadata": {},
   "source": [
    "### Tuned Cat Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1194de50-7e6a-466c-b409-a809dadc4ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed M1 in 16.63 seconds\n",
      "Completed M2 in 17.90 seconds\n",
      "Completed M3 in 20.68 seconds\n",
      "Completed M4 in 21.23 seconds\n",
      "Completed M5 in 21.07 seconds\n",
      "Completed M6 in 24.97 seconds\n",
      "Completed M7 in 26.55 seconds\n",
      "Completed M8 in 27.29 seconds\n",
      "Completed M9 in 29.09 seconds\n",
      "Completed M10 in 33.91 seconds\n",
      "Completed M11 in 35.61 seconds\n",
      "Completed M12 in 24.77 seconds\n",
      "Completed M13 in 30.18 seconds\n",
      "Completed M14 in 30.29 seconds\n",
      "Completed M15 in 32.84 seconds\n",
      "Completed M16 in 32.79 seconds\n",
      "Completed M17 in 34.28 seconds\n",
      "Completed M18 in 45.00 seconds\n",
      "Completed M19 in 45.59 seconds\n",
      "Completed M20 in 52.07 seconds\n",
      "Completed M21 in 58.94 seconds\n",
      "Completed M22 in 28.65 seconds\n",
      "Completed M23 in 30.82 seconds\n",
      "Completed M24 in 34.09 seconds\n",
      "Completed M25 in 38.57 seconds\n",
      "Completed M26 in 39.91 seconds\n",
      "Completed M27 in 47.98 seconds\n",
      "Completed M28 in 53.11 seconds\n",
      "Completed M29 in 55.45 seconds\n",
      "Completed M30 in 66.49 seconds\n",
      "Completed M31 in 66.22 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>M1 CatBoost Tuned</td>\n",
       "      <td>0.626457</td>\n",
       "      <td>0.593662</td>\n",
       "      <td>0.2306</td>\n",
       "      <td>0.2349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>M2 CatBoost Tuned</td>\n",
       "      <td>0.682740</td>\n",
       "      <td>0.655602</td>\n",
       "      <td>0.2274</td>\n",
       "      <td>0.2324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>M3 CatBoost Tuned</td>\n",
       "      <td>0.716299</td>\n",
       "      <td>0.704937</td>\n",
       "      <td>0.2244</td>\n",
       "      <td>0.2287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>M4 CatBoost Tuned</td>\n",
       "      <td>0.728570</td>\n",
       "      <td>0.711844</td>\n",
       "      <td>0.2229</td>\n",
       "      <td>0.2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>M5 CatBoost Tuned</td>\n",
       "      <td>0.729916</td>\n",
       "      <td>0.711713</td>\n",
       "      <td>0.2228</td>\n",
       "      <td>0.2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>M6 CatBoost Tuned</td>\n",
       "      <td>0.734208</td>\n",
       "      <td>0.712797</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>M7 CatBoost Tuned</td>\n",
       "      <td>0.736047</td>\n",
       "      <td>0.712959</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>0.2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>M8 CatBoost Tuned</td>\n",
       "      <td>0.736876</td>\n",
       "      <td>0.713473</td>\n",
       "      <td>0.2224</td>\n",
       "      <td>0.2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>M9 CatBoost Tuned</td>\n",
       "      <td>0.736553</td>\n",
       "      <td>0.713060</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>0.2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>M10 CatBoost Tuned</td>\n",
       "      <td>0.736948</td>\n",
       "      <td>0.713204</td>\n",
       "      <td>0.2224</td>\n",
       "      <td>0.2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>M11 CatBoost Tuned</td>\n",
       "      <td>0.737306</td>\n",
       "      <td>0.713051</td>\n",
       "      <td>0.2224</td>\n",
       "      <td>0.2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>M12 CatBoost Tuned</td>\n",
       "      <td>0.734932</td>\n",
       "      <td>0.714174</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.2279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>M13 CatBoost Tuned</td>\n",
       "      <td>0.734330</td>\n",
       "      <td>0.713430</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>0.2279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>M14 CatBoost Tuned</td>\n",
       "      <td>0.736037</td>\n",
       "      <td>0.713077</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>0.2281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>M15 CatBoost Tuned</td>\n",
       "      <td>0.735528</td>\n",
       "      <td>0.714038</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>0.2279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>M16 CatBoost Tuned</td>\n",
       "      <td>0.734902</td>\n",
       "      <td>0.713281</td>\n",
       "      <td>0.2224</td>\n",
       "      <td>0.2279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>M17 CatBoost Tuned</td>\n",
       "      <td>0.738524</td>\n",
       "      <td>0.712682</td>\n",
       "      <td>0.2223</td>\n",
       "      <td>0.2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>M18 CatBoost Tuned</td>\n",
       "      <td>0.737946</td>\n",
       "      <td>0.714574</td>\n",
       "      <td>0.2221</td>\n",
       "      <td>0.2278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>M19 CatBoost Tuned</td>\n",
       "      <td>0.737564</td>\n",
       "      <td>0.714739</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>M20 CatBoost Tuned</td>\n",
       "      <td>0.737282</td>\n",
       "      <td>0.714359</td>\n",
       "      <td>0.2221</td>\n",
       "      <td>0.2278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>M21 CatBoost Tuned</td>\n",
       "      <td>0.739480</td>\n",
       "      <td>0.715113</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.2278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>M22 CatBoost Tuned</td>\n",
       "      <td>0.736325</td>\n",
       "      <td>0.712568</td>\n",
       "      <td>0.2224</td>\n",
       "      <td>0.2281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>M23 CatBoost Tuned</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.712147</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>0.2281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>M24 CatBoost Tuned</td>\n",
       "      <td>0.735431</td>\n",
       "      <td>0.712291</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.2281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>M25 CatBoost Tuned</td>\n",
       "      <td>0.735819</td>\n",
       "      <td>0.714331</td>\n",
       "      <td>0.2224</td>\n",
       "      <td>0.2279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>M26 CatBoost Tuned</td>\n",
       "      <td>0.735275</td>\n",
       "      <td>0.713497</td>\n",
       "      <td>0.2223</td>\n",
       "      <td>0.2279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>M27 CatBoost Tuned</td>\n",
       "      <td>0.737269</td>\n",
       "      <td>0.713180</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.2279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>M28 CatBoost Tuned</td>\n",
       "      <td>0.738768</td>\n",
       "      <td>0.713571</td>\n",
       "      <td>0.2221</td>\n",
       "      <td>0.2279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>M29 CatBoost Tuned</td>\n",
       "      <td>0.738677</td>\n",
       "      <td>0.713442</td>\n",
       "      <td>0.2221</td>\n",
       "      <td>0.2279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>M30 CatBoost Tuned</td>\n",
       "      <td>0.739003</td>\n",
       "      <td>0.714696</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.2278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>M31 CatBoost Tuned</td>\n",
       "      <td>0.738665</td>\n",
       "      <td>0.714524</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.2278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "403   M1 CatBoost Tuned      0.626457        0.593662          0.2306   \n",
       "404   M2 CatBoost Tuned      0.682740        0.655602          0.2274   \n",
       "405   M3 CatBoost Tuned      0.716299        0.704937          0.2244   \n",
       "406   M4 CatBoost Tuned      0.728570        0.711844          0.2229   \n",
       "407   M5 CatBoost Tuned      0.729916        0.711713          0.2228   \n",
       "408   M6 CatBoost Tuned      0.734208        0.712797          0.2226   \n",
       "409   M7 CatBoost Tuned      0.736047        0.712959          0.2225   \n",
       "410   M8 CatBoost Tuned      0.736876        0.713473          0.2224   \n",
       "411   M9 CatBoost Tuned      0.736553        0.713060          0.2225   \n",
       "412  M10 CatBoost Tuned      0.736948        0.713204          0.2224   \n",
       "413  M11 CatBoost Tuned      0.737306        0.713051          0.2224   \n",
       "414  M12 CatBoost Tuned      0.734932        0.714174          0.2226   \n",
       "415  M13 CatBoost Tuned      0.734330        0.713430          0.2225   \n",
       "416  M14 CatBoost Tuned      0.736037        0.713077          0.2225   \n",
       "417  M15 CatBoost Tuned      0.735528        0.714038          0.2225   \n",
       "418  M16 CatBoost Tuned      0.734902        0.713281          0.2224   \n",
       "419  M17 CatBoost Tuned      0.738524        0.712682          0.2223   \n",
       "420  M18 CatBoost Tuned      0.737946        0.714574          0.2221   \n",
       "421  M19 CatBoost Tuned      0.737564        0.714739          0.2220   \n",
       "422  M20 CatBoost Tuned      0.737282        0.714359          0.2221   \n",
       "423  M21 CatBoost Tuned      0.739480        0.715113          0.2219   \n",
       "424  M22 CatBoost Tuned      0.736325        0.712568          0.2224   \n",
       "425  M23 CatBoost Tuned      0.735849        0.712147          0.2225   \n",
       "426  M24 CatBoost Tuned      0.735431        0.712291          0.2226   \n",
       "427  M25 CatBoost Tuned      0.735819        0.714331          0.2224   \n",
       "428  M26 CatBoost Tuned      0.735275        0.713497          0.2223   \n",
       "429  M27 CatBoost Tuned      0.737269        0.713180          0.2222   \n",
       "430  M28 CatBoost Tuned      0.738768        0.713571          0.2221   \n",
       "431  M29 CatBoost Tuned      0.738677        0.713442          0.2221   \n",
       "432  M30 CatBoost Tuned      0.739003        0.714696          0.2220   \n",
       "433  M31 CatBoost Tuned      0.738665        0.714524          0.2219   \n",
       "\n",
       "     Validation RMSLE  \n",
       "403            0.2349  \n",
       "404            0.2324  \n",
       "405            0.2287  \n",
       "406            0.2280  \n",
       "407            0.2280  \n",
       "408            0.2280  \n",
       "409            0.2280  \n",
       "410            0.2280  \n",
       "411            0.2280  \n",
       "412            0.2280  \n",
       "413            0.2280  \n",
       "414            0.2279  \n",
       "415            0.2279  \n",
       "416            0.2281  \n",
       "417            0.2279  \n",
       "418            0.2279  \n",
       "419            0.2280  \n",
       "420            0.2278  \n",
       "421            0.2277  \n",
       "422            0.2278  \n",
       "423            0.2278  \n",
       "424            0.2281  \n",
       "425            0.2281  \n",
       "426            0.2281  \n",
       "427            0.2279  \n",
       "428            0.2279  \n",
       "429            0.2279  \n",
       "430            0.2279  \n",
       "431            0.2279  \n",
       "432            0.2278  \n",
       "433            0.2278  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for group_name, features in models.items():\n",
    "    start_time = time.time()\n",
    "\n",
    "    cb_model = CatBoostClassifier(\n",
    "        iterations=2000,  # Explore more iterations for deeper learning\n",
    "        learning_rate=0.001,  # Further reduce learning rate for more gradual learning\n",
    "        depth=7,  # Slightly increase depth for capturing more complex patterns\n",
    "        l2_leaf_reg=5,  # Increase L2 regularization to control overfit depth's complexity\n",
    "        bagging_temperature=1,  # Introduce bagging for randomness, reducing overfitting\n",
    "        early_stopping_rounds=100,\n",
    "        random_state=20240325,\n",
    "        verbose=False)  # Use only a portion of data for each tree, increasing diversity\n",
    "    \n",
    "    cb_model.fit(X_train[features], y_train, eval_set=(X_val[features], y_val), early_stopping_rounds=50, verbose=False)\n",
    "\n",
    "    train_prob = cb_model.predict_proba(X_train[features])[:, 1]\n",
    "    val_prob = cb_model.predict_proba(X_val[features])[:, 1]\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, train_prob)\n",
    "    val_auc = roc_auc_score(y_val, val_prob)\n",
    "    \n",
    "    # Calculate RMSLE\n",
    "    train_rmsle = calculateRMSLE(train_prob, y_train)\n",
    "    val_rmsle = calculateRMSLE(val_prob, y_val)\n",
    "\n",
    "\n",
    "    new_row = pd.DataFrame([[f\"{group_name} CatBoost Tuned\", train_auc, val_auc, train_rmsle, val_rmsle]], \n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Completed {group_name} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df.tail(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a884036-8492-4ab0-b79d-01149db92e3e",
   "metadata": {},
   "source": [
    "## Explainable Boosting Machine\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89796388-b1e5-4406-b108-da038ed847c0",
   "metadata": {},
   "source": [
    "### Simple EBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40007e87-defa-4e48-9e55-a512a9d43122",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed M1 in 7.88 seconds\n",
      "Completed M2 in 5.56 seconds\n",
      "Completed M3 in 8.20 seconds\n",
      "Completed M4 in 8.54 seconds\n",
      "Completed M5 in 10.48 seconds\n",
      "Completed M6 in 16.10 seconds\n",
      "Completed M7 in 17.86 seconds\n",
      "Completed M8 in 18.70 seconds\n",
      "Completed M9 in 22.03 seconds\n",
      "Completed M10 in 29.12 seconds\n",
      "Completed M11 in 32.21 seconds\n",
      "Completed M12 in 15.36 seconds\n",
      "Completed M13 in 23.41 seconds\n",
      "Completed M14 in 23.31 seconds\n",
      "Completed M15 in 27.13 seconds\n",
      "Completed M16 in 28.41 seconds\n",
      "Completed M17 in 28.71 seconds\n",
      "Completed M18 in 45.57 seconds\n",
      "Completed M19 in 46.40 seconds\n",
      "Completed M20 in 58.07 seconds\n",
      "Completed M21 in 71.17 seconds\n",
      "Completed M22 in 20.55 seconds\n",
      "Completed M23 in 24.68 seconds\n",
      "Completed M24 in 30.64 seconds\n",
      "Completed M25 in 37.38 seconds\n",
      "Completed M26 in 38.50 seconds\n",
      "Completed M27 in 51.10 seconds\n",
      "Completed M28 in 60.19 seconds\n",
      "Completed M29 in 62.76 seconds\n",
      "Completed M30 in 80.82 seconds\n",
      "Completed M31 in 82.06 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>M1 EBM</td>\n",
       "      <td>0.628037</td>\n",
       "      <td>0.599450</td>\n",
       "      <td>0.2246</td>\n",
       "      <td>0.2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>M2 EBM</td>\n",
       "      <td>0.687042</td>\n",
       "      <td>0.658695</td>\n",
       "      <td>0.2211</td>\n",
       "      <td>0.2276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>M3 EBM</td>\n",
       "      <td>0.727854</td>\n",
       "      <td>0.710408</td>\n",
       "      <td>0.2182</td>\n",
       "      <td>0.2242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>M4 EBM</td>\n",
       "      <td>0.743061</td>\n",
       "      <td>0.718112</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>M5 EBM</td>\n",
       "      <td>0.744391</td>\n",
       "      <td>0.718935</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>M6 EBM</td>\n",
       "      <td>0.761945</td>\n",
       "      <td>0.724416</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.2235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>M7 EBM</td>\n",
       "      <td>0.765401</td>\n",
       "      <td>0.727386</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>M8 EBM</td>\n",
       "      <td>0.766168</td>\n",
       "      <td>0.726259</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>M9 EBM</td>\n",
       "      <td>0.762717</td>\n",
       "      <td>0.728033</td>\n",
       "      <td>0.2141</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>M10 EBM</td>\n",
       "      <td>0.766798</td>\n",
       "      <td>0.726993</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>M11 EBM</td>\n",
       "      <td>0.766312</td>\n",
       "      <td>0.726887</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>M12 EBM</td>\n",
       "      <td>0.760207</td>\n",
       "      <td>0.727088</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>M13 EBM</td>\n",
       "      <td>0.760188</td>\n",
       "      <td>0.725832</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>M14 EBM</td>\n",
       "      <td>0.761601</td>\n",
       "      <td>0.726991</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>M15 EBM</td>\n",
       "      <td>0.760804</td>\n",
       "      <td>0.726864</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>M16 EBM</td>\n",
       "      <td>0.761924</td>\n",
       "      <td>0.725496</td>\n",
       "      <td>0.2142</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>M17 EBM</td>\n",
       "      <td>0.771508</td>\n",
       "      <td>0.724410</td>\n",
       "      <td>0.2131</td>\n",
       "      <td>0.2235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>M18 EBM</td>\n",
       "      <td>0.783207</td>\n",
       "      <td>0.727065</td>\n",
       "      <td>0.2114</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>M19 EBM</td>\n",
       "      <td>0.790839</td>\n",
       "      <td>0.726561</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.2234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>M20 EBM</td>\n",
       "      <td>0.783635</td>\n",
       "      <td>0.726916</td>\n",
       "      <td>0.2114</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>M21 EBM</td>\n",
       "      <td>0.783100</td>\n",
       "      <td>0.725566</td>\n",
       "      <td>0.2115</td>\n",
       "      <td>0.2234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>M22 EBM</td>\n",
       "      <td>0.765821</td>\n",
       "      <td>0.726432</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>0.2234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>M23 EBM</td>\n",
       "      <td>0.762217</td>\n",
       "      <td>0.729273</td>\n",
       "      <td>0.2141</td>\n",
       "      <td>0.2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>M24 EBM</td>\n",
       "      <td>0.760277</td>\n",
       "      <td>0.726308</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>M25 EBM</td>\n",
       "      <td>0.759795</td>\n",
       "      <td>0.726340</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>M26 EBM</td>\n",
       "      <td>0.756982</td>\n",
       "      <td>0.725016</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>M27 EBM</td>\n",
       "      <td>0.762477</td>\n",
       "      <td>0.724901</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.2234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>M28 EBM</td>\n",
       "      <td>0.763246</td>\n",
       "      <td>0.724333</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.2234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>M29 EBM</td>\n",
       "      <td>0.758858</td>\n",
       "      <td>0.725428</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>0.2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>M30 EBM</td>\n",
       "      <td>0.779160</td>\n",
       "      <td>0.725136</td>\n",
       "      <td>0.2121</td>\n",
       "      <td>0.2234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>M31 EBM</td>\n",
       "      <td>0.781066</td>\n",
       "      <td>0.726712</td>\n",
       "      <td>0.2118</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Training AUC  Validation AUC  Training RMSLE  Validation RMSLE\n",
       "434   M1 EBM      0.628037        0.599450          0.2246            0.2300\n",
       "435   M2 EBM      0.687042        0.658695          0.2211            0.2276\n",
       "436   M3 EBM      0.727854        0.710408          0.2182            0.2242\n",
       "437   M4 EBM      0.743061        0.718112          0.2165            0.2240\n",
       "438   M5 EBM      0.744391        0.718935          0.2165            0.2239\n",
       "439   M6 EBM      0.761945        0.724416          0.2143            0.2235\n",
       "440   M7 EBM      0.765401        0.727386          0.2137            0.2232\n",
       "441   M8 EBM      0.766168        0.726259          0.2137            0.2233\n",
       "442   M9 EBM      0.762717        0.728033          0.2141            0.2232\n",
       "443  M10 EBM      0.766798        0.726993          0.2136            0.2231\n",
       "444  M11 EBM      0.766312        0.726887          0.2136            0.2232\n",
       "445  M12 EBM      0.760207        0.727088          0.2145            0.2231\n",
       "446  M13 EBM      0.760188        0.725832          0.2144            0.2232\n",
       "447  M14 EBM      0.761601        0.726991          0.2143            0.2232\n",
       "448  M15 EBM      0.760804        0.726864          0.2144            0.2231\n",
       "449  M16 EBM      0.761924        0.725496          0.2142            0.2233\n",
       "450  M17 EBM      0.771508        0.724410          0.2131            0.2235\n",
       "451  M18 EBM      0.783207        0.727065          0.2114            0.2233\n",
       "452  M19 EBM      0.790839        0.726561          0.2102            0.2234\n",
       "453  M20 EBM      0.783635        0.726916          0.2114            0.2233\n",
       "454  M21 EBM      0.783100        0.725566          0.2115            0.2234\n",
       "455  M22 EBM      0.765821        0.726432          0.2137            0.2234\n",
       "456  M23 EBM      0.762217        0.729273          0.2141            0.2230\n",
       "457  M24 EBM      0.760277        0.726308          0.2144            0.2233\n",
       "458  M25 EBM      0.759795        0.726340          0.2145            0.2231\n",
       "459  M26 EBM      0.756982        0.725016          0.2149            0.2233\n",
       "460  M27 EBM      0.762477        0.724901          0.2144            0.2234\n",
       "461  M28 EBM      0.763246        0.724333          0.2144            0.2234\n",
       "462  M29 EBM      0.758858        0.725428          0.2150            0.2231\n",
       "463  M30 EBM      0.779160        0.725136          0.2121            0.2234\n",
       "464  M31 EBM      0.781066        0.726712          0.2118            0.2233"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for group_name, features in models.items():\n",
    "    start_time = time.time()  # Timer start\n",
    "\n",
    "    # Adjusted EBM pipeline without SimpleImputer for numerical data\n",
    "    ebm = ExplainableBoostingClassifier(random_state=20240325)\n",
    "\n",
    "    ebm.fit(X_train[features], y_train)\n",
    "\n",
    "    # Predict probabilities for the positive class\n",
    "    train_prob = ebm.predict_proba(X_train[features])[:, 1]\n",
    "    val_prob = ebm.predict_proba(X_val[features])[:, 1]\n",
    "\n",
    "    # Calculate AUC scores using the probabilities\n",
    "    train_auc = roc_auc_score(y_train, train_prob)\n",
    "    val_auc = roc_auc_score(y_val, val_prob)\n",
    "    \n",
    "    # Calculate RMSLE\n",
    "    train_rmsle = calculateRMSLE(train_prob, y_train)\n",
    "    val_rmsle = calculateRMSLE(val_prob, y_val)\n",
    "\n",
    "    # Append results\n",
    "    new_row = pd.DataFrame([[f\"{group_name} EBM\", train_auc, val_auc, train_rmsle, val_rmsle]],\n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    end_time = time.time()  # End timer\n",
    "    print(f\"Completed {group_name} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df.tail(31)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6b300-aa17-430b-862e-eb8403fdc830",
   "metadata": {},
   "source": [
    "### **Permutation Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b995f98-0f95-4dee-9edd-cd3ad6dbee52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose a model (for example, M1 EBM) and its features for illustration\n",
    "ebm = ExplainableBoostingClassifier(random_state=20240325)\n",
    "ebm.fit(X_train[models['M7']], y_train)\n",
    "\n",
    "# Compute permutation-based feature importance\n",
    "perm_importance = permutation_importance(ebm, X_val[models['M7']], y_val, n_repeats=10, random_state=42, scoring='roc_auc')\n",
    "\n",
    "# Retrieve and display feature importances\n",
    "feature_names = np.array(models['M7'])\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(feature_names[sorted_idx], perm_importance.importances_mean[sorted_idx])\n",
    "plt.xlabel(\"Permutation Importance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2e5811f-cbf2-4d2c-afae-d082685b9590",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with positive permutation importance:\n",
      "n_tokens_title\n",
      "n_tokens_content\n",
      "n_unique_tokens\n",
      "n_non_stop_words\n",
      "n_non_stop_unique_tokens\n",
      "average_token_length\n",
      "num_hrefs\n",
      "num_self_hrefs\n",
      "num_imgs\n",
      "num_videos\n",
      "global_subjectivity\n",
      "global_sentiment_polarity\n",
      "kw_min_min\n",
      "kw_max_min\n",
      "kw_avg_min\n",
      "kw_min_max\n",
      "kw_max_max\n",
      "kw_avg_max\n",
      "kw_min_avg\n",
      "kw_max_avg\n",
      "kw_avg_avg\n",
      "self_reference_min_shares\n",
      "self_reference_max_shares\n",
      "self_reference_avg_sharess\n",
      "weekday_is_wednesday\n",
      "weekday_is_thursday\n",
      "weekday_is_saturday\n",
      "weekday_is_sunday\n",
      "data_channel_is_entertainment\n",
      "data_channel_is_bus\n",
      "data_channel_is_socmed\n",
      "data_channel_is_tech\n",
      "data_channel_is_world\n",
      "LDA_00\n",
      "LDA_01\n",
      "LDA_02\n",
      "LDA_03\n",
      "LDA_04\n",
      "avg_positive_polarity\n",
      "min_positive_polarity\n",
      "avg_negative_polarity\n",
      "min_negative_polarity\n",
      "title_subjectivity\n",
      "title_sentiment_polarity\n",
      "abs_title_subjectivity\n",
      "abs_title_sentiment_polarity\n",
      "Variable group with positive permutation importance:\n",
      "['n_tokens_title', 'n_tokens_content', 'n_unique_tokens', 'n_non_stop_words', 'n_non_stop_unique_tokens', 'average_token_length', 'num_hrefs', 'num_self_hrefs', 'num_imgs', 'num_videos', 'global_subjectivity', 'global_sentiment_polarity', 'kw_min_min', 'kw_max_min', 'kw_avg_min', 'kw_min_max', 'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg', 'kw_avg_avg', 'self_reference_min_shares', 'self_reference_max_shares', 'self_reference_avg_sharess', 'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_saturday', 'weekday_is_sunday', 'data_channel_is_entertainment', 'data_channel_is_bus', 'data_channel_is_socmed', 'data_channel_is_tech', 'data_channel_is_world', 'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'avg_positive_polarity', 'min_positive_polarity', 'avg_negative_polarity', 'min_negative_polarity', 'title_subjectivity', 'title_sentiment_polarity', 'abs_title_subjectivity', 'abs_title_sentiment_polarity']\n"
     ]
    }
   ],
   "source": [
    "# Assuming perm_importance is calculated as shown previously\n",
    "feature_names = np.array(models['M7'])  # Adjust to use the correct model features as needed\n",
    "\n",
    "# Identify features with positive permutation importance values\n",
    "positive_importance_features = feature_names[perm_importance.importances_mean > 0]\n",
    "\n",
    "# Print out the feature names\n",
    "print(\"Features with positive permutation importance:\")\n",
    "for feature in positive_importance_features:\n",
    "    print(feature)\n",
    "\n",
    "# Create a variable group with these features\n",
    "perm_importance_positive = positive_importance_features.tolist()\n",
    "\n",
    "print(\"Variable group with positive permutation importance:\")\n",
    "print(perm_importance_positive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45731658-2c1f-4bb3-9ea7-e949bff18bf9",
   "metadata": {},
   "source": [
    "### Adjusted EBM 1\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97d9ebe5-92b4-4d99-871a-7731a4d03813",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed M1 in 3.86 seconds\n",
      "Completed M2 in 4.43 seconds\n",
      "Completed M3 in 5.70 seconds\n",
      "Completed M4 in 6.81 seconds\n",
      "Completed M5 in 6.95 seconds\n",
      "Completed M6 in 12.10 seconds\n",
      "Completed M7 in 12.17 seconds\n",
      "Completed M8 in 12.84 seconds\n",
      "Completed M9 in 13.69 seconds\n",
      "Completed M10 in 19.48 seconds\n",
      "Completed M11 in 19.88 seconds\n",
      "Completed M12 in 10.35 seconds\n",
      "Completed M13 in 15.02 seconds\n",
      "Completed M14 in 15.56 seconds\n",
      "Completed M15 in 17.55 seconds\n",
      "Completed M16 in 18.07 seconds\n",
      "Completed M17 in 18.12 seconds\n",
      "Completed M18 in 27.47 seconds\n",
      "Completed M19 in 27.29 seconds\n",
      "Completed M20 in 34.66 seconds\n",
      "Completed M21 in 42.02 seconds\n",
      "Completed M22 in 13.70 seconds\n",
      "Completed M23 in 16.18 seconds\n",
      "Completed M24 in 19.84 seconds\n",
      "Completed M25 in 24.07 seconds\n",
      "Completed M26 in 24.39 seconds\n",
      "Completed M27 in 32.04 seconds\n",
      "Completed M28 in 37.78 seconds\n",
      "Completed M29 in 38.65 seconds\n",
      "Completed M30 in 49.82 seconds\n",
      "Completed M31 in 51.07 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>M1 EBM Adjusted 1</td>\n",
       "      <td>0.636023</td>\n",
       "      <td>0.607193</td>\n",
       "      <td>0.2242</td>\n",
       "      <td>0.2297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>M2 EBM Adjusted 1</td>\n",
       "      <td>0.678342</td>\n",
       "      <td>0.658737</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>M3 EBM Adjusted 1</td>\n",
       "      <td>0.718354</td>\n",
       "      <td>0.709401</td>\n",
       "      <td>0.2193</td>\n",
       "      <td>0.2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>M4 EBM Adjusted 1</td>\n",
       "      <td>0.728440</td>\n",
       "      <td>0.718318</td>\n",
       "      <td>0.2185</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>M5 EBM Adjusted 1</td>\n",
       "      <td>0.729174</td>\n",
       "      <td>0.719371</td>\n",
       "      <td>0.2184</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>M6 EBM Adjusted 1</td>\n",
       "      <td>0.741476</td>\n",
       "      <td>0.724784</td>\n",
       "      <td>0.2172</td>\n",
       "      <td>0.2235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>M7 EBM Adjusted 1</td>\n",
       "      <td>0.742880</td>\n",
       "      <td>0.725028</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>M8 EBM Adjusted 1</td>\n",
       "      <td>0.743572</td>\n",
       "      <td>0.725698</td>\n",
       "      <td>0.2169</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>M9 EBM Adjusted 1</td>\n",
       "      <td>0.738593</td>\n",
       "      <td>0.726296</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>M10 EBM Adjusted 1</td>\n",
       "      <td>0.739305</td>\n",
       "      <td>0.727329</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>M11 EBM Adjusted 1</td>\n",
       "      <td>0.738411</td>\n",
       "      <td>0.726542</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>M12 EBM Adjusted 1</td>\n",
       "      <td>0.741744</td>\n",
       "      <td>0.724843</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.2234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>M13 EBM Adjusted 1</td>\n",
       "      <td>0.738455</td>\n",
       "      <td>0.725163</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>M14 EBM Adjusted 1</td>\n",
       "      <td>0.740413</td>\n",
       "      <td>0.726406</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>M15 EBM Adjusted 1</td>\n",
       "      <td>0.736548</td>\n",
       "      <td>0.725262</td>\n",
       "      <td>0.2178</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>M16 EBM Adjusted 1</td>\n",
       "      <td>0.737079</td>\n",
       "      <td>0.724997</td>\n",
       "      <td>0.2177</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>M17 EBM Adjusted 1</td>\n",
       "      <td>0.746843</td>\n",
       "      <td>0.726236</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>M18 EBM Adjusted 1</td>\n",
       "      <td>0.755229</td>\n",
       "      <td>0.727098</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>M19 EBM Adjusted 1</td>\n",
       "      <td>0.753422</td>\n",
       "      <td>0.728563</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>M20 EBM Adjusted 1</td>\n",
       "      <td>0.748417</td>\n",
       "      <td>0.727667</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>M21 EBM Adjusted 1</td>\n",
       "      <td>0.745826</td>\n",
       "      <td>0.727762</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>M22 EBM Adjusted 1</td>\n",
       "      <td>0.741926</td>\n",
       "      <td>0.726765</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>M23 EBM Adjusted 1</td>\n",
       "      <td>0.736410</td>\n",
       "      <td>0.725763</td>\n",
       "      <td>0.2178</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>M24 EBM Adjusted 1</td>\n",
       "      <td>0.736663</td>\n",
       "      <td>0.724825</td>\n",
       "      <td>0.2179</td>\n",
       "      <td>0.2234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>M25 EBM Adjusted 1</td>\n",
       "      <td>0.737436</td>\n",
       "      <td>0.724272</td>\n",
       "      <td>0.2177</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>M26 EBM Adjusted 1</td>\n",
       "      <td>0.733850</td>\n",
       "      <td>0.724753</td>\n",
       "      <td>0.2181</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>M27 EBM Adjusted 1</td>\n",
       "      <td>0.735912</td>\n",
       "      <td>0.724925</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>0.2234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>M28 EBM Adjusted 1</td>\n",
       "      <td>0.737813</td>\n",
       "      <td>0.724208</td>\n",
       "      <td>0.2177</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>M29 EBM Adjusted 1</td>\n",
       "      <td>0.736539</td>\n",
       "      <td>0.724705</td>\n",
       "      <td>0.2178</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>M30 EBM Adjusted 1</td>\n",
       "      <td>0.743963</td>\n",
       "      <td>0.726811</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>M31 EBM Adjusted 1</td>\n",
       "      <td>0.742422</td>\n",
       "      <td>0.726985</td>\n",
       "      <td>0.2172</td>\n",
       "      <td>0.2230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "465   M1 EBM Adjusted 1      0.636023        0.607193          0.2242   \n",
       "466   M2 EBM Adjusted 1      0.678342        0.658737          0.2218   \n",
       "467   M3 EBM Adjusted 1      0.718354        0.709401          0.2193   \n",
       "468   M4 EBM Adjusted 1      0.728440        0.718318          0.2185   \n",
       "469   M5 EBM Adjusted 1      0.729174        0.719371          0.2184   \n",
       "470   M6 EBM Adjusted 1      0.741476        0.724784          0.2172   \n",
       "471   M7 EBM Adjusted 1      0.742880        0.725028          0.2170   \n",
       "472   M8 EBM Adjusted 1      0.743572        0.725698          0.2169   \n",
       "473   M9 EBM Adjusted 1      0.738593        0.726296          0.2175   \n",
       "474  M10 EBM Adjusted 1      0.739305        0.727329          0.2174   \n",
       "475  M11 EBM Adjusted 1      0.738411        0.726542          0.2175   \n",
       "476  M12 EBM Adjusted 1      0.741744        0.724843          0.2171   \n",
       "477  M13 EBM Adjusted 1      0.738455        0.725163          0.2175   \n",
       "478  M14 EBM Adjusted 1      0.740413        0.726406          0.2173   \n",
       "479  M15 EBM Adjusted 1      0.736548        0.725262          0.2178   \n",
       "480  M16 EBM Adjusted 1      0.737079        0.724997          0.2177   \n",
       "481  M17 EBM Adjusted 1      0.746843        0.726236          0.2167   \n",
       "482  M18 EBM Adjusted 1      0.755229        0.727098          0.2155   \n",
       "483  M19 EBM Adjusted 1      0.753422        0.728563          0.2156   \n",
       "484  M20 EBM Adjusted 1      0.748417        0.727667          0.2164   \n",
       "485  M21 EBM Adjusted 1      0.745826        0.727762          0.2167   \n",
       "486  M22 EBM Adjusted 1      0.741926        0.726765          0.2171   \n",
       "487  M23 EBM Adjusted 1      0.736410        0.725763          0.2178   \n",
       "488  M24 EBM Adjusted 1      0.736663        0.724825          0.2179   \n",
       "489  M25 EBM Adjusted 1      0.737436        0.724272          0.2177   \n",
       "490  M26 EBM Adjusted 1      0.733850        0.724753          0.2181   \n",
       "491  M27 EBM Adjusted 1      0.735912        0.724925          0.2180   \n",
       "492  M28 EBM Adjusted 1      0.737813        0.724208          0.2177   \n",
       "493  M29 EBM Adjusted 1      0.736539        0.724705          0.2178   \n",
       "494  M30 EBM Adjusted 1      0.743963        0.726811          0.2170   \n",
       "495  M31 EBM Adjusted 1      0.742422        0.726985          0.2172   \n",
       "\n",
       "     Validation RMSLE  \n",
       "465            0.2297  \n",
       "466            0.2277  \n",
       "467            0.2243  \n",
       "468            0.2239  \n",
       "469            0.2238  \n",
       "470            0.2235  \n",
       "471            0.2233  \n",
       "472            0.2233  \n",
       "473            0.2232  \n",
       "474            0.2231  \n",
       "475            0.2231  \n",
       "476            0.2234  \n",
       "477            0.2232  \n",
       "478            0.2232  \n",
       "479            0.2232  \n",
       "480            0.2233  \n",
       "481            0.2232  \n",
       "482            0.2231  \n",
       "483            0.2230  \n",
       "484            0.2230  \n",
       "485            0.2230  \n",
       "486            0.2232  \n",
       "487            0.2232  \n",
       "488            0.2234  \n",
       "489            0.2233  \n",
       "490            0.2233  \n",
       "491            0.2234  \n",
       "492            0.2233  \n",
       "493            0.2232  \n",
       "494            0.2230  \n",
       "495            0.2230  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for group_name, features in models.items():\n",
    "    start_time = time.time()  # Timer start\n",
    "\n",
    "    # Adjusted EBM pipeline without SimpleImputer for numerical data\n",
    "    ebm_adjusted = ExplainableBoostingClassifier(\n",
    "        random_state=20240325,\n",
    "        learning_rate=0.01,\n",
    "        max_bins=256,\n",
    "        interactions=10,\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "\n",
    "    ebm_adjusted.fit(X_train[features], y_train)\n",
    "\n",
    "    # Predict probabilities for the positive class\n",
    "    train_prob = ebm_adjusted.predict_proba(X_train[features])[:, 1]\n",
    "    val_prob = ebm_adjusted.predict_proba(X_val[features])[:, 1]\n",
    "\n",
    "    # Calculate AUC scores using the probabilities\n",
    "    train_auc = roc_auc_score(y_train, train_prob)\n",
    "    val_auc = roc_auc_score(y_val, val_prob)\n",
    "    \n",
    "    # Calculate RMSLE\n",
    "    train_rmsle = calculateRMSLE(train_prob, y_train)\n",
    "    val_rmsle = calculateRMSLE(val_prob, y_val)\n",
    "\n",
    "    # Append results\n",
    "    new_row = pd.DataFrame([[f\"{group_name} EBM Adjusted 1\", train_auc, val_auc, train_rmsle, val_rmsle]],\n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    end_time = time.time()  # End timer\n",
    "    print(f\"Completed {group_name} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df.tail(31)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbaad88-bf56-4be3-be06-d69f2f84b484",
   "metadata": {},
   "source": [
    "### Adjusted EBM 2\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa4816a1-c3d0-4a73-b0eb-3daa4dc0453c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed M1 in 7.39 seconds\n",
      "Completed M2 in 7.72 seconds\n",
      "Completed M3 in 9.87 seconds\n",
      "Completed M4 in 10.86 seconds\n",
      "Completed M5 in 11.57 seconds\n",
      "Completed M6 in 17.13 seconds\n",
      "Completed M7 in 18.03 seconds\n",
      "Completed M8 in 19.27 seconds\n",
      "Completed M9 in 21.18 seconds\n",
      "Completed M10 in 27.25 seconds\n",
      "Completed M11 in 29.29 seconds\n",
      "Completed M12 in 15.10 seconds\n",
      "Completed M13 in 22.38 seconds\n",
      "Completed M14 in 23.96 seconds\n",
      "Completed M15 in 25.75 seconds\n",
      "Completed M16 in 26.29 seconds\n",
      "Completed M17 in 26.70 seconds\n",
      "Completed M18 in 42.31 seconds\n",
      "Completed M19 in 42.00 seconds\n",
      "Completed M20 in 51.85 seconds\n",
      "Completed M21 in 62.51 seconds\n",
      "Completed M22 in 20.08 seconds\n",
      "Completed M23 in 23.93 seconds\n",
      "Completed M24 in 28.01 seconds\n",
      "Completed M25 in 33.66 seconds\n",
      "Completed M26 in 35.50 seconds\n",
      "Completed M27 in 44.24 seconds\n",
      "Completed M28 in 53.32 seconds\n",
      "Completed M29 in 55.19 seconds\n",
      "Completed M30 in 73.72 seconds\n",
      "Completed M31 in 73.84 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>M1 EBM Adjusted 2</td>\n",
       "      <td>0.640790</td>\n",
       "      <td>0.604144</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.2297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>M2 EBM Adjusted 2</td>\n",
       "      <td>0.685208</td>\n",
       "      <td>0.658450</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>M3 EBM Adjusted 2</td>\n",
       "      <td>0.725316</td>\n",
       "      <td>0.712219</td>\n",
       "      <td>0.2187</td>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>M4 EBM Adjusted 2</td>\n",
       "      <td>0.735612</td>\n",
       "      <td>0.719000</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>M5 EBM Adjusted 2</td>\n",
       "      <td>0.736297</td>\n",
       "      <td>0.719678</td>\n",
       "      <td>0.2176</td>\n",
       "      <td>0.2237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>M6 EBM Adjusted 2</td>\n",
       "      <td>0.745007</td>\n",
       "      <td>0.722964</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.2235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>M7 EBM Adjusted 2</td>\n",
       "      <td>0.746603</td>\n",
       "      <td>0.725448</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>M8 EBM Adjusted 2</td>\n",
       "      <td>0.746996</td>\n",
       "      <td>0.725894</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>M9 EBM Adjusted 2</td>\n",
       "      <td>0.743411</td>\n",
       "      <td>0.725140</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>M10 EBM Adjusted 2</td>\n",
       "      <td>0.740707</td>\n",
       "      <td>0.724105</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>M11 EBM Adjusted 2</td>\n",
       "      <td>0.738092</td>\n",
       "      <td>0.725196</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>M12 EBM Adjusted 2</td>\n",
       "      <td>0.742293</td>\n",
       "      <td>0.723971</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>M13 EBM Adjusted 2</td>\n",
       "      <td>0.745445</td>\n",
       "      <td>0.724357</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>M14 EBM Adjusted 2</td>\n",
       "      <td>0.745211</td>\n",
       "      <td>0.725595</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>M15 EBM Adjusted 2</td>\n",
       "      <td>0.742294</td>\n",
       "      <td>0.724800</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>M16 EBM Adjusted 2</td>\n",
       "      <td>0.743081</td>\n",
       "      <td>0.724533</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>M17 EBM Adjusted 2</td>\n",
       "      <td>0.749817</td>\n",
       "      <td>0.726238</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>M18 EBM Adjusted 2</td>\n",
       "      <td>0.759832</td>\n",
       "      <td>0.728308</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>0.2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>M19 EBM Adjusted 2</td>\n",
       "      <td>0.756544</td>\n",
       "      <td>0.729734</td>\n",
       "      <td>0.2153</td>\n",
       "      <td>0.2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>M20 EBM Adjusted 2</td>\n",
       "      <td>0.753729</td>\n",
       "      <td>0.728196</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>M21 EBM Adjusted 2</td>\n",
       "      <td>0.750283</td>\n",
       "      <td>0.726772</td>\n",
       "      <td>0.2161</td>\n",
       "      <td>0.2229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>M22 EBM Adjusted 2</td>\n",
       "      <td>0.747202</td>\n",
       "      <td>0.726052</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>M23 EBM Adjusted 2</td>\n",
       "      <td>0.740450</td>\n",
       "      <td>0.724853</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>M24 EBM Adjusted 2</td>\n",
       "      <td>0.742782</td>\n",
       "      <td>0.724551</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>M25 EBM Adjusted 2</td>\n",
       "      <td>0.736484</td>\n",
       "      <td>0.725186</td>\n",
       "      <td>0.2178</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>M26 EBM Adjusted 2</td>\n",
       "      <td>0.734731</td>\n",
       "      <td>0.724442</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>M27 EBM Adjusted 2</td>\n",
       "      <td>0.734562</td>\n",
       "      <td>0.724694</td>\n",
       "      <td>0.2181</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>M28 EBM Adjusted 2</td>\n",
       "      <td>0.736742</td>\n",
       "      <td>0.724625</td>\n",
       "      <td>0.2178</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>M29 EBM Adjusted 2</td>\n",
       "      <td>0.736133</td>\n",
       "      <td>0.724560</td>\n",
       "      <td>0.2179</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>M30 EBM Adjusted 2</td>\n",
       "      <td>0.747995</td>\n",
       "      <td>0.727965</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>M31 EBM Adjusted 2</td>\n",
       "      <td>0.746505</td>\n",
       "      <td>0.726678</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.2230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "496   M1 EBM Adjusted 2      0.640790        0.604144          0.2240   \n",
       "497   M2 EBM Adjusted 2      0.685208        0.658450          0.2213   \n",
       "498   M3 EBM Adjusted 2      0.725316        0.712219          0.2187   \n",
       "499   M4 EBM Adjusted 2      0.735612        0.719000          0.2175   \n",
       "500   M5 EBM Adjusted 2      0.736297        0.719678          0.2176   \n",
       "501   M6 EBM Adjusted 2      0.745007        0.722964          0.2167   \n",
       "502   M7 EBM Adjusted 2      0.746603        0.725448          0.2165   \n",
       "503   M8 EBM Adjusted 2      0.746996        0.725894          0.2164   \n",
       "504   M9 EBM Adjusted 2      0.743411        0.725140          0.2170   \n",
       "505  M10 EBM Adjusted 2      0.740707        0.724105          0.2173   \n",
       "506  M11 EBM Adjusted 2      0.738092        0.725196          0.2175   \n",
       "507  M12 EBM Adjusted 2      0.742293        0.723971          0.2170   \n",
       "508  M13 EBM Adjusted 2      0.745445        0.724357          0.2167   \n",
       "509  M14 EBM Adjusted 2      0.745211        0.725595          0.2167   \n",
       "510  M15 EBM Adjusted 2      0.742294        0.724800          0.2171   \n",
       "511  M16 EBM Adjusted 2      0.743081        0.724533          0.2170   \n",
       "512  M17 EBM Adjusted 2      0.749817        0.726238          0.2162   \n",
       "513  M18 EBM Adjusted 2      0.759832        0.728308          0.2149   \n",
       "514  M19 EBM Adjusted 2      0.756544        0.729734          0.2153   \n",
       "515  M20 EBM Adjusted 2      0.753729        0.728196          0.2156   \n",
       "516  M21 EBM Adjusted 2      0.750283        0.726772          0.2161   \n",
       "517  M22 EBM Adjusted 2      0.747202        0.726052          0.2164   \n",
       "518  M23 EBM Adjusted 2      0.740450        0.724853          0.2174   \n",
       "519  M24 EBM Adjusted 2      0.742782        0.724551          0.2171   \n",
       "520  M25 EBM Adjusted 2      0.736484        0.725186          0.2178   \n",
       "521  M26 EBM Adjusted 2      0.734731        0.724442          0.2180   \n",
       "522  M27 EBM Adjusted 2      0.734562        0.724694          0.2181   \n",
       "523  M28 EBM Adjusted 2      0.736742        0.724625          0.2178   \n",
       "524  M29 EBM Adjusted 2      0.736133        0.724560          0.2179   \n",
       "525  M30 EBM Adjusted 2      0.747995        0.727965          0.2164   \n",
       "526  M31 EBM Adjusted 2      0.746505        0.726678          0.2166   \n",
       "\n",
       "     Validation RMSLE  \n",
       "496            0.2297  \n",
       "497            0.2277  \n",
       "498            0.2240  \n",
       "499            0.2238  \n",
       "500            0.2237  \n",
       "501            0.2235  \n",
       "502            0.2233  \n",
       "503            0.2233  \n",
       "504            0.2233  \n",
       "505            0.2233  \n",
       "506            0.2232  \n",
       "507            0.2233  \n",
       "508            0.2233  \n",
       "509            0.2232  \n",
       "510            0.2232  \n",
       "511            0.2233  \n",
       "512            0.2232  \n",
       "513            0.2231  \n",
       "514            0.2230  \n",
       "515            0.2230  \n",
       "516            0.2229  \n",
       "517            0.2233  \n",
       "518            0.2233  \n",
       "519            0.2233  \n",
       "520            0.2232  \n",
       "521            0.2233  \n",
       "522            0.2233  \n",
       "523            0.2232  \n",
       "524            0.2232  \n",
       "525            0.2228  \n",
       "526            0.2230  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for group_name, features in models.items():\n",
    "    start_time = time.time()\n",
    "\n",
    "    ebm_more_adjusted = ExplainableBoostingClassifier(\n",
    "        random_state=20240325,\n",
    "        learning_rate=0.005,  # Slightly lower learning rate for more fine-grained adjustments\n",
    "        max_bins=512,  # Increased number of bins for potentially capturing more detail\n",
    "        interactions=15,  # Allowing for more interactions\n",
    "        early_stopping_rounds=100,  # More patience on early stopping to allow more rounds for convergence\n",
    "        n_jobs=-1  # Utilize all CPU cores for faster training\n",
    "    )\n",
    "\n",
    "    ebm_more_adjusted.fit(X_train[features], y_train)\n",
    "\n",
    "    train_prob = ebm_more_adjusted.predict_proba(X_train[features])[:, 1]\n",
    "    val_prob = ebm_more_adjusted.predict_proba(X_val[features])[:, 1]\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, train_prob)\n",
    "    val_auc = roc_auc_score(y_val, val_prob)\n",
    "\n",
    "    train_rmsle = calculateRMSLE(train_prob, y_train)\n",
    "    val_rmsle = calculateRMSLE(val_prob, y_val)\n",
    "\n",
    "    new_row = pd.DataFrame([[f\"{group_name} EBM Adjusted 2\", train_auc, val_auc, train_rmsle, val_rmsle]], \n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Completed {group_name} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df.tail(31)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a0b07d-bede-4715-9b44-63dad2582cd8",
   "metadata": {},
   "source": [
    "## Neural Network Models\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4bf6c0b-0f6b-4aff-a8e9-2dd0f21c0a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "    \n",
    "# Reshape your data accordingly\n",
    "X_train_reshaped = X_train_scaled.reshape((-1, n_features, 1)) \n",
    "X_val_reshaped = X_val_scaled.reshape((-1, n_features, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60bd9a9-5916-4582-942d-8fc149208216",
   "metadata": {},
   "source": [
    "### Simple Neural Network Model 1\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8141f855-6669-4799-aef5-5dc95be7b67d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed M1 in 7.06 seconds\n",
      "Completed M2 in 8.11 seconds\n",
      "Completed M3 in 7.84 seconds\n",
      "Completed M4 in 6.69 seconds\n",
      "Completed M5 in 8.90 seconds\n",
      "Completed M6 in 7.41 seconds\n",
      "Completed M7 in 7.84 seconds\n",
      "Completed M8 in 7.43 seconds\n",
      "Completed M9 in 7.79 seconds\n",
      "Completed M10 in 6.70 seconds\n",
      "Completed M11 in 9.24 seconds\n",
      "Completed M12 in 8.11 seconds\n",
      "Completed M13 in 6.24 seconds\n",
      "Completed M14 in 8.25 seconds\n",
      "Completed M15 in 6.54 seconds\n",
      "Completed M16 in 8.50 seconds\n",
      "Completed M17 in 6.86 seconds\n",
      "Completed M18 in 4.98 seconds\n",
      "Completed M19 in 4.65 seconds\n",
      "Completed M20 in 6.30 seconds\n",
      "Completed M21 in 5.61 seconds\n",
      "Completed M22 in 6.75 seconds\n",
      "Completed M23 in 5.55 seconds\n",
      "Completed M24 in 9.07 seconds\n",
      "Completed M25 in 10.98 seconds\n",
      "Completed M26 in 8.35 seconds\n",
      "Completed M27 in 8.71 seconds\n",
      "Completed M28 in 8.41 seconds\n",
      "Completed M29 in 9.44 seconds\n",
      "Completed M30 in 6.08 seconds\n",
      "Completed M31 in 5.09 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.741335</td>\n",
       "      <td>0.697379</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.762277</td>\n",
       "      <td>0.697792</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.763364</td>\n",
       "      <td>0.697828</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.748440</td>\n",
       "      <td>0.696561</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.763079</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.759928</td>\n",
       "      <td>0.701576</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.753629</td>\n",
       "      <td>0.691433</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.759079</td>\n",
       "      <td>0.703278</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.756915</td>\n",
       "      <td>0.699650</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.747009</td>\n",
       "      <td>0.702391</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.760823</td>\n",
       "      <td>0.702124</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.764183</td>\n",
       "      <td>0.695668</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.748486</td>\n",
       "      <td>0.701846</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.764888</td>\n",
       "      <td>0.697487</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.740686</td>\n",
       "      <td>0.697459</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.764389</td>\n",
       "      <td>0.696239</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.745908</td>\n",
       "      <td>0.695658</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.713361</td>\n",
       "      <td>0.698802</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.714093</td>\n",
       "      <td>0.698813</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.727177</td>\n",
       "      <td>0.696039</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.735637</td>\n",
       "      <td>0.699231</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.754121</td>\n",
       "      <td>0.699695</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.736498</td>\n",
       "      <td>0.700157</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.769709</td>\n",
       "      <td>0.699743</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.775640</td>\n",
       "      <td>0.698962</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.762922</td>\n",
       "      <td>0.694514</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.768229</td>\n",
       "      <td>0.699622</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.764222</td>\n",
       "      <td>0.697586</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.766511</td>\n",
       "      <td>0.700379</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.744096</td>\n",
       "      <td>0.691332</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>M31 NN Simple</td>\n",
       "      <td>0.722249</td>\n",
       "      <td>0.702998</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "527  M31 NN Simple      0.741335        0.697379          0.2166   \n",
       "528  M31 NN Simple      0.762277        0.697792          0.2166   \n",
       "529  M31 NN Simple      0.763364        0.697828          0.2166   \n",
       "530  M31 NN Simple      0.748440        0.696561          0.2166   \n",
       "531  M31 NN Simple      0.763079        0.701149          0.2166   \n",
       "532  M31 NN Simple      0.759928        0.701576          0.2166   \n",
       "533  M31 NN Simple      0.753629        0.691433          0.2166   \n",
       "534  M31 NN Simple      0.759079        0.703278          0.2166   \n",
       "535  M31 NN Simple      0.756915        0.699650          0.2166   \n",
       "536  M31 NN Simple      0.747009        0.702391          0.2166   \n",
       "537  M31 NN Simple      0.760823        0.702124          0.2166   \n",
       "538  M31 NN Simple      0.764183        0.695668          0.2166   \n",
       "539  M31 NN Simple      0.748486        0.701846          0.2166   \n",
       "540  M31 NN Simple      0.764888        0.697487          0.2166   \n",
       "541  M31 NN Simple      0.740686        0.697459          0.2166   \n",
       "542  M31 NN Simple      0.764389        0.696239          0.2166   \n",
       "543  M31 NN Simple      0.745908        0.695658          0.2166   \n",
       "544  M31 NN Simple      0.713361        0.698802          0.2166   \n",
       "545  M31 NN Simple      0.714093        0.698813          0.2166   \n",
       "546  M31 NN Simple      0.727177        0.696039          0.2166   \n",
       "547  M31 NN Simple      0.735637        0.699231          0.2166   \n",
       "548  M31 NN Simple      0.754121        0.699695          0.2166   \n",
       "549  M31 NN Simple      0.736498        0.700157          0.2166   \n",
       "550  M31 NN Simple      0.769709        0.699743          0.2166   \n",
       "551  M31 NN Simple      0.775640        0.698962          0.2166   \n",
       "552  M31 NN Simple      0.762922        0.694514          0.2166   \n",
       "553  M31 NN Simple      0.768229        0.699622          0.2166   \n",
       "554  M31 NN Simple      0.764222        0.697586          0.2166   \n",
       "555  M31 NN Simple      0.766511        0.700379          0.2166   \n",
       "556  M31 NN Simple      0.744096        0.691332          0.2166   \n",
       "557  M31 NN Simple      0.722249        0.702998          0.2166   \n",
       "\n",
       "     Validation RMSLE  \n",
       "527             0.223  \n",
       "528             0.223  \n",
       "529             0.223  \n",
       "530             0.223  \n",
       "531             0.223  \n",
       "532             0.223  \n",
       "533             0.223  \n",
       "534             0.223  \n",
       "535             0.223  \n",
       "536             0.223  \n",
       "537             0.223  \n",
       "538             0.223  \n",
       "539             0.223  \n",
       "540             0.223  \n",
       "541             0.223  \n",
       "542             0.223  \n",
       "543             0.223  \n",
       "544             0.223  \n",
       "545             0.223  \n",
       "546             0.223  \n",
       "547             0.223  \n",
       "548             0.223  \n",
       "549             0.223  \n",
       "550             0.223  \n",
       "551             0.223  \n",
       "552             0.223  \n",
       "553             0.223  \n",
       "554             0.223  \n",
       "555             0.223  \n",
       "556             0.223  \n",
       "557             0.223  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model_name, features in models.items():\n",
    "    start_time = time.time()  # Timer start\n",
    "    \n",
    "    # Define the model\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=[AUC(name='auc')])\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0,\n",
    "              validation_data=(X_val_scaled, y_val),\n",
    "              callbacks=[EarlyStopping(monitor='val_auc', patience=3, restore_best_weights=True, mode='max')])\n",
    "\n",
    "    _, train_auc = model.evaluate(X_train_scaled, y_train, verbose=0)\n",
    "    _, val_auc = model.evaluate(X_val_scaled, y_val, verbose=0)\n",
    "    \n",
    "    train_rmsle = calculateRMSLE(train_prob, y_train)\n",
    "    val_rmsle = calculateRMSLE(val_prob, y_val)\n",
    "    \n",
    "    new_row = pd.DataFrame([[f\"{group_name} NN Simple\", train_auc, val_auc, train_rmsle, val_rmsle]], \n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "    \n",
    "    end_time = time.time()  # End timer\n",
    "    print(f\"Completed {model_name} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df.tail(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2630f1da-6084-492b-9beb-22f978372f3b",
   "metadata": {},
   "source": [
    "### Simple Neural Network Model 2\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22e0de60-d318-43d9-8592-0df2d73b17fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed M1 in 21.17 seconds\n",
      "Completed M2 in 14.99 seconds\n",
      "Completed M3 in 19.28 seconds\n",
      "Completed M4 in 28.84 seconds\n",
      "Completed M5 in 16.66 seconds\n",
      "Completed M6 in 22.48 seconds\n",
      "Completed M7 in 20.77 seconds\n",
      "Completed M8 in 13.06 seconds\n",
      "Completed M9 in 10.00 seconds\n",
      "Completed M10 in 16.34 seconds\n",
      "Completed M11 in 15.49 seconds\n",
      "Completed M12 in 21.39 seconds\n",
      "Completed M13 in 22.12 seconds\n",
      "Completed M14 in 14.68 seconds\n",
      "Completed M15 in 15.50 seconds\n",
      "Completed M16 in 13.02 seconds\n",
      "Completed M17 in 16.72 seconds\n",
      "Completed M18 in 14.25 seconds\n",
      "Completed M19 in 20.13 seconds\n",
      "Completed M20 in 14.43 seconds\n",
      "Completed M21 in 15.43 seconds\n",
      "Completed M22 in 19.43 seconds\n",
      "Completed M23 in 15.39 seconds\n",
      "Completed M24 in 22.35 seconds\n",
      "Completed M25 in 19.67 seconds\n",
      "Completed M26 in 22.62 seconds\n",
      "Completed M27 in 17.53 seconds\n",
      "Completed M28 in 11.37 seconds\n",
      "Completed M29 in 18.73 seconds\n",
      "Completed M30 in 19.35 seconds\n",
      "Completed M31 in 14.61 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.735007</td>\n",
       "      <td>0.711569</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.721606</td>\n",
       "      <td>0.709027</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.730091</td>\n",
       "      <td>0.712359</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.744425</td>\n",
       "      <td>0.713225</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.722596</td>\n",
       "      <td>0.710438</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.734413</td>\n",
       "      <td>0.709325</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.734427</td>\n",
       "      <td>0.713802</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.719356</td>\n",
       "      <td>0.713082</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.714103</td>\n",
       "      <td>0.711539</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.725969</td>\n",
       "      <td>0.711156</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.724496</td>\n",
       "      <td>0.711650</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.734949</td>\n",
       "      <td>0.712868</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.735455</td>\n",
       "      <td>0.713970</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.720712</td>\n",
       "      <td>0.710623</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.725633</td>\n",
       "      <td>0.712650</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.717147</td>\n",
       "      <td>0.711825</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.723081</td>\n",
       "      <td>0.711703</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.720874</td>\n",
       "      <td>0.712989</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.729694</td>\n",
       "      <td>0.712246</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.721147</td>\n",
       "      <td>0.710628</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.722792</td>\n",
       "      <td>0.711507</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.729305</td>\n",
       "      <td>0.712246</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.724951</td>\n",
       "      <td>0.710409</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.735535</td>\n",
       "      <td>0.712052</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.730657</td>\n",
       "      <td>0.714916</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.736531</td>\n",
       "      <td>0.715483</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.725283</td>\n",
       "      <td>0.709696</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.715883</td>\n",
       "      <td>0.709546</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.730486</td>\n",
       "      <td>0.715034</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.731919</td>\n",
       "      <td>0.709702</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>M31 NN Simple 2</td>\n",
       "      <td>0.723552</td>\n",
       "      <td>0.709553</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "558  M31 NN Simple 2      0.735007        0.711569          0.2166   \n",
       "559  M31 NN Simple 2      0.721606        0.709027          0.2166   \n",
       "560  M31 NN Simple 2      0.730091        0.712359          0.2166   \n",
       "561  M31 NN Simple 2      0.744425        0.713225          0.2166   \n",
       "562  M31 NN Simple 2      0.722596        0.710438          0.2166   \n",
       "563  M31 NN Simple 2      0.734413        0.709325          0.2166   \n",
       "564  M31 NN Simple 2      0.734427        0.713802          0.2166   \n",
       "565  M31 NN Simple 2      0.719356        0.713082          0.2166   \n",
       "566  M31 NN Simple 2      0.714103        0.711539          0.2166   \n",
       "567  M31 NN Simple 2      0.725969        0.711156          0.2166   \n",
       "568  M31 NN Simple 2      0.724496        0.711650          0.2166   \n",
       "569  M31 NN Simple 2      0.734949        0.712868          0.2166   \n",
       "570  M31 NN Simple 2      0.735455        0.713970          0.2166   \n",
       "571  M31 NN Simple 2      0.720712        0.710623          0.2166   \n",
       "572  M31 NN Simple 2      0.725633        0.712650          0.2166   \n",
       "573  M31 NN Simple 2      0.717147        0.711825          0.2166   \n",
       "574  M31 NN Simple 2      0.723081        0.711703          0.2166   \n",
       "575  M31 NN Simple 2      0.720874        0.712989          0.2166   \n",
       "576  M31 NN Simple 2      0.729694        0.712246          0.2166   \n",
       "577  M31 NN Simple 2      0.721147        0.710628          0.2166   \n",
       "578  M31 NN Simple 2      0.722792        0.711507          0.2166   \n",
       "579  M31 NN Simple 2      0.729305        0.712246          0.2166   \n",
       "580  M31 NN Simple 2      0.724951        0.710409          0.2166   \n",
       "581  M31 NN Simple 2      0.735535        0.712052          0.2166   \n",
       "582  M31 NN Simple 2      0.730657        0.714916          0.2166   \n",
       "583  M31 NN Simple 2      0.736531        0.715483          0.2166   \n",
       "584  M31 NN Simple 2      0.725283        0.709696          0.2166   \n",
       "585  M31 NN Simple 2      0.715883        0.709546          0.2166   \n",
       "586  M31 NN Simple 2      0.730486        0.715034          0.2166   \n",
       "587  M31 NN Simple 2      0.731919        0.709702          0.2166   \n",
       "588  M31 NN Simple 2      0.723552        0.709553          0.2166   \n",
       "\n",
       "     Validation RMSLE  \n",
       "558             0.223  \n",
       "559             0.223  \n",
       "560             0.223  \n",
       "561             0.223  \n",
       "562             0.223  \n",
       "563             0.223  \n",
       "564             0.223  \n",
       "565             0.223  \n",
       "566             0.223  \n",
       "567             0.223  \n",
       "568             0.223  \n",
       "569             0.223  \n",
       "570             0.223  \n",
       "571             0.223  \n",
       "572             0.223  \n",
       "573             0.223  \n",
       "574             0.223  \n",
       "575             0.223  \n",
       "576             0.223  \n",
       "577             0.223  \n",
       "578             0.223  \n",
       "579             0.223  \n",
       "580             0.223  \n",
       "581             0.223  \n",
       "582             0.223  \n",
       "583             0.223  \n",
       "584             0.223  \n",
       "585             0.223  \n",
       "586             0.223  \n",
       "587             0.223  \n",
       "588             0.223  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model_name, features in models.items():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(32, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dropout(0.5),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=[AUC(name='auc')])\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0,\n",
    "              validation_data=(X_val_scaled, y_val),\n",
    "              callbacks=[EarlyStopping(monitor='val_auc', patience=5, restore_best_weights=True, mode='max')])\n",
    "\n",
    "    _, train_auc = model.evaluate(X_train_scaled, y_train, verbose=0)\n",
    "    _, val_auc = model.evaluate(X_val_scaled, y_val, verbose=0)\n",
    "    \n",
    "    train_rmsle = calculateRMSLE(train_prob, y_train)\n",
    "    val_rmsle = calculateRMSLE(val_prob, y_val)\n",
    "    \n",
    "    new_row = pd.DataFrame([[f\"{group_name} NN Simple 2\", train_auc, val_auc, train_rmsle, val_rmsle]], \n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Completed {model_name} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df.tail(31)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0cd2bd-fd5a-4179-9e68-00b7590c59ae",
   "metadata": {},
   "source": [
    "### Simple Neural Network Model 3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d44bcd0-0b7d-4863-9ca6-dfee985cab9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step\n",
      "Completed M1 in 20.57 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step\n",
      "Completed M2 in 18.99 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step\n",
      "Completed M3 in 13.40 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 967us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step\n",
      "Completed M4 in 20.52 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step\n",
      "Completed M5 in 18.80 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 854us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step\n",
      "Completed M6 in 19.23 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 948us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step\n",
      "Completed M7 in 17.98 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step\n",
      "Completed M8 in 16.23 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 904us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step\n",
      "Completed M9 in 13.84 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step\n",
      "Completed M10 in 16.96 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step\n",
      "Completed M11 in 14.72 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 969us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step\n",
      "Completed M12 in 13.14 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 974us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step\n",
      "Completed M13 in 15.90 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 980us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step\n",
      "Completed M14 in 16.22 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step\n",
      "Completed M15 in 17.53 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step\n",
      "Completed M16 in 20.48 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step\n",
      "Completed M17 in 14.79 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step\n",
      "Completed M18 in 24.28 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step\n",
      "Completed M19 in 25.68 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 976us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step\n",
      "Completed M20 in 18.39 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step\n",
      "Completed M21 in 16.96 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step\n",
      "Completed M22 in 18.35 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step\n",
      "Completed M23 in 21.93 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step\n",
      "Completed M24 in 18.63 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step\n",
      "Completed M25 in 18.14 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step\n",
      "Completed M26 in 19.24 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step\n",
      "Completed M27 in 16.34 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 964us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step\n",
      "Completed M28 in 19.44 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step\n",
      "Completed M29 in 20.75 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step\n",
      "Completed M30 in 16.58 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step\n",
      "Completed M31 in 15.09 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>M1 NN Simple 3</td>\n",
       "      <td>0.773596</td>\n",
       "      <td>0.707178</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.2271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>M2 NN Simple 3</td>\n",
       "      <td>0.762032</td>\n",
       "      <td>0.710935</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>M3 NN Simple 3</td>\n",
       "      <td>0.737172</td>\n",
       "      <td>0.711257</td>\n",
       "      <td>0.2203</td>\n",
       "      <td>0.2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>M4 NN Simple 3</td>\n",
       "      <td>0.764650</td>\n",
       "      <td>0.713795</td>\n",
       "      <td>0.2151</td>\n",
       "      <td>0.2253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>M5 NN Simple 3</td>\n",
       "      <td>0.761089</td>\n",
       "      <td>0.710670</td>\n",
       "      <td>0.2185</td>\n",
       "      <td>0.2273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>M6 NN Simple 3</td>\n",
       "      <td>0.764435</td>\n",
       "      <td>0.715658</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.2261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>M7 NN Simple 3</td>\n",
       "      <td>0.755129</td>\n",
       "      <td>0.708435</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.2254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>M8 NN Simple 3</td>\n",
       "      <td>0.753159</td>\n",
       "      <td>0.709823</td>\n",
       "      <td>0.2168</td>\n",
       "      <td>0.2253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>M9 NN Simple 3</td>\n",
       "      <td>0.738479</td>\n",
       "      <td>0.711350</td>\n",
       "      <td>0.2236</td>\n",
       "      <td>0.2289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>M10 NN Simple 3</td>\n",
       "      <td>0.758296</td>\n",
       "      <td>0.708929</td>\n",
       "      <td>0.2187</td>\n",
       "      <td>0.2269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>M11 NN Simple 3</td>\n",
       "      <td>0.742851</td>\n",
       "      <td>0.709935</td>\n",
       "      <td>0.2187</td>\n",
       "      <td>0.2257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>M12 NN Simple 3</td>\n",
       "      <td>0.740842</td>\n",
       "      <td>0.707439</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>M13 NN Simple 3</td>\n",
       "      <td>0.754575</td>\n",
       "      <td>0.711732</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.2276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>M14 NN Simple 3</td>\n",
       "      <td>0.755348</td>\n",
       "      <td>0.711463</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>M15 NN Simple 3</td>\n",
       "      <td>0.759631</td>\n",
       "      <td>0.712694</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>0.2248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>M16 NN Simple 3</td>\n",
       "      <td>0.770100</td>\n",
       "      <td>0.710377</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.2269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>M17 NN Simple 3</td>\n",
       "      <td>0.742443</td>\n",
       "      <td>0.709034</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>0.2270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>M18 NN Simple 3</td>\n",
       "      <td>0.778322</td>\n",
       "      <td>0.708297</td>\n",
       "      <td>0.2147</td>\n",
       "      <td>0.2262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>M19 NN Simple 3</td>\n",
       "      <td>0.787028</td>\n",
       "      <td>0.708725</td>\n",
       "      <td>0.2148</td>\n",
       "      <td>0.2279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>M20 NN Simple 3</td>\n",
       "      <td>0.766381</td>\n",
       "      <td>0.707720</td>\n",
       "      <td>0.2193</td>\n",
       "      <td>0.2281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>M21 NN Simple 3</td>\n",
       "      <td>0.752942</td>\n",
       "      <td>0.707485</td>\n",
       "      <td>0.2198</td>\n",
       "      <td>0.2284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>M22 NN Simple 3</td>\n",
       "      <td>0.762211</td>\n",
       "      <td>0.709287</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>M23 NN Simple 3</td>\n",
       "      <td>0.777090</td>\n",
       "      <td>0.709640</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.2281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>M24 NN Simple 3</td>\n",
       "      <td>0.764877</td>\n",
       "      <td>0.713710</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.2257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>M25 NN Simple 3</td>\n",
       "      <td>0.761254</td>\n",
       "      <td>0.711644</td>\n",
       "      <td>0.2178</td>\n",
       "      <td>0.2266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>M26 NN Simple 3</td>\n",
       "      <td>0.765765</td>\n",
       "      <td>0.712541</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>M27 NN Simple 3</td>\n",
       "      <td>0.754383</td>\n",
       "      <td>0.711643</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>M28 NN Simple 3</td>\n",
       "      <td>0.765894</td>\n",
       "      <td>0.712757</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>M29 NN Simple 3</td>\n",
       "      <td>0.774746</td>\n",
       "      <td>0.711561</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.2279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>M30 NN Simple 3</td>\n",
       "      <td>0.751126</td>\n",
       "      <td>0.710251</td>\n",
       "      <td>0.2185</td>\n",
       "      <td>0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>M31 NN Simple 3</td>\n",
       "      <td>0.749497</td>\n",
       "      <td>0.711788</td>\n",
       "      <td>0.2184</td>\n",
       "      <td>0.2261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "589   M1 NN Simple 3      0.773596        0.707178          0.2166   \n",
       "590   M2 NN Simple 3      0.762032        0.710935          0.2173   \n",
       "591   M3 NN Simple 3      0.737172        0.711257          0.2203   \n",
       "592   M4 NN Simple 3      0.764650        0.713795          0.2151   \n",
       "593   M5 NN Simple 3      0.761089        0.710670          0.2185   \n",
       "594   M6 NN Simple 3      0.764435        0.715658          0.2166   \n",
       "595   M7 NN Simple 3      0.755129        0.708435          0.2165   \n",
       "596   M8 NN Simple 3      0.753159        0.709823          0.2168   \n",
       "597   M9 NN Simple 3      0.738479        0.711350          0.2236   \n",
       "598  M10 NN Simple 3      0.758296        0.708929          0.2187   \n",
       "599  M11 NN Simple 3      0.742851        0.709935          0.2187   \n",
       "600  M12 NN Simple 3      0.740842        0.707439          0.2250   \n",
       "601  M13 NN Simple 3      0.754575        0.711732          0.2195   \n",
       "602  M14 NN Simple 3      0.755348        0.711463          0.2197   \n",
       "603  M15 NN Simple 3      0.759631        0.712694          0.2162   \n",
       "604  M16 NN Simple 3      0.770100        0.710377          0.2165   \n",
       "605  M17 NN Simple 3      0.742443        0.709034          0.2208   \n",
       "606  M18 NN Simple 3      0.778322        0.708297          0.2147   \n",
       "607  M19 NN Simple 3      0.787028        0.708725          0.2148   \n",
       "608  M20 NN Simple 3      0.766381        0.707720          0.2193   \n",
       "609  M21 NN Simple 3      0.752942        0.707485          0.2198   \n",
       "610  M22 NN Simple 3      0.762211        0.709287          0.2166   \n",
       "611  M23 NN Simple 3      0.777090        0.709640          0.2167   \n",
       "612  M24 NN Simple 3      0.764877        0.713710          0.2165   \n",
       "613  M25 NN Simple 3      0.761254        0.711644          0.2178   \n",
       "614  M26 NN Simple 3      0.765765        0.712541          0.2164   \n",
       "615  M27 NN Simple 3      0.754383        0.711643          0.2174   \n",
       "616  M28 NN Simple 3      0.765894        0.712757          0.2150   \n",
       "617  M29 NN Simple 3      0.774746        0.711561          0.2173   \n",
       "618  M30 NN Simple 3      0.751126        0.710251          0.2185   \n",
       "619  M31 NN Simple 3      0.749497        0.711788          0.2184   \n",
       "\n",
       "     Validation RMSLE  \n",
       "589            0.2271  \n",
       "590            0.2264  \n",
       "591            0.2264  \n",
       "592            0.2253  \n",
       "593            0.2273  \n",
       "594            0.2261  \n",
       "595            0.2254  \n",
       "596            0.2253  \n",
       "597            0.2289  \n",
       "598            0.2269  \n",
       "599            0.2257  \n",
       "600            0.2311  \n",
       "601            0.2276  \n",
       "602            0.2272  \n",
       "603            0.2248  \n",
       "604            0.2269  \n",
       "605            0.2270  \n",
       "606            0.2262  \n",
       "607            0.2279  \n",
       "608            0.2281  \n",
       "609            0.2284  \n",
       "610            0.2259  \n",
       "611            0.2281  \n",
       "612            0.2257  \n",
       "613            0.2266  \n",
       "614            0.2258  \n",
       "615            0.2250  \n",
       "616            0.2250  \n",
       "617            0.2279  \n",
       "618            0.2263  \n",
       "619            0.2261  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model_name, features in models.items():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=[AUC(name='auc')])\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_auc', patience=10, restore_best_weights=True, mode='max')\n",
    "    model.fit(X_train_scaled, y_train, epochs=150, batch_size=64, verbose=0,\n",
    "              validation_data=(X_val_scaled, y_val),\n",
    "              callbacks=[es])\n",
    "\n",
    "    train_pred = model.predict(X_train_scaled).flatten()\n",
    "    val_pred = model.predict(X_val_scaled).flatten()\n",
    "\n",
    "    _, train_auc = model.evaluate(X_train_scaled, y_train, verbose=0)\n",
    "    _, val_auc = model.evaluate(X_val_scaled, y_val, verbose=0)\n",
    "    \n",
    "    train_rmsle = calculateRMSLE(y_train, np.clip(train_pred, 0, None))  # Clipping predictions to ensure non-negative values\n",
    "    val_rmsle = calculateRMSLE(y_val, np.clip(val_pred, 0, None))\n",
    "    \n",
    "    new_row = pd.DataFrame([[f\"{model_name} NN Simple 3\", train_auc, val_auc, train_rmsle, val_rmsle]], \n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Completed {model_name} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df.tail(31)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e322c41-583f-48bd-9ed1-f0afb9ea9f22",
   "metadata": {},
   "source": [
    "### Complex Neural Network Model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0c35a6b0-3a21-4eda-ac6f-2a8e4968ec37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed M1 in 24.89 seconds\n",
      "Completed M2 in 30.25 seconds\n",
      "Completed M3 in 31.14 seconds\n",
      "Completed M4 in 23.07 seconds\n",
      "Completed M5 in 23.19 seconds\n",
      "Completed M6 in 27.37 seconds\n",
      "Completed M7 in 28.28 seconds\n",
      "Completed M8 in 37.69 seconds\n",
      "Completed M9 in 33.52 seconds\n",
      "Completed M10 in 30.38 seconds\n",
      "Completed M11 in 28.78 seconds\n",
      "Completed M12 in 21.76 seconds\n",
      "Completed M13 in 32.14 seconds\n",
      "Completed M14 in 24.58 seconds\n",
      "Completed M15 in 31.40 seconds\n",
      "Completed M16 in 23.17 seconds\n",
      "Completed M17 in 28.93 seconds\n",
      "Completed M18 in 23.60 seconds\n",
      "Completed M19 in 29.49 seconds\n",
      "Completed M20 in 33.59 seconds\n",
      "Completed M21 in 28.65 seconds\n",
      "Completed M22 in 29.43 seconds\n",
      "Completed M23 in 29.17 seconds\n",
      "Completed M24 in 23.39 seconds\n",
      "Completed M25 in 27.52 seconds\n",
      "Completed M26 in 27.00 seconds\n",
      "Completed M27 in 31.97 seconds\n",
      "Completed M28 in 28.92 seconds\n",
      "Completed M29 in 34.23 seconds\n",
      "Completed M30 in 26.95 seconds\n",
      "Completed M31 in 27.46 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.736321</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.742054</td>\n",
       "      <td>0.715358</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.743683</td>\n",
       "      <td>0.717296</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.727441</td>\n",
       "      <td>0.709844</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.728448</td>\n",
       "      <td>0.714545</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.738683</td>\n",
       "      <td>0.714576</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.739094</td>\n",
       "      <td>0.712156</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.754559</td>\n",
       "      <td>0.714179</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.747513</td>\n",
       "      <td>0.715055</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.744133</td>\n",
       "      <td>0.720031</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.735812</td>\n",
       "      <td>0.713895</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.728398</td>\n",
       "      <td>0.713818</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.744699</td>\n",
       "      <td>0.713467</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.731408</td>\n",
       "      <td>0.714155</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.743502</td>\n",
       "      <td>0.716064</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.728712</td>\n",
       "      <td>0.712847</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.738614</td>\n",
       "      <td>0.714640</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.731331</td>\n",
       "      <td>0.712403</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.739741</td>\n",
       "      <td>0.714656</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.745247</td>\n",
       "      <td>0.715128</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.739494</td>\n",
       "      <td>0.717039</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.740445</td>\n",
       "      <td>0.714874</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.739989</td>\n",
       "      <td>0.710696</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.730830</td>\n",
       "      <td>0.714468</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.738327</td>\n",
       "      <td>0.715159</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.737683</td>\n",
       "      <td>0.713959</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.744693</td>\n",
       "      <td>0.715496</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.738888</td>\n",
       "      <td>0.713192</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.748208</td>\n",
       "      <td>0.718108</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.733689</td>\n",
       "      <td>0.714462</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.736184</td>\n",
       "      <td>0.713266</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "620  M31 NN Complex      0.736321        0.711864          0.2166   \n",
       "621  M31 NN Complex      0.742054        0.715358          0.2166   \n",
       "622  M31 NN Complex      0.743683        0.717296          0.2166   \n",
       "623  M31 NN Complex      0.727441        0.709844          0.2166   \n",
       "624  M31 NN Complex      0.728448        0.714545          0.2166   \n",
       "625  M31 NN Complex      0.738683        0.714576          0.2166   \n",
       "626  M31 NN Complex      0.739094        0.712156          0.2166   \n",
       "627  M31 NN Complex      0.754559        0.714179          0.2166   \n",
       "628  M31 NN Complex      0.747513        0.715055          0.2166   \n",
       "629  M31 NN Complex      0.744133        0.720031          0.2166   \n",
       "630  M31 NN Complex      0.735812        0.713895          0.2166   \n",
       "631  M31 NN Complex      0.728398        0.713818          0.2166   \n",
       "632  M31 NN Complex      0.744699        0.713467          0.2166   \n",
       "633  M31 NN Complex      0.731408        0.714155          0.2166   \n",
       "634  M31 NN Complex      0.743502        0.716064          0.2166   \n",
       "635  M31 NN Complex      0.728712        0.712847          0.2166   \n",
       "636  M31 NN Complex      0.738614        0.714640          0.2166   \n",
       "637  M31 NN Complex      0.731331        0.712403          0.2166   \n",
       "638  M31 NN Complex      0.739741        0.714656          0.2166   \n",
       "639  M31 NN Complex      0.745247        0.715128          0.2166   \n",
       "640  M31 NN Complex      0.739494        0.717039          0.2166   \n",
       "641  M31 NN Complex      0.740445        0.714874          0.2166   \n",
       "642  M31 NN Complex      0.739989        0.710696          0.2166   \n",
       "643  M31 NN Complex      0.730830        0.714468          0.2166   \n",
       "644  M31 NN Complex      0.738327        0.715159          0.2166   \n",
       "645  M31 NN Complex      0.737683        0.713959          0.2166   \n",
       "646  M31 NN Complex      0.744693        0.715496          0.2166   \n",
       "647  M31 NN Complex      0.738888        0.713192          0.2166   \n",
       "648  M31 NN Complex      0.748208        0.718108          0.2166   \n",
       "649  M31 NN Complex      0.733689        0.714462          0.2166   \n",
       "650  M31 NN Complex      0.736184        0.713266          0.2166   \n",
       "\n",
       "     Validation RMSLE  \n",
       "620             0.223  \n",
       "621             0.223  \n",
       "622             0.223  \n",
       "623             0.223  \n",
       "624             0.223  \n",
       "625             0.223  \n",
       "626             0.223  \n",
       "627             0.223  \n",
       "628             0.223  \n",
       "629             0.223  \n",
       "630             0.223  \n",
       "631             0.223  \n",
       "632             0.223  \n",
       "633             0.223  \n",
       "634             0.223  \n",
       "635             0.223  \n",
       "636             0.223  \n",
       "637             0.223  \n",
       "638             0.223  \n",
       "639             0.223  \n",
       "640             0.223  \n",
       "641             0.223  \n",
       "642             0.223  \n",
       "643             0.223  \n",
       "644             0.223  \n",
       "645             0.223  \n",
       "646             0.223  \n",
       "647             0.223  \n",
       "648             0.223  \n",
       "649             0.223  \n",
       "650             0.223  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model_name, features in models.items():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(32, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=[AUC(name='auc')])\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0,\n",
    "              validation_data=(X_val_scaled, y_val),\n",
    "              callbacks=[EarlyStopping(monitor='val_auc', patience=5, restore_best_weights=True, mode='max')])\n",
    "\n",
    "    _, train_auc = model.evaluate(X_train_scaled, y_train, verbose=0)\n",
    "    _, val_auc = model.evaluate(X_val_scaled, y_val, verbose=0)\n",
    "    \n",
    "    train_rmsle = calculateRMSLE(train_prob, y_train)\n",
    "    val_rmsle = calculateRMSLE(val_prob, y_val)\n",
    "    \n",
    "    new_row = pd.DataFrame([[f\"{group_name} NN Complex\", train_auc, val_auc, train_rmsle, val_rmsle]], \n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Completed {model_name} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df.tail(31)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb730fbc-6096-4fa2-a3b4-38ec9f54541f",
   "metadata": {},
   "source": [
    "### Conv1D Adjusted Neural Network 1\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c14a377-8620-4ffb-82c0-ba7cc9b6407e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M1 in 80.89 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M2 in 90.04 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M3 in 85.91 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M4 in 99.06 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M5 in 114.49 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M6 in 64.48 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M7 in 96.15 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M8 in 71.11 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M9 in 79.46 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M10 in 82.62 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M11 in 101.87 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M12 in 84.08 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M13 in 87.52 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M14 in 109.49 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M15 in 82.62 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M16 in 63.56 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M17 in 98.61 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M18 in 74.86 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M19 in 94.26 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M20 in 64.36 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M21 in 106.53 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M22 in 103.11 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M23 in 101.14 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M24 in 90.51 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M25 in 82.11 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M26 in 78.79 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M27 in 80.63 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M28 in 105.85 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M29 in 80.71 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Completed M30 in 84.54 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M31 in 89.75 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>M1 NN Conv1D Adjusted</td>\n",
       "      <td>0.736287</td>\n",
       "      <td>0.711109</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.2242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>M2 NN Conv1D Adjusted</td>\n",
       "      <td>0.743762</td>\n",
       "      <td>0.713524</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.2294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>M3 NN Conv1D Adjusted</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.710604</td>\n",
       "      <td>0.2183</td>\n",
       "      <td>0.2265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>M4 NN Conv1D Adjusted</td>\n",
       "      <td>0.755695</td>\n",
       "      <td>0.710115</td>\n",
       "      <td>0.2132</td>\n",
       "      <td>0.2232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>M5 NN Conv1D Adjusted</td>\n",
       "      <td>0.769245</td>\n",
       "      <td>0.713502</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>0.2257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>M6 NN Conv1D Adjusted</td>\n",
       "      <td>0.722870</td>\n",
       "      <td>0.712042</td>\n",
       "      <td>0.2209</td>\n",
       "      <td>0.2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>M7 NN Conv1D Adjusted</td>\n",
       "      <td>0.756500</td>\n",
       "      <td>0.710696</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.2254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>M8 NN Conv1D Adjusted</td>\n",
       "      <td>0.730564</td>\n",
       "      <td>0.710325</td>\n",
       "      <td>0.2168</td>\n",
       "      <td>0.2234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>M9 NN Conv1D Adjusted</td>\n",
       "      <td>0.744752</td>\n",
       "      <td>0.712093</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>M10 NN Conv1D Adjusted</td>\n",
       "      <td>0.741162</td>\n",
       "      <td>0.711302</td>\n",
       "      <td>0.2184</td>\n",
       "      <td>0.2261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>M11 NN Conv1D Adjusted</td>\n",
       "      <td>0.763622</td>\n",
       "      <td>0.711633</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>0.2260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>M12 NN Conv1D Adjusted</td>\n",
       "      <td>0.748451</td>\n",
       "      <td>0.711741</td>\n",
       "      <td>0.2181</td>\n",
       "      <td>0.2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>M13 NN Conv1D Adjusted</td>\n",
       "      <td>0.750646</td>\n",
       "      <td>0.712623</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>0.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>M14 NN Conv1D Adjusted</td>\n",
       "      <td>0.758349</td>\n",
       "      <td>0.708382</td>\n",
       "      <td>0.2132</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>M15 NN Conv1D Adjusted</td>\n",
       "      <td>0.745220</td>\n",
       "      <td>0.712818</td>\n",
       "      <td>0.2186</td>\n",
       "      <td>0.2262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>M16 NN Conv1D Adjusted</td>\n",
       "      <td>0.728950</td>\n",
       "      <td>0.710767</td>\n",
       "      <td>0.2219</td>\n",
       "      <td>0.2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>M17 NN Conv1D Adjusted</td>\n",
       "      <td>0.757627</td>\n",
       "      <td>0.710231</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>M18 NN Conv1D Adjusted</td>\n",
       "      <td>0.736233</td>\n",
       "      <td>0.710957</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>M19 NN Conv1D Adjusted</td>\n",
       "      <td>0.750675</td>\n",
       "      <td>0.712858</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>M20 NN Conv1D Adjusted</td>\n",
       "      <td>0.725361</td>\n",
       "      <td>0.709774</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>0.2261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>M21 NN Conv1D Adjusted</td>\n",
       "      <td>0.766348</td>\n",
       "      <td>0.709069</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.2258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>M22 NN Conv1D Adjusted</td>\n",
       "      <td>0.760813</td>\n",
       "      <td>0.708625</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>0.2268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>M23 NN Conv1D Adjusted</td>\n",
       "      <td>0.766132</td>\n",
       "      <td>0.710065</td>\n",
       "      <td>0.2131</td>\n",
       "      <td>0.2248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>M24 NN Conv1D Adjusted</td>\n",
       "      <td>0.750844</td>\n",
       "      <td>0.710358</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>M25 NN Conv1D Adjusted</td>\n",
       "      <td>0.747387</td>\n",
       "      <td>0.710534</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.2257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>M26 NN Conv1D Adjusted</td>\n",
       "      <td>0.742208</td>\n",
       "      <td>0.709871</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>M27 NN Conv1D Adjusted</td>\n",
       "      <td>0.735802</td>\n",
       "      <td>0.710878</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>0.2236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>M28 NN Conv1D Adjusted</td>\n",
       "      <td>0.761499</td>\n",
       "      <td>0.712150</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.2249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>M29 NN Conv1D Adjusted</td>\n",
       "      <td>0.739853</td>\n",
       "      <td>0.711530</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>0.2271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>M30 NN Conv1D Adjusted</td>\n",
       "      <td>0.745729</td>\n",
       "      <td>0.710258</td>\n",
       "      <td>0.2176</td>\n",
       "      <td>0.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>M31 NN Conv1D Adjusted</td>\n",
       "      <td>0.744512</td>\n",
       "      <td>0.710516</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>0.2243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "651   M1 NN Conv1D Adjusted      0.736287        0.711109          0.2167   \n",
       "652   M2 NN Conv1D Adjusted      0.743762        0.713524          0.2220   \n",
       "653   M3 NN Conv1D Adjusted      0.746032        0.710604          0.2183   \n",
       "654   M4 NN Conv1D Adjusted      0.755695        0.710115          0.2132   \n",
       "655   M5 NN Conv1D Adjusted      0.769245        0.713502          0.2139   \n",
       "656   M6 NN Conv1D Adjusted      0.722870        0.712042          0.2209   \n",
       "657   M7 NN Conv1D Adjusted      0.756500        0.710696          0.2155   \n",
       "658   M8 NN Conv1D Adjusted      0.730564        0.710325          0.2168   \n",
       "659   M9 NN Conv1D Adjusted      0.744752        0.712093          0.2164   \n",
       "660  M10 NN Conv1D Adjusted      0.741162        0.711302          0.2184   \n",
       "661  M11 NN Conv1D Adjusted      0.763622        0.711633          0.2149   \n",
       "662  M12 NN Conv1D Adjusted      0.748451        0.711741          0.2181   \n",
       "663  M13 NN Conv1D Adjusted      0.750646        0.712623          0.2160   \n",
       "664  M14 NN Conv1D Adjusted      0.758349        0.708382          0.2132   \n",
       "665  M15 NN Conv1D Adjusted      0.745220        0.712818          0.2186   \n",
       "666  M16 NN Conv1D Adjusted      0.728950        0.710767          0.2219   \n",
       "667  M17 NN Conv1D Adjusted      0.757627        0.710231          0.2136   \n",
       "668  M18 NN Conv1D Adjusted      0.736233        0.710957          0.2167   \n",
       "669  M19 NN Conv1D Adjusted      0.750675        0.712858          0.2160   \n",
       "670  M20 NN Conv1D Adjusted      0.725361        0.709774          0.2208   \n",
       "671  M21 NN Conv1D Adjusted      0.766348        0.709069          0.2136   \n",
       "672  M22 NN Conv1D Adjusted      0.760813        0.708625          0.2160   \n",
       "673  M23 NN Conv1D Adjusted      0.766132        0.710065          0.2131   \n",
       "674  M24 NN Conv1D Adjusted      0.750844        0.710358          0.2164   \n",
       "675  M25 NN Conv1D Adjusted      0.747387        0.710534          0.2170   \n",
       "676  M26 NN Conv1D Adjusted      0.742208        0.709871          0.2197   \n",
       "677  M27 NN Conv1D Adjusted      0.735802        0.710878          0.2162   \n",
       "678  M28 NN Conv1D Adjusted      0.761499        0.712150          0.2143   \n",
       "679  M29 NN Conv1D Adjusted      0.739853        0.711530          0.2197   \n",
       "680  M30 NN Conv1D Adjusted      0.745729        0.710258          0.2176   \n",
       "681  M31 NN Conv1D Adjusted      0.744512        0.710516          0.2160   \n",
       "\n",
       "     Validation RMSLE  \n",
       "651            0.2242  \n",
       "652            0.2294  \n",
       "653            0.2265  \n",
       "654            0.2232  \n",
       "655            0.2257  \n",
       "656            0.2259  \n",
       "657            0.2254  \n",
       "658            0.2234  \n",
       "659            0.2251  \n",
       "660            0.2261  \n",
       "661            0.2260  \n",
       "662            0.2264  \n",
       "663            0.2255  \n",
       "664            0.2241  \n",
       "665            0.2262  \n",
       "666            0.2277  \n",
       "667            0.2240  \n",
       "668            0.2240  \n",
       "669            0.2251  \n",
       "670            0.2261  \n",
       "671            0.2258  \n",
       "672            0.2268  \n",
       "673            0.2248  \n",
       "674            0.2254  \n",
       "675            0.2257  \n",
       "676            0.2269  \n",
       "677            0.2236  \n",
       "678            0.2249  \n",
       "679            0.2271  \n",
       "680            0.2255  \n",
       "681            0.2243  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model_name, features in models.items():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model = Sequential([\n",
    "        # Applying Conv1D on the reshaped data; treating each feature as a timestep\n",
    "        Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=(n_features, 1)),\n",
    "        MaxPooling1D(pool_size=2, strides=2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss='binary_crossentropy', metrics=[AUC(name='auc')])\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_auc', patience=15, restore_best_weights=True, mode='max')\n",
    "    model.fit(X_train_reshaped, y_train, epochs=200, batch_size=32, verbose=0,\n",
    "              validation_data=(X_val_reshaped, y_val),\n",
    "              callbacks=[es])\n",
    "\n",
    "    _, train_auc = model.evaluate(X_train_reshaped, y_train, verbose=0)\n",
    "    _, val_auc = model.evaluate(X_val_reshaped, y_val, verbose=0)\n",
    "\n",
    "    # Prediction and RMSLE calculation need correct predictions\n",
    "    train_pred = model.predict(X_train_reshaped).flatten()\n",
    "    val_pred = model.predict(X_val_reshaped).flatten()\n",
    "\n",
    "    train_rmsle = calculateRMSLE(y_train, np.clip(train_pred, 0, None))\n",
    "    val_rmsle = calculateRMSLE(y_val, np.clip(val_pred, 0, None))\n",
    "\n",
    "    new_row = pd.DataFrame([[f\"{model_name} NN Conv1D Adjusted\", train_auc, val_auc, train_rmsle, val_rmsle]], \n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Completed {model_name} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df.tail(31)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110ee8f3-0d35-4646-b9e3-76a78dd52a5a",
   "metadata": {},
   "source": [
    "### Conv1D Adjusted Neural Network 2\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9968b958-d4b3-4655-977b-9ac6829b9633",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M1 in 73.77 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M2 in 78.44 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M3 in 72.46 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M4 in 77.57 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M5 in 80.59 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M6 in 69.26 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M7 in 73.79 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M8 in 77.46 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M9 in 80.90 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M10 in 80.43 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M11 in 83.20 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M12 in 68.57 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M13 in 55.52 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M14 in 71.44 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M15 in 57.33 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M16 in 62.23 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M17 in 60.96 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M18 in 70.59 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M19 in 55.46 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M20 in 65.83 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M21 in 72.91 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M22 in 84.75 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M23 in 75.36 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M24 in 73.09 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M25 in 71.03 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M26 in 66.63 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M27 in 73.51 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M28 in 79.45 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M29 in 62.14 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M30 in 83.21 seconds\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n",
      "\u001b[1m186/186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Completed M31 in 77.67 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>M1 NN Conv1D Optimized 2</td>\n",
       "      <td>0.741977</td>\n",
       "      <td>0.712537</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>M2 NN Conv1D Optimized 2</td>\n",
       "      <td>0.741016</td>\n",
       "      <td>0.712113</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>M3 NN Conv1D Optimized 2</td>\n",
       "      <td>0.735827</td>\n",
       "      <td>0.716828</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.2228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>M4 NN Conv1D Optimized 2</td>\n",
       "      <td>0.746041</td>\n",
       "      <td>0.712080</td>\n",
       "      <td>0.2159</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>M5 NN Conv1D Optimized 2</td>\n",
       "      <td>0.747499</td>\n",
       "      <td>0.715631</td>\n",
       "      <td>0.2159</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>M6 NN Conv1D Optimized 2</td>\n",
       "      <td>0.735628</td>\n",
       "      <td>0.712862</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.2234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>M7 NN Conv1D Optimized 2</td>\n",
       "      <td>0.739474</td>\n",
       "      <td>0.713740</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.2241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>M8 NN Conv1D Optimized 2</td>\n",
       "      <td>0.744471</td>\n",
       "      <td>0.711743</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.2244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>M9 NN Conv1D Optimized 2</td>\n",
       "      <td>0.744813</td>\n",
       "      <td>0.716533</td>\n",
       "      <td>0.2163</td>\n",
       "      <td>0.2235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>M10 NN Conv1D Optimized 2</td>\n",
       "      <td>0.748764</td>\n",
       "      <td>0.714428</td>\n",
       "      <td>0.2146</td>\n",
       "      <td>0.2229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>M11 NN Conv1D Optimized 2</td>\n",
       "      <td>0.749263</td>\n",
       "      <td>0.713469</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.2248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>M12 NN Conv1D Optimized 2</td>\n",
       "      <td>0.736619</td>\n",
       "      <td>0.714565</td>\n",
       "      <td>0.2179</td>\n",
       "      <td>0.2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>M13 NN Conv1D Optimized 2</td>\n",
       "      <td>0.725337</td>\n",
       "      <td>0.713589</td>\n",
       "      <td>0.2182</td>\n",
       "      <td>0.2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>M14 NN Conv1D Optimized 2</td>\n",
       "      <td>0.739692</td>\n",
       "      <td>0.715245</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.2235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>M15 NN Conv1D Optimized 2</td>\n",
       "      <td>0.724454</td>\n",
       "      <td>0.711854</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>M16 NN Conv1D Optimized 2</td>\n",
       "      <td>0.728835</td>\n",
       "      <td>0.712735</td>\n",
       "      <td>0.2183</td>\n",
       "      <td>0.2237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>M17 NN Conv1D Optimized 2</td>\n",
       "      <td>0.727925</td>\n",
       "      <td>0.714761</td>\n",
       "      <td>0.2183</td>\n",
       "      <td>0.2236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>M18 NN Conv1D Optimized 2</td>\n",
       "      <td>0.740541</td>\n",
       "      <td>0.713188</td>\n",
       "      <td>0.2177</td>\n",
       "      <td>0.2245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>M19 NN Conv1D Optimized 2</td>\n",
       "      <td>0.725578</td>\n",
       "      <td>0.713094</td>\n",
       "      <td>0.2183</td>\n",
       "      <td>0.2236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>M20 NN Conv1D Optimized 2</td>\n",
       "      <td>0.736986</td>\n",
       "      <td>0.714197</td>\n",
       "      <td>0.2163</td>\n",
       "      <td>0.2229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>M21 NN Conv1D Optimized 2</td>\n",
       "      <td>0.740667</td>\n",
       "      <td>0.714013</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.2254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>M22 NN Conv1D Optimized 2</td>\n",
       "      <td>0.749898</td>\n",
       "      <td>0.713328</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>0.2244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>M23 NN Conv1D Optimized 2</td>\n",
       "      <td>0.745875</td>\n",
       "      <td>0.713304</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>M24 NN Conv1D Optimized 2</td>\n",
       "      <td>0.737323</td>\n",
       "      <td>0.716395</td>\n",
       "      <td>0.2184</td>\n",
       "      <td>0.2245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>M25 NN Conv1D Optimized 2</td>\n",
       "      <td>0.740056</td>\n",
       "      <td>0.714612</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>M26 NN Conv1D Optimized 2</td>\n",
       "      <td>0.734910</td>\n",
       "      <td>0.714037</td>\n",
       "      <td>0.2186</td>\n",
       "      <td>0.2245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>M27 NN Conv1D Optimized 2</td>\n",
       "      <td>0.741309</td>\n",
       "      <td>0.713575</td>\n",
       "      <td>0.2187</td>\n",
       "      <td>0.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>M28 NN Conv1D Optimized 2</td>\n",
       "      <td>0.751094</td>\n",
       "      <td>0.713018</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>0.2238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>M29 NN Conv1D Optimized 2</td>\n",
       "      <td>0.728173</td>\n",
       "      <td>0.714781</td>\n",
       "      <td>0.2203</td>\n",
       "      <td>0.2255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>M30 NN Conv1D Optimized 2</td>\n",
       "      <td>0.751206</td>\n",
       "      <td>0.713651</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>0.2235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>M31 NN Conv1D Optimized 2</td>\n",
       "      <td>0.745493</td>\n",
       "      <td>0.714612</td>\n",
       "      <td>0.2153</td>\n",
       "      <td>0.2235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "682   M1 NN Conv1D Optimized 2      0.741977        0.712537          0.2164   \n",
       "683   M2 NN Conv1D Optimized 2      0.741016        0.712113          0.2155   \n",
       "684   M3 NN Conv1D Optimized 2      0.735827        0.716828          0.2167   \n",
       "685   M4 NN Conv1D Optimized 2      0.746041        0.712080          0.2159   \n",
       "686   M5 NN Conv1D Optimized 2      0.747499        0.715631          0.2159   \n",
       "687   M6 NN Conv1D Optimized 2      0.735628        0.712862          0.2171   \n",
       "688   M7 NN Conv1D Optimized 2      0.739474        0.713740          0.2173   \n",
       "689   M8 NN Conv1D Optimized 2      0.744471        0.711743          0.2175   \n",
       "690   M9 NN Conv1D Optimized 2      0.744813        0.716533          0.2163   \n",
       "691  M10 NN Conv1D Optimized 2      0.748764        0.714428          0.2146   \n",
       "692  M11 NN Conv1D Optimized 2      0.749263        0.713469          0.2167   \n",
       "693  M12 NN Conv1D Optimized 2      0.736619        0.714565          0.2179   \n",
       "694  M13 NN Conv1D Optimized 2      0.725337        0.713589          0.2182   \n",
       "695  M14 NN Conv1D Optimized 2      0.739692        0.715245          0.2166   \n",
       "696  M15 NN Conv1D Optimized 2      0.724454        0.711854          0.2173   \n",
       "697  M16 NN Conv1D Optimized 2      0.728835        0.712735          0.2183   \n",
       "698  M17 NN Conv1D Optimized 2      0.727925        0.714761          0.2183   \n",
       "699  M18 NN Conv1D Optimized 2      0.740541        0.713188          0.2177   \n",
       "700  M19 NN Conv1D Optimized 2      0.725578        0.713094          0.2183   \n",
       "701  M20 NN Conv1D Optimized 2      0.736986        0.714197          0.2163   \n",
       "702  M21 NN Conv1D Optimized 2      0.740667        0.714013          0.2191   \n",
       "703  M22 NN Conv1D Optimized 2      0.749898        0.713328          0.2162   \n",
       "704  M23 NN Conv1D Optimized 2      0.745875        0.713304          0.2165   \n",
       "705  M24 NN Conv1D Optimized 2      0.737323        0.716395          0.2184   \n",
       "706  M25 NN Conv1D Optimized 2      0.740056        0.714612          0.2170   \n",
       "707  M26 NN Conv1D Optimized 2      0.734910        0.714037          0.2186   \n",
       "708  M27 NN Conv1D Optimized 2      0.741309        0.713575          0.2187   \n",
       "709  M28 NN Conv1D Optimized 2      0.751094        0.713018          0.2150   \n",
       "710  M29 NN Conv1D Optimized 2      0.728173        0.714781          0.2203   \n",
       "711  M30 NN Conv1D Optimized 2      0.751206        0.713651          0.2137   \n",
       "712  M31 NN Conv1D Optimized 2      0.745493        0.714612          0.2153   \n",
       "\n",
       "     Validation RMSLE  \n",
       "682            0.2236  \n",
       "683            0.2233  \n",
       "684            0.2228  \n",
       "685            0.2241  \n",
       "686            0.2238  \n",
       "687            0.2234  \n",
       "688            0.2241  \n",
       "689            0.2244  \n",
       "690            0.2235  \n",
       "691            0.2229  \n",
       "692            0.2248  \n",
       "693            0.2243  \n",
       "694            0.2233  \n",
       "695            0.2235  \n",
       "696            0.2230  \n",
       "697            0.2237  \n",
       "698            0.2236  \n",
       "699            0.2245  \n",
       "700            0.2236  \n",
       "701            0.2229  \n",
       "702            0.2254  \n",
       "703            0.2244  \n",
       "704            0.2239  \n",
       "705            0.2245  \n",
       "706            0.2238  \n",
       "707            0.2245  \n",
       "708            0.2255  \n",
       "709            0.2238  \n",
       "710            0.2255  \n",
       "711            0.2235  \n",
       "712            0.2235  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for model_name, features in models.items():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=1, activation='relu', input_shape=(n_features, 1)), \n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=64, kernel_size=1, activation='relu'),  # Additional Conv layer\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.4),  # Slightly increased dropout\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005),  # Increased learning rate\n",
    "                  loss='binary_crossentropy', metrics=[AUC(name='auc')])\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_auc', patience=10, restore_best_weights=True, mode='max')  # Adjusted patience\n",
    "    model.fit(X_train_reshaped, y_train, epochs=100, batch_size=64, verbose=0,  # Reduced epochs, increased batch size\n",
    "              validation_data=(X_val_reshaped, y_val),\n",
    "              callbacks=[es])\n",
    "\n",
    "    _, train_auc = model.evaluate(X_train_reshaped, y_train, verbose=0)\n",
    "    _, val_auc = model.evaluate(X_val_reshaped, y_val, verbose=0)\n",
    "\n",
    "    train_pred = model.predict(X_train_reshaped).flatten()\n",
    "    val_pred = model.predict(X_val_reshaped).flatten()\n",
    "\n",
    "    train_rmsle = calculateRMSLE(y_train, np.clip(train_pred, 0, None))\n",
    "    val_rmsle = calculateRMSLE(y_val, np.clip(val_pred, 0, None))\n",
    "\n",
    "    new_row = pd.DataFrame([[f\"{model_name} NN Conv1D Optimized 2\", train_auc, val_auc, train_rmsle, val_rmsle]], \n",
    "                           columns=['Model', 'Training AUC', 'Validation AUC', 'Training RMSLE', 'Validation RMSLE'])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Completed {model_name} in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "results_df.tail(31)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7a33e3-90b3-4668-a5a5-4165f874974d",
   "metadata": {},
   "source": [
    "# Hypertuning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bca990-82f6-4e01-b72d-7bf383d0bd02",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4abceeb-03e3-47d2-a333-c3d5d3d2582e",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1b297dae-ec84-4c62-8e89-c73a29b7f3d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "      <th>Difference AUC</th>\n",
       "      <th>Complexity</th>\n",
       "      <th>Normalized RMSLE</th>\n",
       "      <th>Combined Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>M19 EBM Adjusted 2</td>\n",
       "      <td>0.756544</td>\n",
       "      <td>0.729734</td>\n",
       "      <td>0.2153</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.026810</td>\n",
       "      <td>19</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.672591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>M23 EBM</td>\n",
       "      <td>0.762217</td>\n",
       "      <td>0.729273</td>\n",
       "      <td>0.2141</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.032944</td>\n",
       "      <td>23</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.672268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>M19 EBM Adjusted 1</td>\n",
       "      <td>0.753422</td>\n",
       "      <td>0.728563</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.024858</td>\n",
       "      <td>19</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.671771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>M18 EBM Adjusted 2</td>\n",
       "      <td>0.759832</td>\n",
       "      <td>0.728308</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.031524</td>\n",
       "      <td>18</td>\n",
       "      <td>0.539050</td>\n",
       "      <td>0.671530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>M20 EBM Adjusted 2</td>\n",
       "      <td>0.753729</td>\n",
       "      <td>0.728196</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.025534</td>\n",
       "      <td>20</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.671514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>M9 EBM</td>\n",
       "      <td>0.762717</td>\n",
       "      <td>0.728033</td>\n",
       "      <td>0.2141</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.034684</td>\n",
       "      <td>9</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.671276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>M30 EBM Adjusted 2</td>\n",
       "      <td>0.747995</td>\n",
       "      <td>0.727965</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2228</td>\n",
       "      <td>0.020030</td>\n",
       "      <td>30</td>\n",
       "      <td>0.539669</td>\n",
       "      <td>0.671476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>M21 EBM Adjusted 1</td>\n",
       "      <td>0.745826</td>\n",
       "      <td>0.727762</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.018064</td>\n",
       "      <td>21</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.671210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>M20 EBM Adjusted 1</td>\n",
       "      <td>0.748417</td>\n",
       "      <td>0.727667</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.020750</td>\n",
       "      <td>20</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.671144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>M7 EBM</td>\n",
       "      <td>0.765401</td>\n",
       "      <td>0.727386</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.038015</td>\n",
       "      <td>7</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.670823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>M10 EBM Adjusted 1</td>\n",
       "      <td>0.739305</td>\n",
       "      <td>0.727329</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.011977</td>\n",
       "      <td>10</td>\n",
       "      <td>0.539050</td>\n",
       "      <td>0.670845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>M18 EBM Adjusted 1</td>\n",
       "      <td>0.755229</td>\n",
       "      <td>0.727098</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.028131</td>\n",
       "      <td>18</td>\n",
       "      <td>0.539050</td>\n",
       "      <td>0.670683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>M12 EBM</td>\n",
       "      <td>0.760207</td>\n",
       "      <td>0.727088</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.033119</td>\n",
       "      <td>12</td>\n",
       "      <td>0.539050</td>\n",
       "      <td>0.670677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>M18 EBM</td>\n",
       "      <td>0.783207</td>\n",
       "      <td>0.727065</td>\n",
       "      <td>0.2114</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.056142</td>\n",
       "      <td>18</td>\n",
       "      <td>0.538636</td>\n",
       "      <td>0.670536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>M10 EBM</td>\n",
       "      <td>0.766798</td>\n",
       "      <td>0.726993</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.039804</td>\n",
       "      <td>10</td>\n",
       "      <td>0.539050</td>\n",
       "      <td>0.670610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>M14 EBM</td>\n",
       "      <td>0.761601</td>\n",
       "      <td>0.726991</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.034610</td>\n",
       "      <td>14</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.670547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>M31 EBM Adjusted 1</td>\n",
       "      <td>0.742422</td>\n",
       "      <td>0.726985</td>\n",
       "      <td>0.2172</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.015437</td>\n",
       "      <td>31</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.670666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>M20 EBM</td>\n",
       "      <td>0.783635</td>\n",
       "      <td>0.726916</td>\n",
       "      <td>0.2114</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.056718</td>\n",
       "      <td>20</td>\n",
       "      <td>0.538636</td>\n",
       "      <td>0.670432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>M11 EBM</td>\n",
       "      <td>0.766312</td>\n",
       "      <td>0.726887</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.039425</td>\n",
       "      <td>11</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.670474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>M15 EBM</td>\n",
       "      <td>0.760804</td>\n",
       "      <td>0.726864</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.033939</td>\n",
       "      <td>15</td>\n",
       "      <td>0.539050</td>\n",
       "      <td>0.670520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>M30 EBM Adjusted 1</td>\n",
       "      <td>0.743963</td>\n",
       "      <td>0.726811</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.017152</td>\n",
       "      <td>30</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.670545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>M21 EBM Adjusted 2</td>\n",
       "      <td>0.750283</td>\n",
       "      <td>0.726772</td>\n",
       "      <td>0.2161</td>\n",
       "      <td>0.2229</td>\n",
       "      <td>0.023511</td>\n",
       "      <td>21</td>\n",
       "      <td>0.539463</td>\n",
       "      <td>0.670579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>M22 EBM Adjusted 1</td>\n",
       "      <td>0.741926</td>\n",
       "      <td>0.726765</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>22</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.670389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>M31 EBM</td>\n",
       "      <td>0.781066</td>\n",
       "      <td>0.726712</td>\n",
       "      <td>0.2118</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.054354</td>\n",
       "      <td>31</td>\n",
       "      <td>0.538636</td>\n",
       "      <td>0.670289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>M31 EBM Adjusted 2</td>\n",
       "      <td>0.746505</td>\n",
       "      <td>0.726678</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.019827</td>\n",
       "      <td>31</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.670452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>M19 EBM</td>\n",
       "      <td>0.790839</td>\n",
       "      <td>0.726561</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.2234</td>\n",
       "      <td>0.064278</td>\n",
       "      <td>19</td>\n",
       "      <td>0.538430</td>\n",
       "      <td>0.670122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>M11 EBM Adjusted 1</td>\n",
       "      <td>0.738411</td>\n",
       "      <td>0.726542</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.011869</td>\n",
       "      <td>11</td>\n",
       "      <td>0.539050</td>\n",
       "      <td>0.670294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>M22 EBM</td>\n",
       "      <td>0.765821</td>\n",
       "      <td>0.726432</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>0.2234</td>\n",
       "      <td>0.039389</td>\n",
       "      <td>22</td>\n",
       "      <td>0.538430</td>\n",
       "      <td>0.670031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>M14 EBM Adjusted 1</td>\n",
       "      <td>0.740413</td>\n",
       "      <td>0.726406</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.014007</td>\n",
       "      <td>14</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.670137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>M25 EBM</td>\n",
       "      <td>0.759795</td>\n",
       "      <td>0.726340</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.033455</td>\n",
       "      <td>25</td>\n",
       "      <td>0.539050</td>\n",
       "      <td>0.670153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>M24 EBM</td>\n",
       "      <td>0.760277</td>\n",
       "      <td>0.726308</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.033969</td>\n",
       "      <td>24</td>\n",
       "      <td>0.538636</td>\n",
       "      <td>0.670006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>M9 EBM Adjusted 1</td>\n",
       "      <td>0.738593</td>\n",
       "      <td>0.726296</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.012297</td>\n",
       "      <td>9</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.670060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>M8 EBM</td>\n",
       "      <td>0.766168</td>\n",
       "      <td>0.726259</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.039908</td>\n",
       "      <td>8</td>\n",
       "      <td>0.538636</td>\n",
       "      <td>0.669972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>M17 EBM Adjusted 2</td>\n",
       "      <td>0.749817</td>\n",
       "      <td>0.726238</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.023579</td>\n",
       "      <td>17</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.670019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>M17 EBM Adjusted 1</td>\n",
       "      <td>0.746843</td>\n",
       "      <td>0.726236</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.020607</td>\n",
       "      <td>17</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.670018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>M22 EBM Adjusted 2</td>\n",
       "      <td>0.747202</td>\n",
       "      <td>0.726052</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.021150</td>\n",
       "      <td>22</td>\n",
       "      <td>0.538636</td>\n",
       "      <td>0.669827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>M8 EBM Adjusted 2</td>\n",
       "      <td>0.746996</td>\n",
       "      <td>0.725894</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.021101</td>\n",
       "      <td>8</td>\n",
       "      <td>0.538636</td>\n",
       "      <td>0.669717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>M13 EBM</td>\n",
       "      <td>0.760188</td>\n",
       "      <td>0.725832</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.034355</td>\n",
       "      <td>13</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.669736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>M23 EBM Adjusted 1</td>\n",
       "      <td>0.736410</td>\n",
       "      <td>0.725763</td>\n",
       "      <td>0.2178</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.010646</td>\n",
       "      <td>23</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.669687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>M8 EBM Adjusted 1</td>\n",
       "      <td>0.743572</td>\n",
       "      <td>0.725698</td>\n",
       "      <td>0.2169</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.017874</td>\n",
       "      <td>8</td>\n",
       "      <td>0.538636</td>\n",
       "      <td>0.669579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "514  M19 EBM Adjusted 2      0.756544        0.729734          0.2153   \n",
       "456             M23 EBM      0.762217        0.729273          0.2141   \n",
       "483  M19 EBM Adjusted 1      0.753422        0.728563          0.2156   \n",
       "513  M18 EBM Adjusted 2      0.759832        0.728308          0.2149   \n",
       "515  M20 EBM Adjusted 2      0.753729        0.728196          0.2156   \n",
       "442              M9 EBM      0.762717        0.728033          0.2141   \n",
       "525  M30 EBM Adjusted 2      0.747995        0.727965          0.2164   \n",
       "485  M21 EBM Adjusted 1      0.745826        0.727762          0.2167   \n",
       "484  M20 EBM Adjusted 1      0.748417        0.727667          0.2164   \n",
       "440              M7 EBM      0.765401        0.727386          0.2137   \n",
       "474  M10 EBM Adjusted 1      0.739305        0.727329          0.2174   \n",
       "482  M18 EBM Adjusted 1      0.755229        0.727098          0.2155   \n",
       "445             M12 EBM      0.760207        0.727088          0.2145   \n",
       "451             M18 EBM      0.783207        0.727065          0.2114   \n",
       "443             M10 EBM      0.766798        0.726993          0.2136   \n",
       "447             M14 EBM      0.761601        0.726991          0.2143   \n",
       "495  M31 EBM Adjusted 1      0.742422        0.726985          0.2172   \n",
       "453             M20 EBM      0.783635        0.726916          0.2114   \n",
       "444             M11 EBM      0.766312        0.726887          0.2136   \n",
       "448             M15 EBM      0.760804        0.726864          0.2144   \n",
       "494  M30 EBM Adjusted 1      0.743963        0.726811          0.2170   \n",
       "516  M21 EBM Adjusted 2      0.750283        0.726772          0.2161   \n",
       "486  M22 EBM Adjusted 1      0.741926        0.726765          0.2171   \n",
       "464             M31 EBM      0.781066        0.726712          0.2118   \n",
       "526  M31 EBM Adjusted 2      0.746505        0.726678          0.2166   \n",
       "452             M19 EBM      0.790839        0.726561          0.2102   \n",
       "475  M11 EBM Adjusted 1      0.738411        0.726542          0.2175   \n",
       "455             M22 EBM      0.765821        0.726432          0.2137   \n",
       "478  M14 EBM Adjusted 1      0.740413        0.726406          0.2173   \n",
       "458             M25 EBM      0.759795        0.726340          0.2145   \n",
       "457             M24 EBM      0.760277        0.726308          0.2144   \n",
       "473   M9 EBM Adjusted 1      0.738593        0.726296          0.2175   \n",
       "441              M8 EBM      0.766168        0.726259          0.2137   \n",
       "512  M17 EBM Adjusted 2      0.749817        0.726238          0.2162   \n",
       "481  M17 EBM Adjusted 1      0.746843        0.726236          0.2167   \n",
       "517  M22 EBM Adjusted 2      0.747202        0.726052          0.2164   \n",
       "503   M8 EBM Adjusted 2      0.746996        0.725894          0.2164   \n",
       "446             M13 EBM      0.760188        0.725832          0.2144   \n",
       "487  M23 EBM Adjusted 1      0.736410        0.725763          0.2178   \n",
       "472   M8 EBM Adjusted 1      0.743572        0.725698          0.2169   \n",
       "\n",
       "     Validation RMSLE  Difference AUC  Complexity  Normalized RMSLE  \\\n",
       "514            0.2230        0.026810          19          0.539256   \n",
       "456            0.2230        0.032944          23          0.539256   \n",
       "483            0.2230        0.024858          19          0.539256   \n",
       "513            0.2231        0.031524          18          0.539050   \n",
       "515            0.2230        0.025534          20          0.539256   \n",
       "442            0.2232        0.034684           9          0.538843   \n",
       "525            0.2228        0.020030          30          0.539669   \n",
       "485            0.2230        0.018064          21          0.539256   \n",
       "484            0.2230        0.020750          20          0.539256   \n",
       "440            0.2232        0.038015           7          0.538843   \n",
       "474            0.2231        0.011977          10          0.539050   \n",
       "482            0.2231        0.028131          18          0.539050   \n",
       "445            0.2231        0.033119          12          0.539050   \n",
       "451            0.2233        0.056142          18          0.538636   \n",
       "443            0.2231        0.039804          10          0.539050   \n",
       "447            0.2232        0.034610          14          0.538843   \n",
       "495            0.2230        0.015437          31          0.539256   \n",
       "453            0.2233        0.056718          20          0.538636   \n",
       "444            0.2232        0.039425          11          0.538843   \n",
       "448            0.2231        0.033939          15          0.539050   \n",
       "494            0.2230        0.017152          30          0.539256   \n",
       "516            0.2229        0.023511          21          0.539463   \n",
       "486            0.2232        0.015160          22          0.538843   \n",
       "464            0.2233        0.054354          31          0.538636   \n",
       "526            0.2230        0.019827          31          0.539256   \n",
       "452            0.2234        0.064278          19          0.538430   \n",
       "475            0.2231        0.011869          11          0.539050   \n",
       "455            0.2234        0.039389          22          0.538430   \n",
       "478            0.2232        0.014007          14          0.538843   \n",
       "458            0.2231        0.033455          25          0.539050   \n",
       "457            0.2233        0.033969          24          0.538636   \n",
       "473            0.2232        0.012297           9          0.538843   \n",
       "441            0.2233        0.039908           8          0.538636   \n",
       "512            0.2232        0.023579          17          0.538843   \n",
       "481            0.2232        0.020607          17          0.538843   \n",
       "517            0.2233        0.021150          22          0.538636   \n",
       "503            0.2233        0.021101           8          0.538636   \n",
       "446            0.2232        0.034355          13          0.538843   \n",
       "487            0.2232        0.010646          23          0.538843   \n",
       "472            0.2233        0.017874           8          0.538636   \n",
       "\n",
       "     Combined Score  \n",
       "514        0.672591  \n",
       "456        0.672268  \n",
       "483        0.671771  \n",
       "513        0.671530  \n",
       "515        0.671514  \n",
       "442        0.671276  \n",
       "525        0.671476  \n",
       "485        0.671210  \n",
       "484        0.671144  \n",
       "440        0.670823  \n",
       "474        0.670845  \n",
       "482        0.670683  \n",
       "445        0.670677  \n",
       "451        0.670536  \n",
       "443        0.670610  \n",
       "447        0.670547  \n",
       "495        0.670666  \n",
       "453        0.670432  \n",
       "444        0.670474  \n",
       "448        0.670520  \n",
       "494        0.670545  \n",
       "516        0.670579  \n",
       "486        0.670389  \n",
       "464        0.670289  \n",
       "526        0.670452  \n",
       "452        0.670122  \n",
       "475        0.670294  \n",
       "455        0.670031  \n",
       "478        0.670137  \n",
       "458        0.670153  \n",
       "457        0.670006  \n",
       "473        0.670060  \n",
       "441        0.669972  \n",
       "512        0.670019  \n",
       "481        0.670018  \n",
       "517        0.669827  \n",
       "503        0.669717  \n",
       "446        0.669736  \n",
       "487        0.669687  \n",
       "472        0.669579  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a 'Difference AUC' column to measure overfitting\n",
    "results_df['Difference AUC'] = abs(results_df['Training AUC'] - results_df['Validation AUC'])\n",
    "\n",
    "# Add a 'Complexity' column based on the model name. Assuming 'M1' is simpler than 'M11'.\n",
    "results_df['Complexity'] = results_df['Model'].apply(lambda x: int(x.split()[0][1:]))\n",
    "\n",
    "# Sort by Validation AUC (desc), then by Difference AUC (asc), then by Complexity (asc)\n",
    "sorted_results_df = results_df.sort_values(by=['Validation AUC', 'Difference AUC', 'Complexity'], ascending=[False, True, True])\n",
    "\n",
    "# Get the top 20 models\n",
    "top_20_models = sorted_results_df.head(40)\n",
    "top_20_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e95a0a1e-81b0-490d-9820-a230d43eb17e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Models Sorted by RMSLE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "      <th>Difference AUC</th>\n",
       "      <th>Complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>M30 EBM Adjusted 2</td>\n",
       "      <td>0.747995</td>\n",
       "      <td>0.727965</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2228</td>\n",
       "      <td>0.020030</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>M3 NN Conv1D Optimized 2</td>\n",
       "      <td>0.735827</td>\n",
       "      <td>0.716828</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.2228</td>\n",
       "      <td>0.018998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>M21 EBM Adjusted 2</td>\n",
       "      <td>0.750283</td>\n",
       "      <td>0.726772</td>\n",
       "      <td>0.2161</td>\n",
       "      <td>0.2229</td>\n",
       "      <td>0.023511</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>M10 NN Conv1D Optimized 2</td>\n",
       "      <td>0.748764</td>\n",
       "      <td>0.714428</td>\n",
       "      <td>0.2146</td>\n",
       "      <td>0.2229</td>\n",
       "      <td>0.034336</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>M20 NN Conv1D Optimized 2</td>\n",
       "      <td>0.736986</td>\n",
       "      <td>0.714197</td>\n",
       "      <td>0.2163</td>\n",
       "      <td>0.2229</td>\n",
       "      <td>0.022789</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>M19 EBM Adjusted 2</td>\n",
       "      <td>0.756544</td>\n",
       "      <td>0.729734</td>\n",
       "      <td>0.2153</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.026810</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>M23 EBM</td>\n",
       "      <td>0.762217</td>\n",
       "      <td>0.729273</td>\n",
       "      <td>0.2141</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.032944</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>M19 EBM Adjusted 1</td>\n",
       "      <td>0.753422</td>\n",
       "      <td>0.728563</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.024858</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>M20 EBM Adjusted 2</td>\n",
       "      <td>0.753729</td>\n",
       "      <td>0.728196</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.025534</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>M21 EBM Adjusted 1</td>\n",
       "      <td>0.745826</td>\n",
       "      <td>0.727762</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.018064</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>M20 EBM Adjusted 1</td>\n",
       "      <td>0.748417</td>\n",
       "      <td>0.727667</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.020750</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>M31 EBM Adjusted 1</td>\n",
       "      <td>0.742422</td>\n",
       "      <td>0.726985</td>\n",
       "      <td>0.2172</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.015437</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>M30 EBM Adjusted 1</td>\n",
       "      <td>0.743963</td>\n",
       "      <td>0.726811</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.017152</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>M31 EBM Adjusted 2</td>\n",
       "      <td>0.746505</td>\n",
       "      <td>0.726678</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.019827</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.744133</td>\n",
       "      <td>0.720031</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.024102</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.748208</td>\n",
       "      <td>0.718108</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.743683</td>\n",
       "      <td>0.717296</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.026387</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.739494</td>\n",
       "      <td>0.717039</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.022455</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.743502</td>\n",
       "      <td>0.716064</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.027439</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>M31 NN Complex</td>\n",
       "      <td>0.744693</td>\n",
       "      <td>0.715496</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.029197</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "525         M30 EBM Adjusted 2      0.747995        0.727965          0.2164   \n",
       "684   M3 NN Conv1D Optimized 2      0.735827        0.716828          0.2167   \n",
       "516         M21 EBM Adjusted 2      0.750283        0.726772          0.2161   \n",
       "691  M10 NN Conv1D Optimized 2      0.748764        0.714428          0.2146   \n",
       "701  M20 NN Conv1D Optimized 2      0.736986        0.714197          0.2163   \n",
       "514         M19 EBM Adjusted 2      0.756544        0.729734          0.2153   \n",
       "456                    M23 EBM      0.762217        0.729273          0.2141   \n",
       "483         M19 EBM Adjusted 1      0.753422        0.728563          0.2156   \n",
       "515         M20 EBM Adjusted 2      0.753729        0.728196          0.2156   \n",
       "485         M21 EBM Adjusted 1      0.745826        0.727762          0.2167   \n",
       "484         M20 EBM Adjusted 1      0.748417        0.727667          0.2164   \n",
       "495         M31 EBM Adjusted 1      0.742422        0.726985          0.2172   \n",
       "494         M30 EBM Adjusted 1      0.743963        0.726811          0.2170   \n",
       "526         M31 EBM Adjusted 2      0.746505        0.726678          0.2166   \n",
       "629             M31 NN Complex      0.744133        0.720031          0.2166   \n",
       "648             M31 NN Complex      0.748208        0.718108          0.2166   \n",
       "622             M31 NN Complex      0.743683        0.717296          0.2166   \n",
       "640             M31 NN Complex      0.739494        0.717039          0.2166   \n",
       "634             M31 NN Complex      0.743502        0.716064          0.2166   \n",
       "646             M31 NN Complex      0.744693        0.715496          0.2166   \n",
       "\n",
       "     Validation RMSLE  Difference AUC  Complexity  \n",
       "525            0.2228        0.020030          30  \n",
       "684            0.2228        0.018998           3  \n",
       "516            0.2229        0.023511          21  \n",
       "691            0.2229        0.034336          10  \n",
       "701            0.2229        0.022789          20  \n",
       "514            0.2230        0.026810          19  \n",
       "456            0.2230        0.032944          23  \n",
       "483            0.2230        0.024858          19  \n",
       "515            0.2230        0.025534          20  \n",
       "485            0.2230        0.018064          21  \n",
       "484            0.2230        0.020750          20  \n",
       "495            0.2230        0.015437          31  \n",
       "494            0.2230        0.017152          30  \n",
       "526            0.2230        0.019827          31  \n",
       "629            0.2230        0.024102          31  \n",
       "648            0.2230        0.030100          31  \n",
       "622            0.2230        0.026387          31  \n",
       "640            0.2230        0.022455          31  \n",
       "634            0.2230        0.027439          31  \n",
       "646            0.2230        0.029197          31  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sorting models by Validation RMSLE (ascending), then by Validation AUC (descending) for a focus on prediction accuracy\n",
    "sorted_by_rmsle_df = results_df.sort_values(by=['Validation RMSLE', 'Validation AUC'], ascending=[True, False])\n",
    "\n",
    "# Get the top 10 models focused on RMSLE\n",
    "top_20_models_rmsle = sorted_by_rmsle_df.head(20)\n",
    "print(\"Top 20 Models Sorted by RMSLE:\")\n",
    "top_20_models_rmsle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dcf7299d-146e-41f7-a353-0b248bd6b938",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Models Sorted by Combined Score (AUC & RMSLE):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training AUC</th>\n",
       "      <th>Validation AUC</th>\n",
       "      <th>Training RMSLE</th>\n",
       "      <th>Validation RMSLE</th>\n",
       "      <th>Difference AUC</th>\n",
       "      <th>Complexity</th>\n",
       "      <th>Normalized RMSLE</th>\n",
       "      <th>Combined Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>M19 EBM Adjusted 2</td>\n",
       "      <td>0.756544</td>\n",
       "      <td>0.729734</td>\n",
       "      <td>0.2153</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.026810</td>\n",
       "      <td>19</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.672591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>M23 EBM</td>\n",
       "      <td>0.762217</td>\n",
       "      <td>0.729273</td>\n",
       "      <td>0.2141</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.032944</td>\n",
       "      <td>23</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.672268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>M19 EBM Adjusted 1</td>\n",
       "      <td>0.753422</td>\n",
       "      <td>0.728563</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.024858</td>\n",
       "      <td>19</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.671771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>M18 EBM Adjusted 2</td>\n",
       "      <td>0.759832</td>\n",
       "      <td>0.728308</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.031524</td>\n",
       "      <td>18</td>\n",
       "      <td>0.539050</td>\n",
       "      <td>0.671530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>M20 EBM Adjusted 2</td>\n",
       "      <td>0.753729</td>\n",
       "      <td>0.728196</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.025534</td>\n",
       "      <td>20</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.671514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>M30 EBM Adjusted 2</td>\n",
       "      <td>0.747995</td>\n",
       "      <td>0.727965</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2228</td>\n",
       "      <td>0.020030</td>\n",
       "      <td>30</td>\n",
       "      <td>0.539669</td>\n",
       "      <td>0.671476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>M9 EBM</td>\n",
       "      <td>0.762717</td>\n",
       "      <td>0.728033</td>\n",
       "      <td>0.2141</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.034684</td>\n",
       "      <td>9</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.671276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>M21 EBM Adjusted 1</td>\n",
       "      <td>0.745826</td>\n",
       "      <td>0.727762</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.018064</td>\n",
       "      <td>21</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.671210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>M20 EBM Adjusted 1</td>\n",
       "      <td>0.748417</td>\n",
       "      <td>0.727667</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.020750</td>\n",
       "      <td>20</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.671144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>M10 EBM Adjusted 1</td>\n",
       "      <td>0.739305</td>\n",
       "      <td>0.727329</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.011977</td>\n",
       "      <td>10</td>\n",
       "      <td>0.539050</td>\n",
       "      <td>0.670845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>M7 EBM</td>\n",
       "      <td>0.765401</td>\n",
       "      <td>0.727386</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.038015</td>\n",
       "      <td>7</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.670823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>M18 EBM Adjusted 1</td>\n",
       "      <td>0.755229</td>\n",
       "      <td>0.727098</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.028131</td>\n",
       "      <td>18</td>\n",
       "      <td>0.539050</td>\n",
       "      <td>0.670683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>M12 EBM</td>\n",
       "      <td>0.760207</td>\n",
       "      <td>0.727088</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.033119</td>\n",
       "      <td>12</td>\n",
       "      <td>0.539050</td>\n",
       "      <td>0.670677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>M31 EBM Adjusted 1</td>\n",
       "      <td>0.742422</td>\n",
       "      <td>0.726985</td>\n",
       "      <td>0.2172</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.015437</td>\n",
       "      <td>31</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.670666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>M10 EBM</td>\n",
       "      <td>0.766798</td>\n",
       "      <td>0.726993</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.039804</td>\n",
       "      <td>10</td>\n",
       "      <td>0.539050</td>\n",
       "      <td>0.670610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>M21 EBM Adjusted 2</td>\n",
       "      <td>0.750283</td>\n",
       "      <td>0.726772</td>\n",
       "      <td>0.2161</td>\n",
       "      <td>0.2229</td>\n",
       "      <td>0.023511</td>\n",
       "      <td>21</td>\n",
       "      <td>0.539463</td>\n",
       "      <td>0.670579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>M14 EBM</td>\n",
       "      <td>0.761601</td>\n",
       "      <td>0.726991</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.034610</td>\n",
       "      <td>14</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.670547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>M30 EBM Adjusted 1</td>\n",
       "      <td>0.743963</td>\n",
       "      <td>0.726811</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.017152</td>\n",
       "      <td>30</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.670545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>M18 EBM</td>\n",
       "      <td>0.783207</td>\n",
       "      <td>0.727065</td>\n",
       "      <td>0.2114</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.056142</td>\n",
       "      <td>18</td>\n",
       "      <td>0.538636</td>\n",
       "      <td>0.670536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>M15 EBM</td>\n",
       "      <td>0.760804</td>\n",
       "      <td>0.726864</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.033939</td>\n",
       "      <td>15</td>\n",
       "      <td>0.539050</td>\n",
       "      <td>0.670520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>M11 EBM</td>\n",
       "      <td>0.766312</td>\n",
       "      <td>0.726887</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.039425</td>\n",
       "      <td>11</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.670474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>M31 EBM Adjusted 2</td>\n",
       "      <td>0.746505</td>\n",
       "      <td>0.726678</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.019827</td>\n",
       "      <td>31</td>\n",
       "      <td>0.539256</td>\n",
       "      <td>0.670452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>M20 EBM</td>\n",
       "      <td>0.783635</td>\n",
       "      <td>0.726916</td>\n",
       "      <td>0.2114</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.056718</td>\n",
       "      <td>20</td>\n",
       "      <td>0.538636</td>\n",
       "      <td>0.670432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>M22 EBM Adjusted 1</td>\n",
       "      <td>0.741926</td>\n",
       "      <td>0.726765</td>\n",
       "      <td>0.2171</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.015160</td>\n",
       "      <td>22</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.670389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>M11 EBM Adjusted 1</td>\n",
       "      <td>0.738411</td>\n",
       "      <td>0.726542</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.011869</td>\n",
       "      <td>11</td>\n",
       "      <td>0.539050</td>\n",
       "      <td>0.670294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>M31 EBM</td>\n",
       "      <td>0.781066</td>\n",
       "      <td>0.726712</td>\n",
       "      <td>0.2118</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.054354</td>\n",
       "      <td>31</td>\n",
       "      <td>0.538636</td>\n",
       "      <td>0.670289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>M25 EBM</td>\n",
       "      <td>0.759795</td>\n",
       "      <td>0.726340</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.033455</td>\n",
       "      <td>25</td>\n",
       "      <td>0.539050</td>\n",
       "      <td>0.670153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>M14 EBM Adjusted 1</td>\n",
       "      <td>0.740413</td>\n",
       "      <td>0.726406</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.014007</td>\n",
       "      <td>14</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.670137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>M19 EBM</td>\n",
       "      <td>0.790839</td>\n",
       "      <td>0.726561</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.2234</td>\n",
       "      <td>0.064278</td>\n",
       "      <td>19</td>\n",
       "      <td>0.538430</td>\n",
       "      <td>0.670122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>M9 EBM Adjusted 1</td>\n",
       "      <td>0.738593</td>\n",
       "      <td>0.726296</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.012297</td>\n",
       "      <td>9</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.670060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>M22 EBM</td>\n",
       "      <td>0.765821</td>\n",
       "      <td>0.726432</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>0.2234</td>\n",
       "      <td>0.039389</td>\n",
       "      <td>22</td>\n",
       "      <td>0.538430</td>\n",
       "      <td>0.670031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>M17 EBM Adjusted 2</td>\n",
       "      <td>0.749817</td>\n",
       "      <td>0.726238</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.023579</td>\n",
       "      <td>17</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.670019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>M17 EBM Adjusted 1</td>\n",
       "      <td>0.746843</td>\n",
       "      <td>0.726236</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.020607</td>\n",
       "      <td>17</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.670018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>M24 EBM</td>\n",
       "      <td>0.760277</td>\n",
       "      <td>0.726308</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.033969</td>\n",
       "      <td>24</td>\n",
       "      <td>0.538636</td>\n",
       "      <td>0.670006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>M8 EBM</td>\n",
       "      <td>0.766168</td>\n",
       "      <td>0.726259</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.039908</td>\n",
       "      <td>8</td>\n",
       "      <td>0.538636</td>\n",
       "      <td>0.669972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>M22 EBM Adjusted 2</td>\n",
       "      <td>0.747202</td>\n",
       "      <td>0.726052</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.021150</td>\n",
       "      <td>22</td>\n",
       "      <td>0.538636</td>\n",
       "      <td>0.669827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>M13 EBM</td>\n",
       "      <td>0.760188</td>\n",
       "      <td>0.725832</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.034355</td>\n",
       "      <td>13</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.669736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>M8 EBM Adjusted 2</td>\n",
       "      <td>0.746996</td>\n",
       "      <td>0.725894</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.021101</td>\n",
       "      <td>8</td>\n",
       "      <td>0.538636</td>\n",
       "      <td>0.669717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>M23 EBM Adjusted 1</td>\n",
       "      <td>0.736410</td>\n",
       "      <td>0.725763</td>\n",
       "      <td>0.2178</td>\n",
       "      <td>0.2232</td>\n",
       "      <td>0.010646</td>\n",
       "      <td>23</td>\n",
       "      <td>0.538843</td>\n",
       "      <td>0.669687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>M8 EBM Adjusted 1</td>\n",
       "      <td>0.743572</td>\n",
       "      <td>0.725698</td>\n",
       "      <td>0.2169</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.017874</td>\n",
       "      <td>8</td>\n",
       "      <td>0.538636</td>\n",
       "      <td>0.669579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Training AUC  Validation AUC  Training RMSLE  \\\n",
       "514  M19 EBM Adjusted 2      0.756544        0.729734          0.2153   \n",
       "456             M23 EBM      0.762217        0.729273          0.2141   \n",
       "483  M19 EBM Adjusted 1      0.753422        0.728563          0.2156   \n",
       "513  M18 EBM Adjusted 2      0.759832        0.728308          0.2149   \n",
       "515  M20 EBM Adjusted 2      0.753729        0.728196          0.2156   \n",
       "525  M30 EBM Adjusted 2      0.747995        0.727965          0.2164   \n",
       "442              M9 EBM      0.762717        0.728033          0.2141   \n",
       "485  M21 EBM Adjusted 1      0.745826        0.727762          0.2167   \n",
       "484  M20 EBM Adjusted 1      0.748417        0.727667          0.2164   \n",
       "474  M10 EBM Adjusted 1      0.739305        0.727329          0.2174   \n",
       "440              M7 EBM      0.765401        0.727386          0.2137   \n",
       "482  M18 EBM Adjusted 1      0.755229        0.727098          0.2155   \n",
       "445             M12 EBM      0.760207        0.727088          0.2145   \n",
       "495  M31 EBM Adjusted 1      0.742422        0.726985          0.2172   \n",
       "443             M10 EBM      0.766798        0.726993          0.2136   \n",
       "516  M21 EBM Adjusted 2      0.750283        0.726772          0.2161   \n",
       "447             M14 EBM      0.761601        0.726991          0.2143   \n",
       "494  M30 EBM Adjusted 1      0.743963        0.726811          0.2170   \n",
       "451             M18 EBM      0.783207        0.727065          0.2114   \n",
       "448             M15 EBM      0.760804        0.726864          0.2144   \n",
       "444             M11 EBM      0.766312        0.726887          0.2136   \n",
       "526  M31 EBM Adjusted 2      0.746505        0.726678          0.2166   \n",
       "453             M20 EBM      0.783635        0.726916          0.2114   \n",
       "486  M22 EBM Adjusted 1      0.741926        0.726765          0.2171   \n",
       "475  M11 EBM Adjusted 1      0.738411        0.726542          0.2175   \n",
       "464             M31 EBM      0.781066        0.726712          0.2118   \n",
       "458             M25 EBM      0.759795        0.726340          0.2145   \n",
       "478  M14 EBM Adjusted 1      0.740413        0.726406          0.2173   \n",
       "452             M19 EBM      0.790839        0.726561          0.2102   \n",
       "473   M9 EBM Adjusted 1      0.738593        0.726296          0.2175   \n",
       "455             M22 EBM      0.765821        0.726432          0.2137   \n",
       "512  M17 EBM Adjusted 2      0.749817        0.726238          0.2162   \n",
       "481  M17 EBM Adjusted 1      0.746843        0.726236          0.2167   \n",
       "457             M24 EBM      0.760277        0.726308          0.2144   \n",
       "441              M8 EBM      0.766168        0.726259          0.2137   \n",
       "517  M22 EBM Adjusted 2      0.747202        0.726052          0.2164   \n",
       "446             M13 EBM      0.760188        0.725832          0.2144   \n",
       "503   M8 EBM Adjusted 2      0.746996        0.725894          0.2164   \n",
       "487  M23 EBM Adjusted 1      0.736410        0.725763          0.2178   \n",
       "472   M8 EBM Adjusted 1      0.743572        0.725698          0.2169   \n",
       "\n",
       "     Validation RMSLE  Difference AUC  Complexity  Normalized RMSLE  \\\n",
       "514            0.2230        0.026810          19          0.539256   \n",
       "456            0.2230        0.032944          23          0.539256   \n",
       "483            0.2230        0.024858          19          0.539256   \n",
       "513            0.2231        0.031524          18          0.539050   \n",
       "515            0.2230        0.025534          20          0.539256   \n",
       "525            0.2228        0.020030          30          0.539669   \n",
       "442            0.2232        0.034684           9          0.538843   \n",
       "485            0.2230        0.018064          21          0.539256   \n",
       "484            0.2230        0.020750          20          0.539256   \n",
       "474            0.2231        0.011977          10          0.539050   \n",
       "440            0.2232        0.038015           7          0.538843   \n",
       "482            0.2231        0.028131          18          0.539050   \n",
       "445            0.2231        0.033119          12          0.539050   \n",
       "495            0.2230        0.015437          31          0.539256   \n",
       "443            0.2231        0.039804          10          0.539050   \n",
       "516            0.2229        0.023511          21          0.539463   \n",
       "447            0.2232        0.034610          14          0.538843   \n",
       "494            0.2230        0.017152          30          0.539256   \n",
       "451            0.2233        0.056142          18          0.538636   \n",
       "448            0.2231        0.033939          15          0.539050   \n",
       "444            0.2232        0.039425          11          0.538843   \n",
       "526            0.2230        0.019827          31          0.539256   \n",
       "453            0.2233        0.056718          20          0.538636   \n",
       "486            0.2232        0.015160          22          0.538843   \n",
       "475            0.2231        0.011869          11          0.539050   \n",
       "464            0.2233        0.054354          31          0.538636   \n",
       "458            0.2231        0.033455          25          0.539050   \n",
       "478            0.2232        0.014007          14          0.538843   \n",
       "452            0.2234        0.064278          19          0.538430   \n",
       "473            0.2232        0.012297           9          0.538843   \n",
       "455            0.2234        0.039389          22          0.538430   \n",
       "512            0.2232        0.023579          17          0.538843   \n",
       "481            0.2232        0.020607          17          0.538843   \n",
       "457            0.2233        0.033969          24          0.538636   \n",
       "441            0.2233        0.039908           8          0.538636   \n",
       "517            0.2233        0.021150          22          0.538636   \n",
       "446            0.2232        0.034355          13          0.538843   \n",
       "503            0.2233        0.021101           8          0.538636   \n",
       "487            0.2232        0.010646          23          0.538843   \n",
       "472            0.2233        0.017874           8          0.538636   \n",
       "\n",
       "     Combined Score  \n",
       "514        0.672591  \n",
       "456        0.672268  \n",
       "483        0.671771  \n",
       "513        0.671530  \n",
       "515        0.671514  \n",
       "525        0.671476  \n",
       "442        0.671276  \n",
       "485        0.671210  \n",
       "484        0.671144  \n",
       "474        0.670845  \n",
       "440        0.670823  \n",
       "482        0.670683  \n",
       "445        0.670677  \n",
       "495        0.670666  \n",
       "443        0.670610  \n",
       "516        0.670579  \n",
       "447        0.670547  \n",
       "494        0.670545  \n",
       "451        0.670536  \n",
       "448        0.670520  \n",
       "444        0.670474  \n",
       "526        0.670452  \n",
       "453        0.670432  \n",
       "486        0.670389  \n",
       "475        0.670294  \n",
       "464        0.670289  \n",
       "458        0.670153  \n",
       "478        0.670137  \n",
       "452        0.670122  \n",
       "473        0.670060  \n",
       "455        0.670031  \n",
       "512        0.670019  \n",
       "481        0.670018  \n",
       "457        0.670006  \n",
       "441        0.669972  \n",
       "517        0.669827  \n",
       "446        0.669736  \n",
       "503        0.669717  \n",
       "487        0.669687  \n",
       "472        0.669579  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize RMSLE (assuming lower is better and to align with AUC's higher is better)\n",
    "max_rmsle = results_df['Validation RMSLE'].max()\n",
    "results_df['Normalized RMSLE'] = 1 - (results_df['Validation RMSLE'] / max_rmsle)\n",
    "\n",
    "# Simple combined score (example: 70% weight on AUC, 30% weight on Normalized RMSLE)\n",
    "results_df['Combined Score'] = 0.7 * results_df['Validation AUC'] + 0.3 * results_df['Normalized RMSLE']\n",
    "\n",
    "# Sort by combined score (descending)\n",
    "sorted_by_combined_score_df = results_df.sort_values(by='Combined Score', ascending=False)\n",
    "\n",
    "# Get the top 20 models based on the combined score\n",
    "top_20_models_combined = sorted_by_combined_score_df.head(40)\n",
    "print(\"Top 20 Models Sorted by Combined Score (AUC & RMSLE):\")\n",
    "top_20_models_combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d916fee6-0b25-4e08-81c1-99e1c32e8bc0",
   "metadata": {},
   "source": [
    "# Test Set Prediction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "02d3cc89-8289-41ef-95a4-7e98813f87d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prediction_folder(day):\n",
    "    folder_path = f'Predictions/Day_{day}'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be16c003-cfae-4a96-89f2-5d0f8d85811a",
   "metadata": {},
   "source": [
    "### Prediction Functions\n",
    "---\n",
    "\n",
    "Since some models are repeated frequently, it will clean up the code to utilize functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51128a90-6832-4199-a7f5-9adabb966cae",
   "metadata": {},
   "source": [
    "#### Simple EBM Prediction Function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e15e990-77bb-4889-b96d-e8cb03c6d0dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simple_ebm_prediction(model, day):\n",
    "    features = models[model]\n",
    "\n",
    "    # Training the \"M9\" EBM model\n",
    "    ebm = ExplainableBoostingClassifier(random_state=20240325)\n",
    "    ebm.fit(X_train[features], y_train)\n",
    "\n",
    "    X_test = test_data[features]\n",
    "\n",
    "    # Predicting with the model\n",
    "    test_data['score'] = ebm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Saving the required predictions\n",
    "    test_data[['article_id', 'score']].to_csv(f'Predictions/Day_{day}/{model}_ebm_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc80151-89ec-4e2c-864f-af3ef9253af5",
   "metadata": {},
   "source": [
    "#### Adjusted EBM 1 Prediction Function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8241c519-6ae0-43cd-9b86-f63fa072e51c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ebm_adjusted_1_prediction(model, day):\n",
    "    features = models[model]\n",
    "\n",
    "    # Adjusted EBM Model 1\n",
    "    ebm_adjusted_1 = ExplainableBoostingClassifier(\n",
    "        random_state=20240325,\n",
    "        learning_rate=0.01,\n",
    "        max_bins=256,\n",
    "        interactions=10,\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "    ebm_adjusted_1.fit(X_train[features], y_train)\n",
    "\n",
    "    X_test = test_data[features]\n",
    "\n",
    "    # Predicting with the model\n",
    "    test_data['score'] = ebm_adjusted_1.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Saving the required predictions\n",
    "    test_data[['article_id', 'score']].to_csv(f'Predictions/Day_{day}/{model}_ebm_adjusted_1_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d9423-1ad8-4191-be0f-86b9a1fb6382",
   "metadata": {},
   "source": [
    "#### Adjusted EBM 2 Prediction Function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e92c988-e1b7-4600-9be7-265118217eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ebm_adjusted_2_prediction(model, day):\n",
    "    features = models[model]\n",
    "\n",
    "    # Adjusted EBM Model 2\n",
    "    ebm_adjusted_2 = ExplainableBoostingClassifier(\n",
    "        random_state=20240325,\n",
    "        learning_rate=0.005,\n",
    "        max_bins=512,\n",
    "        interactions=15,\n",
    "        early_stopping_rounds=100,\n",
    "        n_jobs=-1  # Utilize all available CPU cores\n",
    "    )\n",
    "    ebm_adjusted_2.fit(X_train[features], y_train)\n",
    "\n",
    "    X_test = test_data[features]\n",
    "\n",
    "    # Predicting with the model\n",
    "    test_data['score'] = ebm_adjusted_2.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Saving the required predictions\n",
    "    test_data[['article_id', 'score']].to_csv(f'Predictions/Day_{day}/{model}_ebm_adjusted_2_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083a9969-0199-4c71-a1a6-0de09ca96977",
   "metadata": {},
   "source": [
    "## Day 1 Predictions\n",
    "---\n",
    "\n",
    "All of the predictions from day one came from the simple EBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ff7ec3f-ef88-4105-9a89-359b63a865ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_folder('1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e7eca6-7757-473c-ac21-85ce3412745c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Simple EBM M9 Prediction \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1fb5f35c-025a-4a49-b476-a1e10798c7a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_ebm_prediction('M9', '1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351cd996-075c-4207-b15b-55fd5b3dcfed",
   "metadata": {},
   "source": [
    "### Simple EBM M7 Prediction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26d4f6b1-cc52-44d5-9ff9-e7378f1dcaa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_ebm_prediction('M7', '1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc8a201-2dc8-4472-8910-5c26672c320d",
   "metadata": {},
   "source": [
    "### Simple EBM M10 Prediction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c640bec7-6839-4304-a312-ff78f4a35e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_ebm_prediction('M10', '1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c22a36c-e64e-4b48-af16-a9db67e1738c",
   "metadata": {},
   "source": [
    "### Simple EBM M6 Prediction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b91a2a93-12d6-4bde-b63c-83b1314e055f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_ebm_prediction('M6', '1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd1d2a4-4966-4126-99e9-2dd500e326d7",
   "metadata": {},
   "source": [
    "### Simple EBM M12 Prediction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc1782da-5922-40db-8a98-d9c7fe177828",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ebm_prediction('M12', '1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488a8ebf-39a7-4557-a348-b2980cc1296a",
   "metadata": {},
   "source": [
    "## Day 2 Predictions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1bd9485-3d8b-405c-90da-bfcbe120ddbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_folder('2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e122fc51-fc59-4e87-8a89-0c0d5b0ab95d",
   "metadata": {},
   "source": [
    "### Simple EBM M11 Prediction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "df75a49f-bc44-4f08-b3a9-850e5077462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ebm_prediction('M11', '2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0548c9a2-d6e2-455c-8277-fdf54a080634",
   "metadata": {},
   "source": [
    "### Adjusted EBM 1 M10 Prediction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "67f9346b-db13-4992-8b92-cecdd0a78779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ebm_adjusted_1_prediction('M10', '2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c4320b-a0b0-487e-b7cb-698dd549fdad",
   "metadata": {},
   "source": [
    "### Adjusted EBM 1 M11 Prediction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "606dd9a7-ff14-4d28-95fd-46e588bcecd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ebm_adjusted_1_prediction('M11', '2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e694ec-5202-4506-9317-fc84c2711f3a",
   "metadata": {},
   "source": [
    "### Adjusted EBM 1 M12 Prediction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c64caee-9a1d-497e-8045-d5be6d1325f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ebm_adjusted_1_prediction('M12', '2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e1321e-8e8d-4971-b5a3-853aee44ba9c",
   "metadata": {},
   "source": [
    "### Adjusted EBM 1 M9 Prediction\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ac3cdafe-116a-4270-a4d7-84f86a5d43f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ebm_adjusted_1_prediction('M9', '2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6860f173-5a64-43a1-bdda-a2e8bdfdb132",
   "metadata": {},
   "source": [
    "## Day 3 Predictions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e1f60648-ae4a-4c25-9d73-dcd9a0b8438d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_folder('3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f3dbba8a-4cbe-468c-b5ad-82e5b9314a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm_adjusted_1_prediction('M19', '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "327a40e0-547a-4553-ae3d-8d5d82cff8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ebm_adjusted_2_prediction('M18', '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0798461-4df9-4e2c-b3dd-6d14ad874eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ebm_adjusted_2_prediction('M19', '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3832b909-3f29-4ce7-b245-f4667dafc3e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ebm_adjusted_2_prediction('M20', '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f5183bf7-11df-41ee-811d-ed0758dfc902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_ebm_prediction('M18', '3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eae7c74-011d-4cc6-8ded-204749a47062",
   "metadata": {},
   "source": [
    "## Day 4 Predictions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "024cbe27-febd-4b12-bc2c-6542d766fc50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_folder('4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "62392dd9-ee45-45ef-89fa-138619ef78d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_ebm_prediction('M23', '4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c2cf68b5-747a-4f99-802e-2d9dcf6de168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_ebm_prediction('M19', '4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6a6bdf05-98d7-443f-9751-0e172af8c7dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_ebm_prediction('M31', '4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f82cfdd8-0d8e-49dd-ba01-bbb298e710b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_ebm_prediction('M24', '4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dd84957e-b9a6-418a-85d1-494349fb4908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_ebm_prediction('M13', '4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e0d9a0-78d2-4666-a3d6-5ce320a840f6",
   "metadata": {},
   "source": [
    "## Day 5 Predictions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "df34d17a-ab5e-4692-a245-46db9c0b0e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_folder('5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7af29fb7-7ba9-481c-9b00-a4e5998199e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_ebm_prediction('M22', '5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9c252b83-0328-4d13-a035-db025638a004",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ebm_adjusted_2_prediction('M30', '5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "03d7c95b-44cc-4701-a601-d00aa716be9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ebm_adjusted_1_prediction('M18', '5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b03f877c-d214-44c4-a08a-3254eec5aee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ebm_adjusted_1_prediction('M31', '5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "da54f752-0f62-4dac-a449-8dc06c4734fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ebm_adjusted_2_prediction('M21', '5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d3da52-803d-4070-9577-53b1c78fb992",
   "metadata": {},
   "source": [
    "## Day 6 Predictions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b89247e2-0f1a-4a6f-8379-a97dafe7a118",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_folder('6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "acaa0b63-c08e-4cf7-ba59-9c5d8949aae0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_ebm_prediction('M14', '6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e2b0fbed-b863-4fc5-8059-38d8e78596b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_ebm_prediction('M15', '6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d4aa7a91-40c2-461e-be12-53c387a07121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_ebm_prediction('M20', '6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ea240e87-1526-4421-8ed2-880629fe9b92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_ebm_prediction('M25', '6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "697bf46e-00e7-4312-bc08-beebfa7e29f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ebm_adjusted_1_prediction('M30', '6')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b6079-ba41-4fb1-bb79-5cb9741f9a69",
   "metadata": {},
   "source": [
    "## Day 7 Predictions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d70f40b7-ab06-4ab3-a48e-152bb499596e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_folder('7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5276d6b7-b844-4c40-ac84-03405a4d6f98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ebm_adjusted_2_prediction('M31', '7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "79c83cfe-201a-4753-b5b3-c381f7c5f229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ebm_adjusted_1_prediction('M22', '7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b52958e7-db4a-4637-a8a8-a4dc4fa79d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ebm_adjusted_1_prediction('M14', '7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74353151-9a46-4c7d-9955-6bb828709fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
