{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8ca344b-fb23-45fe-bfb5-4964b52ba941",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc7391d-5e43-43c5-93cc-10df934bb858",
   "metadata": {},
   "source": [
    "### Try a pre-trained model on random (AI-generated) pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f328c67-f5b3-4082-8e0c-054d323b7fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import load_img, img_to_array\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "pretrained_model = ResNet50(weights='imagenet')\n",
    "print(pretrained_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dfa298-edd1-4b8a-a5e1-dae6c554bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ResNet = (224, 224)\n",
    "img_path = #TODO\n",
    "img = load_img(img_path, target_size=size_ResNet)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806532fa-30fa-4db4-a64a-99793cee9244",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = img_to_array(img)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381c8026-881b-45be-8ecc-6fa0d40904a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure it is one sample with 3 dimensions\n",
    "import numpy as np\n",
    "\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a63f562-04ae-460a-89b5-e57635513648",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pretrained_model.predict(x)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa66f896-a183-49b3-85c3-638331d8e84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import decode_predictions\n",
    "decoded_preds = decode_predictions(preds, top=3)\n",
    "[(i[1], round(i[2], 4)) for i in decoded_preds[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8611dc-d727-4f54-beea-633fcb747234",
   "metadata": {},
   "source": [
    "### Apply transfer learning for a \"real\" task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1116c86e-1939-48a5-b415-5bd86ee69000",
   "metadata": {},
   "source": [
    "Fun [story](https://youtu.be/vIci3C4JkL0) from HBO's Silicon Valley series from 2017: Shazam for food.\n",
    "\n",
    "Download the data from [Kaggle](https://www.kaggle.com/datasets/dansbecker/hot-dog-not-hot-dog)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17108d2-0c16-400f-a237-d08ca3c96b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "folder_where_data_resides = \"../../data/hotdog/\"\n",
    "\n",
    "# Look at an example hot_dog:\n",
    "hot_dog = load_img(path.join(folder_where_data_resides, \"train/hot_dog/1000288.jpg\"), target_size=size_ResNet)\n",
    "hot_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec25f05e-c903-4c94-861d-b7ee1755a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at an example not hot_dog\n",
    "not_hot_dog = load_img(path.join(folder_where_data_resides, \"train/not_hot_dog/100135.jpg\"), target_size=size_ResNet)\n",
    "not_hot_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4ae34e-045f-4e73-887f-be7d6416a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    return np.expand_dims(img_to_array(img), axis=0)\n",
    "\n",
    "def predict_top_classes(preprocessed_img):\n",
    "    preds = pretrained_model.predict(preprocessed_img)\n",
    "    decoded_preds = decode_predictions(preds, top=3)\n",
    "    return [(i[1], round(i[2], 4)) for i in decoded_preds[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd9527-ba8a-48d0-9cae-4b8346bb6dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Prediction for a sample hot dog:\", predict_top_classes(preprocess_image(hot_dog)))\n",
    "print(\"Prediction for a sample not hot dog:\", predict_top_classes(preprocess_image(not_hot_dog)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9cdb42-7332-47df-b6df-0185e9c7466c",
   "metadata": {},
   "source": [
    "### Load the whole data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822923a5-f52b-4e02-990b-2ba8f9b5f4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from keras.utils import image_dataset_from_directory\n",
    "\n",
    "train_dataset = image_dataset_from_directory(path.join(folder_where_data_resides, \"train\"), batch_size=32, image_size=size_ResNet)\n",
    "test_dataset = image_dataset_from_directory(path.join(folder_where_data_resides, \"train\"), batch_size=32, image_size=size_ResNet)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c80b1-1bdc-443a-a077-903b2ff4973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_dataset.take(1):\n",
    "    print(\"Batch shape:\", images.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559f724b-22a4-4864-8552-61b84f559e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import array_to_img\n",
    "\n",
    "# Take 1 batch and look for the first 15 images:\n",
    "for images, labels in train_dataset.take(1):\n",
    "    for i in range(15):\n",
    "        plt.subplot(3, 5, i+1)\n",
    "        plt.imshow(array_to_img(images[i]))\n",
    "        plt.title(train_dataset.class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1f45bb-e53d-4ebc-9094-f3c990f71c2e",
   "metadata": {},
   "source": [
    "### Build a CNN for this task from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b391220-357d-46f1-b8bb-7a99e1a432fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model we ended up with the digit recognition example\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "\n",
    "# Build the model\n",
    "\n",
    "# Compile the model and print summary\n",
    "\n",
    "# Fit the model (with early stopping) and look at validation accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8b5836-f7a4-4dfa-9467-438d482f0f49",
   "metadata": {},
   "source": [
    "### Fine-tune a pre-defined model for our task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e2071-ea58-4f92-aa43-cd21273e776f",
   "metadata": {},
   "source": [
    "We can fine-tune a pre-trained model for our purposes by modifying the last few layers, and learn only the new parameters on new data (freezing the weights of the original network)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69cb260-40dd-473e-9eb7-11e4f8366f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet50 model without the top layers as we do not want to classify for 1000 classes but only simple binary\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=size_ResNet + (3,))  # concatenating tuples\n",
    "\n",
    "print(base_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfc8e5d-4500-44a9-b1a0-ff461b11f871",
   "metadata": {},
   "source": [
    "Some of the parameters are non-trainable: these correspond to batch normalization layers that applies a transformation to maintain the mean output close to 0 and the output standard deviation close to 1. Mean and standard deviation are parameters that are not updated during backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a8edda-58bb-4caa-8caf-bda091e85d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers of the pre-trained model\n",
    "base_model.trainable = False\n",
    "\n",
    "len(base_model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee453a-924f-4ae4-a2ce-68c2412fd085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "fine_tuned_model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "fine_tuned_model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(fine_tuned_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e30f65-25b0-4167-88c2-addec0b1ed43",
   "metadata": {},
   "source": [
    "Unfortunately, the `Sequential` API cannot show us the number of parameters. Let's use the `Model` API instead which is more versatile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d237dbc2-350a-4163-b0b0-b5f81c7eded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "output = base_model.output\n",
    "output = GlobalAveragePooling2D()(output)\n",
    "output = Dense(256, activation=\"relu\")(output)\n",
    "output = Dense(1, activation=\"sigmoid\")(output)\n",
    "fine_tuned_model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "fine_tuned_model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(fine_tuned_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baf4f25-40c3-4d86-9b6d-af9586192e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the fine-tuned the model (batch size already defined)\n",
    "fine_tuned_model.fit(train_dataset, epochs=10, validation_data=test_dataset, callbacks=[EarlyStopping(monitor='val_accuracy', patience=5)])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = fine_tuned_model.evaluate(test_dataset)\n",
    "print('Test accuracy:', round(accuracy, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fb759a-bfac-4d3d-ac72-91ddeb1b6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# fetch dataset (takes a while)\n",
    "adult = fetch_openml(name=\"adult\", version=2) \n",
    "\n",
    "adult.frame.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb8f53a-124c-4b2f-b30c-b18a74896e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adult.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8624b9e5-959b-49ba-b0ef-582cc6613ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y = adult.frame[\"class\"]\n",
    "X = adult.frame.drop(columns=[\"class\"])\n",
    "\n",
    "prng = np.random.RandomState(20240325)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=prng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb890691-12f9-4c6a-b86c-81324823d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a56e817-dc8e-4d55-9c16-6b0638a90917",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbbad65-471f-4c98-8c20-7ae5abddd491",
   "metadata": {},
   "source": [
    "### Benchmark: logistic regression (sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de78546-add6-4001-ac5a-36e937f1ddb6",
   "metadata": {},
   "source": [
    "By default, sklearn Transformers return Numpy arrays. Thus, even though we input a Pandas DataFrame with the names of the features, we will lose them on the pipeline execution. This is a bad thing when we need to explain our model using, for example, feature importances, because we are no able to track feature names natively.\n",
    "You can explicitly set the output to keep the Pandas output with `set_config`. [Source](https://medium.com/@anderson.riciamorim/how-to-keep-feature-names-in-sklearn-pipeline-e00295359e31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556181d-a2b7-4609-b175-455c13148fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(transform_output=\"pandas\")  # ensure that the transformations return pandas df instead of numpy arrays (thus, they preserve column names e.g.)\n",
    "\n",
    "# preprocess\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False, drop=\"first\", handle_unknown=\"ignore\")\n",
    "categorical_vars = X.select_dtypes(include=\"category\").columns.to_list()\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    [(\"create_dummies\", one_hot_encoder, categorical_vars)],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "pipe_logit = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"preprocess\", column_transformer),\n",
    "    (\"scale\", MinMaxScaler()),\n",
    "    (\"logit\", LogisticRegression(penalty=None, random_state=prng))\n",
    "])\n",
    "pipe_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bb8247-5511-4887-9978-3f364b3a64c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef07c4d-c4a0-4817-9d18-1e1bc78f59f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "\n",
    "predicted_probs = pipe_logit.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc_score_test = roc_auc_score(y_test, predicted_probs)\n",
    "print(f\"AUC on the test set for simple logit is {round(auc_score_test, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6291c79-f11f-48a5-ba10-fa3a99deebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_logit[\"logit\"].coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede0a8c7-e4ff-46c4-8f9c-c0a4bebeb9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_logit[\"logit\"].feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2922607-2992-40b5-be05-4e2f52b726f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only categories that have enough observations, put the others into an \"infrequent\" group\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False, drop=\"first\", min_frequency=100, handle_unknown=\"infrequent_if_exist\")\n",
    "\n",
    "column_transformer = ColumnTransformer(\n",
    "    [(\"create_dummies\", one_hot_encoder, categorical_vars)],\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False  # keep variable names shorter\n",
    ")\n",
    "\n",
    "pipe_logit = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"preprocess\", column_transformer),\n",
    "    (\"scale\", MinMaxScaler()),\n",
    "    (\"logit\", LogisticRegression(penalty=None, random_state=prng, max_iter=1000))\n",
    "])\n",
    "pipe_logit.fit(X_train, y_train)\n",
    "pipe_logit[\"logit\"].feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f34f1b-3a3e-46aa-ac07-f2df673740de",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probs = pipe_logit.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc_score_test = roc_auc_score(y_test, predicted_probs)\n",
    "print(f\"AUC on the test set for the interpretable logit is {round(auc_score_test, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ee8926-06d7-44bf-b855-66b353912606",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model_summary = pd.DataFrame({\n",
    "    \"feature\": pipe_logit[\"logit\"].feature_names_in_,\n",
    "    \"coefficient\": pipe_logit[\"logit\"].coef_[0]\n",
    "})\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfe0857-5cdb-45f6-b839-e4525cb407e7",
   "metadata": {},
   "source": [
    "The logistic regression model uses the sigmoid function to transform the real line into [0, 1]\n",
    "\n",
    "$$\n",
    "P(Y=1) = sigmoid(\\beta_0 + \\beta_1 X_1 + ... + \\beta_k X_k)\n",
    "$$\n",
    "\n",
    "As \n",
    "\n",
    "$$\n",
    "sigmoid(x) = \\frac{1}{1 + \\exp(-x)}\n",
    "$$\n",
    "\n",
    "with some restructuring we can get a result showing that logistic regression is a linear model for the log odds:\n",
    "\n",
    "$$\n",
    "\\log\\left(\\frac{P(Y=1)}{1 - P(Y=1)}\\right) = \\log(odds) = \\beta_0 + \\beta_1 X_1 + ... + \\beta_k X_k\n",
    "$$\n",
    "\n",
    "From here we can derive that a change in a feature by one unit changes the odds ratio (multiplicative) by a factor of the exponential of its coefficient:\n",
    "\n",
    "$$\n",
    "\\frac{odds(x_j + 1)}{odds(x_j)} = \\exp(\\beta_j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34613310-f0b2-4e65-ba5a-84fab250aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary[\"odds_ratio\"] = np.exp(model_summary[\"coefficient\"])\n",
    "model_summary.sort_values(by=\"odds_ratio\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033230ef-8a33-4c17-8759-6455f9bf73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "top_coeffs = model_summary.sort_values(by=\"coefficient\", ascending=True).tail(20)\n",
    "plt.barh(top_coeffs.feature, top_coeffs.odds_ratio)\n",
    "plt.xlabel(\"Odds ratio\")\n",
    "plt.title(\"Odds ratio of the top 20 positive factors\")\n",
    "plt.axvline(x=1, color=\"darkred\", linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dd87ce-251b-4179-8881-afa8b4c9dc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_coeffs = model_summary.sort_values(by=\"coefficient\", ascending=True).head(20)\n",
    "plt.barh(bottom_coeffs.feature, bottom_coeffs.odds_ratio)\n",
    "plt.xlabel(\"Odds ratio\")\n",
    "plt.title(\"Odds ratio of the top 20 negative factors\")\n",
    "plt.axvline(x=1, color=\"darkred\", linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846cd6bf-91bf-44bd-a97d-aa185b61efd5",
   "metadata": {},
   "source": [
    "Is scaling a good idea?\n",
    "Without scaling the coefficients could be easier to interpret. However, convergence is much harder to achieve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c710fa0-9d77-4a43-a1c2-2183c4eec64b",
   "metadata": {},
   "source": [
    "### Permutation-based feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea608b4-a3be-40c5-9065-3d2201028dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", message=\"Found unknown categories*\")\n",
    "    varimp_permutation = permutation_importance(pipe_logit, X_test, y_test, n_repeats=10, scoring=\"roc_auc\", random_state=prng)   # could run in parallel with n_jobs=-1 but then suppressing the warnings is more complicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d15f5d-7552-46bc-adbd-9faa5d914151",
   "metadata": {},
   "outputs": [],
   "source": [
    "varimp_sorted_idx = varimp_permutation.importances_mean.argsort()\n",
    "\n",
    "plt.boxplot(\n",
    "    varimp_permutation.importances[varimp_sorted_idx].T, \n",
    "    labels=X.columns[varimp_sorted_idx],\n",
    "    vert=False\n",
    ")\n",
    "plt.axvline(x=0, color=\"darkred\", linestyle=\"--\")\n",
    "plt.xlabel(\"Decrease in AUC (ROC) score\")\n",
    "plt.title(\"Permutation based feature importance (test set)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b426a-81a1-46b8-aaf4-a78723fd2802",
   "metadata": {},
   "source": [
    "### Partial dependence plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d882f50f-a7b9-4e99-9bfb-3dbb508a5615",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import warnings\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", message=\"Found unknown categories*\")\n",
    "    PartialDependenceDisplay.from_estimator(\n",
    "        pipe_logit, X_test, \n",
    "        features=[\"marital-status\", \"capital-gain\", \"education\", (\"marital-status\", \"education\")], \n",
    "        categorical_features=[\"marital-status\", \"education\"], \n",
    "        n_cols=4, ax=ax\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7118753c-28c7-44f4-a71a-45ff1a7b22fc",
   "metadata": {},
   "source": [
    "### Logistic regression with interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942fb95a-1fdc-47e2-9ab1-71ce5629ba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret import set_visualize_provider\n",
    "from interpret.provider import InlineProvider\n",
    "set_visualize_provider(InlineProvider())\n",
    "\n",
    "from interpret.glassbox import LogisticRegression as ILogisticRegression\n",
    "interpret_logit_pipe = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"preprocess\", column_transformer),\n",
    "    (\"logit\", ILogisticRegression(penalty=None, random_state=prng, max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce66ee8-c1c3-4989-b68f-922b040bf691",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret_logit_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed65e5a-3ff1-49d0-b0a6-3681a10239b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probs = interpret_logit_pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc_score_test = roc_auc_score(y_test, predicted_probs)\n",
    "print(f\"AUC on the test set for interpret logit is {round(auc_score_test, 4)}\")  # same as before as it is only a wrapper around sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d237b-ab14-4e71-93cf-5b6165fdeefb",
   "metadata": {},
   "source": [
    "### Glassbox explainers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d038d81-a5b0-44f4-af09-df8ec1b4ae31",
   "metadata": {},
   "source": [
    "#### Global: coefficient values (marginal contribution to log odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aaf3f6-e911-4518-9163-f43a2354b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret import show\n",
    "logit_global = interpret_logit_pipe[\"logit\"].explain_global(name=\"Logit\")\n",
    "show(logit_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c52d8f5-313f-437c-8ff3-01719c57ae6b",
   "metadata": {},
   "source": [
    "Unfortunately, interpret's explainers cannot work on Pipelines directly, so we have to transform the test data separately (using the transformation steps of the Pipeline)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed27415-8e56-43f1-af5b-e71a03fb8ef4",
   "metadata": {},
   "source": [
    "#### Local: individual predictions (weight * feature value within sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9034cfa0-51b2-4598-b95a-302273152ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_local = interpret_logit_pipe[\"logit\"].explain_local(interpret_logit_pipe[:-1].transform(X_test)[:15], y_test[:15], name=\"Logit\")\n",
    "show(logit_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d09cfe5-3845-4b65-9f49-fbe92a5ee8d1",
   "metadata": {},
   "source": [
    "### Explainable Boosting Machine (EBM)\n",
    "\n",
    "EBM is a glassbox model, designed to have accuracy comparable to state-of-the-art machine learning methods like Random Forest and Boosted Trees, while being highly intelligibile and explainable. EBM is a generalized additive model. See [this video](https://www.youtube.com/watch?v=MREiHgHgl0k&ab_channel=MicrosoftDeveloper) for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b5a7a7-5c90-4f90-95ed-d43dce2382a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "\n",
    "# as EBM is based on trees, it can handle categorical features so no need for one-hot-encoding\n",
    "ebm_pipe = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"ebm\", ExplainableBoostingClassifier(random_state=20240325))  # cannot accept RandomState directly\n",
    "])\n",
    "ebm_pipe.fit(X_train, y_train)  \n",
    "\n",
    "auc = roc_auc_score(y_test, ebm_pipe.predict_proba(X_test)[:, 1])\n",
    "print(f\"AUC on the test set for EBM is {round(auc, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829ddd07-f208-4dbf-9fc5-10cd169f31d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(ebm_pipe[\"ebm\"].explain_global(name=\"EBM\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eddca63-2d60-4e36-9de5-186d8b5ef9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(ebm_pipe[\"ebm\"].explain_local(X_test[:15], y_test[:15], name=\"EBM\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1d59c8-ac6f-43d5-b078-f3434e2150ca",
   "metadata": {},
   "source": [
    "### Comparison: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15de3389-3262-4a00-9345-cf5ab8501e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# sklearn cannot handle categorical features so we need to one-hot-encode\n",
    "rf_pipe = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"preprocess\", column_transformer),\n",
    "    (\"rf\", RandomForestClassifier(random_state=20240325))\n",
    "])\n",
    "\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "predicted_probs = rf_pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc_score_test = roc_auc_score(y_test, predicted_probs)\n",
    "print(f\"AUC on the test set for RF is {round(auc_score_test, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94f7266-02a1-4d43-9db2-4cc87b0c41f4",
   "metadata": {},
   "source": [
    "### Blackbox explainers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aac322b-dc8a-454b-b00a-c048f949565e",
   "metadata": {},
   "source": [
    "#### Some data manipulation to make categorical explanations easier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84672741-933b-470a-8350-5362d2249619",
   "metadata": {},
   "source": [
    "Unfortunately, categorical features are not handled automatically, so we need to do some workarounds.\n",
    "\n",
    "1. Label encode categorical variables so that they are represented by numbers (strings would throw errors).\n",
    "2. Store the categories represented by the coded numeric values for each variable.\n",
    "3. Do one-hot encoding for modelling (but not for explanation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf32b7-2236-475c-a718-a786070a64ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding (encode missings as well) & Save category values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_encoded = X\n",
    "category_names = {}\n",
    "for var in categorical_vars:\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(X[var])\n",
    "    X_encoded[var] = label_encoder.transform(X[var])\n",
    "    category_names[var] = label_encoder.classes_\n",
    "\n",
    "category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3bab4d-dd94-417c-a232-3c1520a626b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformation on the whole data\n",
    "prng = np.random.RandomState(20240325)\n",
    "X_train_encoded, X_test_encoded, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=prng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bad82f-7d2f-4020-8c98-3db0849e1bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train.iloc[0], X_train_encoded.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8002c14d-4187-47c2-b659-d0792f478453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain the model to ensure one-hot-encoded features correspond to the same\n",
    "rf_pipe_encoded = Pipeline([\n",
    "    (\"preprocess\", column_transformer),\n",
    "    (\"rf\", RandomForestClassifier(random_state=20240325))\n",
    "])\n",
    "\n",
    "rf_pipe_encoded.fit(X_train, y_train)\n",
    "predicted_probs = rf_pipe_encoded.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc_score_test = roc_auc_score(y_test, predicted_probs)\n",
    "print(f\"AUC on the test set for encoded RF is {round(auc_score_test, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1d33cd-73d2-44e3-b03d-f55b45721775",
   "metadata": {},
   "source": [
    "#### PDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414a4c9f-cb9e-4ee6-be21-b71166c4c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.blackbox import PartialDependence\n",
    "\n",
    "feature_types = [\"nominal\" if v in categorical_vars else \"continuous\" for v in X.columns]\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", message=\"Found unknown categories*\")\n",
    "    pdp = PartialDependence(\n",
    "        rf_pipe_encoded, X_test_encoded, \n",
    "        feature_names=X.columns.to_list(), \n",
    "        feature_types=feature_types\n",
    "    )\n",
    "\n",
    "show(pdp.explain_global(), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb322ee-4bda-4092-be2f-bb9193985fbe",
   "metadata": {},
   "source": [
    "#### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce54f16-1c65-44f8-904d-3410c68831ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef578b-47b9-4b58-a3f3-2ef2aba467f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.blackbox import LimeTabular\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lime = LimeTabular(\n",
    "    rf_pipe_encoded, X_train_encoded,\n",
    "    categorical_features=categorical_vars, \n",
    "    categorical_names=category_names, \n",
    "    kernel_width=3,\n",
    "    random_state=20240325\n",
    ")\n",
    "\n",
    "# LimeTabular expects numeric labels so we need to encode it first\n",
    "y_test_numeric = LabelEncoder().fit_transform(y_test)\n",
    "show(lime.explain_local(rf_pipe[:-1].transform(X_test[:15]), y_test_numeric[:15], name=\"LIME\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd2f29-0815-4c19-9119-10b77c8b0cee",
   "metadata": {},
   "source": [
    "#### Shapley"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af781cd0-35bc-4aac-8e38-926199e4fb62",
   "metadata": {},
   "source": [
    "Takes a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c95da-0aa4-4fbb-b296-4b65dedc7357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.blackbox import ShapKernel\n",
    "\n",
    "shap_kernel = ShapKernel(rf_pipe[-1], rf_pipe[:-1].transform(X_train))\n",
    "show(shap_kernel.explain_local(rf_pipe[:-1].transform(X_test)[:15], y_test[:15]), name = \"SHAP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319e8d2-3357-466e-ab6b-bb10cf10230f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
