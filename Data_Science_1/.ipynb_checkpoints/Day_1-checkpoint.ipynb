{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "095e1ac2-c972-4982-9eca-a9f3d432678c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.4\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bb07cb-601c-469b-bce4-7694d19402a8",
   "metadata": {},
   "source": [
    "### *Create some data*\n",
    "\n",
    "Write out the Y model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14ee35c1-e242-4c33-be4f-491bc9d3094f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# creating a random dataset\n",
    "np.random.seed(21022024)\n",
    "\n",
    "n = 500\n",
    "\n",
    "X = np.random.uniform(0, 2, size = (n, 3))\n",
    "\n",
    "epsilon = np.random.normal(0, 1, size=n)\n",
    "\n",
    "# from the exercise\n",
    "# Y = X1**3 - 3.5*X1**2 + 3*X1 + epsilon\n",
    "\n",
    "# but we need to reference X appropriately\n",
    "# first element is indexed by 0, so [:, 0] = X1\n",
    "\n",
    "def f(feature_matrix):\n",
    "    return feature_matrix[:,0]**3 - 3.5*feature_matrix[:,0]**2 + 3*feature_matrix[:,0]\n",
    "\n",
    "Y = f(X) + epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef12d27a-7f05-4248-8a16-1c0665120792",
   "metadata": {},
   "source": [
    "### *Begin Linear Regression*\n",
    "\n",
    "Import LinearRegression from sklearn\n",
    "\n",
    "Once you have the LinearRegression() object, you need to fit it to X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "301fb7d7-ba97-4b11-8e99-19ad8926772c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# b) estimate models\n",
    "model1 = LinearRegression().fit(X[:,0].reshape(-1,1), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42fcc8e1-7e6f-424f-82e9-f633325d86bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68978631])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c) computer the estimate ~ predict\n",
    "x_value = np.array([[0.1, 0, 0]]) # the two brackets show that it should be a matrix of 2 rows\n",
    "\n",
    "\n",
    "model1.predict(x_value[:, 0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1bb08394-d2d5-4a6b-95a8-bda091ae9fd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.266])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d1e46ce-459e-4644-8efd-a98debdf2888",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d5fb24c-671a-4507-94ab-7a138571c8f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1073135b-23ee-450a-8231-4327343a07de",
   "metadata": {
    "tags": []
   },
   "source": [
    "Run Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b2bc46a7-a40a-475c-8651-cf0ce3dee991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "np.random.seed(21022024)\n",
    "\n",
    "n = 500\n",
    "R = 5\n",
    "x_value = np.array([[0.1, 0, 0]]) # the two brackets show that it should be a matrix of 2 rows\n",
    "def f(feature_matrix):\n",
    "    return feature_matrix[:,0]**3 - 3.5*feature_matrix[:,0]**2 + 3*feature_matrix[:,0]\n",
    "\n",
    "    # LOOP\n",
    "results = []\n",
    "for _ in range(R):\n",
    "    # For R Times, repeat: \n",
    "    # a. data generation\n",
    "    X = np.random.uniform(0, 2, size = (n, 3))\n",
    "    epsilon = np.random.normal(0, 1, size=n)\n",
    "    Y = f(X) + epsilon\n",
    "    \n",
    "    # b. estimate model\n",
    "    \n",
    "    #model 1\n",
    "    model1 = LinearRegression().fit(X[:,0].reshape(-1,1), Y)\n",
    "    \n",
    "    #model 2\n",
    "    poly2 = PolynomialFeatures(3) # third degree polynomial\n",
    "    X_poly2 = poly2.fit_transform(X[:, 0].reshape(-1,1))\n",
    "    model2 = LinearRegression().fit(X_poly2, Y)\n",
    "\n",
    "\n",
    "    # model 3 (giving them all the features)\n",
    "    poly3 = PolynomialFeatures(3) # third degree polynomial\n",
    "    X_poly3 = poly3.fit_transform(X)\n",
    "    model3 = LinearRegression().fit(X_poly3, Y)\n",
    "    \n",
    "    # c. predict the model for x_value\n",
    "    pred1 = model1.predict(x_value[:, 0].reshape(1, -1))\n",
    "    pred2 = model2.predict(poly2.transform(x_value[:,0].reshape(-1,1)))\n",
    "    pred3 = model3.predict(poly3.transform(x_value))\n",
    "    \n",
    "    # store predictions\n",
    "    results.append([pred1, pred2, pred3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "589b3b4a-c47a-4e55-b197-28b7188e6c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3, 1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f6aebb43-5137-42ca-80ea-b656c1231bff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.68978631]), array([0.43950299]), array([0.00459712])]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0] # here you can see now it is 2 array elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bcca00ab-910b-43a9-a11b-f24df9bb3a22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.68978631],\n",
       "        [ 0.43950299],\n",
       "        [ 0.00459712]],\n",
       "\n",
       "       [[ 0.87216654],\n",
       "        [ 0.25373275],\n",
       "        [ 0.16656408]],\n",
       "\n",
       "       [[ 0.72822135],\n",
       "        [ 0.32940448],\n",
       "        [ 0.54944946]],\n",
       "\n",
       "       [[ 0.76367027],\n",
       "        [ 0.23774149],\n",
       "        [ 0.43267868]],\n",
       "\n",
       "       [[ 0.82306226],\n",
       "        [ 0.1731394 ],\n",
       "        [-0.29548637]]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_array = np.array(results) # this is cool, but hard to differenciate between pred1 and pred2\n",
    "results_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f57b1ce-065a-442a-a3c1-7b6f76dc40d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77538135],\n",
       "       [0.28670422],\n",
       "       [0.17156059]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results_array, axis=0) \n",
    "# first results is for the first model, and second is for the second model\n",
    "# the axis = 0 does this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf82d018-b79c-453a-a8df-4e4bd985fe58",
   "metadata": {},
   "source": [
    "Now, we need to calculate the bias. This is the difference between the predicted values and the actual values. We will use the mean of the results_array as the predicted. \n",
    "\n",
    "f(x_value) is the actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "756600cb-47a6-4800-b81a-ab82aac552c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>bias</th>\n",
       "      <th>variance</th>\n",
       "      <th>mse</th>\n",
       "      <th>mse_check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 1</td>\n",
       "      <td>0.509381</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.263735</td>\n",
       "      <td>0.263735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 2</td>\n",
       "      <td>0.020704</td>\n",
       "      <td>0.008310</td>\n",
       "      <td>0.008739</td>\n",
       "      <td>0.008739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 3</td>\n",
       "      <td>-0.094439</td>\n",
       "      <td>0.091403</td>\n",
       "      <td>0.100322</td>\n",
       "      <td>0.100322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model      bias  variance       mse  mse_check\n",
       "0  Model 1  0.509381  0.004266  0.263735   0.263735\n",
       "1  Model 2  0.020704  0.008310  0.008739   0.008739\n",
       "2  Model 3 -0.094439  0.091403  0.100322   0.100322"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#bias = np.mean(results_array) - f(x_value)\n",
    "#variance = np.var(results_array)\n",
    "#mse = np.mean((results_array - f(x_value))**2 # mean squared error\n",
    "#mse_check = bias**2 + variance\n",
    "\n",
    "\n",
    "# put everything in a pandas df\n",
    "# Calculate bias, variance, and mse outside the DataFrame creation for clarity\n",
    "bias = (np.mean(results_array, axis = 0) - f(x_value)).flatten()\n",
    "variance = (np.var(results_array, axis = 0)).flatten()\n",
    "mse = (np.mean((results_array - f(x_value))**2, axis = 0)).flatten()  # Corrected missing parenthesis here\n",
    "\n",
    "# Put everything in a pandas DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'model': ('Model 1', 'Model 2', 'Model 3'),  # Ensure the values are in a list for consistent DataFrame structure\n",
    "    'bias': bias,\n",
    "    'variance': variance,\n",
    "    'mse': mse  # Use the previously calculated mse\n",
    "})\n",
    "\n",
    "# Calculate mse_check and add it as a new column to the DataFrame\n",
    "df['mse_check'] = df['bias']**2 + df['variance']  # Ensure to use DataFrame's variance column\n",
    "\n",
    "# Print or return the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f29b06-ea8f-41ba-8e08-722b3180ba46",
   "metadata": {},
   "source": [
    "The `bias` should be 0. As we estimate more parameters, the variance will increase, and the bias should decrease. \n",
    "\n",
    "The third model is overfit. The first model is underfit. Is what we are seeing here is Model 2 is a good match, as it has a bias close to 0, a good variance, and mse. \n",
    "\n",
    "Underfit models have high bias and low variance. Overfit has low bias, high variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b840ce-a7e6-4a54-be45-f08788ca6643",
   "metadata": {},
   "source": [
    "# ChatGPT Restructured Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0ded67-b177-4bb1-9caf-99b5029dcc2c",
   "metadata": {},
   "source": [
    "## 1. Setup and Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b5985346-af0c-4c8d-9918-ea01a16e44e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "np.random.seed(21022024)  # Ensure reproducibility\n",
    "\n",
    "# Define the true function\n",
    "def f(feature_matrix):\n",
    "    return feature_matrix[:,0]**3 - 3.5*feature_matrix[:,0]**2 + 3*feature_matrix[:,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19dbd3c-e6cc-4906-8608-aa1fe5ee4fd5",
   "metadata": {},
   "source": [
    "## 2. Data Generation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "754f7bcd-8d09-44b2-80cc-c73e5bd20a29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 500  # Number of samples\n",
    "R = 5  # Number of repetitions\n",
    "x_value = np.array([[0.1, 0, 0]])  # Evaluation point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca5962c-2f31-4f56-af5e-6f95e33f0c27",
   "metadata": {},
   "source": [
    "## 3. Model Training and Prediction Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c06f7913-858d-4be9-8f93-e8979bba0759",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []  # Initialize list to store results\n",
    "\n",
    "for _ in range(R):\n",
    "    # a. Generate data\n",
    "    X = np.random.uniform(0, 2, size=(n, 3))\n",
    "    epsilon = np.random.normal(0, 1, size=n)\n",
    "    Y = f(X) + epsilon\n",
    "\n",
    "    # b. Fit models\n",
    "    # Model 1: Linear Regression\n",
    "    model1 = LinearRegression().fit(X[:, 0].reshape(-1, 1), Y)\n",
    "    \n",
    "    # Model 2: Polynomial Regression (3rd degree) with one feature\n",
    "    poly2 = PolynomialFeatures(3)\n",
    "    X_poly2 = poly2.fit_transform(X[:, 0].reshape(-1, 1))\n",
    "    model2 = LinearRegression().fit(X_poly2, Y)\n",
    "    \n",
    "    # Model 3: Polynomial Regression (3rd degree) with all features\n",
    "    poly3 = PolynomialFeatures(3)\n",
    "    X_poly3 = poly3.fit_transform(X)\n",
    "    model3 = LinearRegression().fit(X_poly3, Y)\n",
    "    \n",
    "    # c. Make predictions at x_value\n",
    "    pred1 = model1.predict(x_value[:, 0].reshape(1, -1))\n",
    "    pred2 = model2.predict(poly2.transform(x_value[:, 0].reshape(-1, 1)))\n",
    "    pred3 = model3.predict(poly3.transform(x_value))\n",
    "    \n",
    "    # Store predictions\n",
    "    results.append([pred1, pred2, pred3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e92e2b2-13b6-44db-92ed-615b01d3ab09",
   "metadata": {},
   "source": [
    "## 4. Analysis and DataFrame Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "db34a678-91cc-4991-b943-b6e8c7410659",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     model      bias  variance       mse  mse_check\n",
      "0  Model 1  0.509381  0.004266  0.263735   0.263735\n",
      "1  Model 2  0.020704  0.008310  0.008739   0.008739\n",
      "2  Model 3 -0.094439  0.091403  0.100322   0.100322\n"
     ]
    }
   ],
   "source": [
    "# Convert results to a NumPy array for analysis\n",
    "results_array = np.array(results).squeeze()  # Remove any unnecessary dimensions\n",
    "\n",
    "# Calculate metrics\n",
    "bias = np.mean(results_array - f(x_value), axis=0)\n",
    "variance = np.var(results_array, axis=0)\n",
    "mse = np.mean((results_array - f(x_value))**2, axis=0)\n",
    "\n",
    "# Create DataFrame to summarize results\n",
    "df = pd.DataFrame({\n",
    "    'model': ['Model 1', 'Model 2', 'Model 3'],\n",
    "    'bias': bias,\n",
    "    'variance': variance,\n",
    "    'mse': mse\n",
    "})\n",
    "\n",
    "# Calculate mse_check (for verification)\n",
    "df['mse_check'] = df['bias']**2 + df['variance']\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f1b61b-9458-491f-a58b-8e5aa5bad80b",
   "metadata": {},
   "source": [
    "## Notes on Model Evaluation\n",
    "\n",
    "    Bias: Represents the error from erroneous assumptions in the learning algorithm. High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting).\n",
    "    Variance: Represents the error from sensitivity to small fluctuations in the training set. High variance can cause an algorithm to model the random noise in the training data, rather than the intended outputs (overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af70ae4-0b4a-43a0-a1fc-6d78193cd564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
